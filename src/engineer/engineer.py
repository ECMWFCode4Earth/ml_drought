import numpy as np
from collections import defaultdict
import calendar
from datetime import date
from pathlib import Path
import xarray as xr

from typing import cast, Dict, List, Optional, Union, Tuple
from typing import DefaultDict as DDict

from ..utils import minus_months


class Engineer:
    """The engineer is responsible for taking all the data from the preprocessors,
    and saving a single training netcdf file to be ingested by machine learning models.

    Training and test sets are defined here, to ensure different machine learning models have
    access to the same data.

    Attributes:
    ----------
    data_folder: Path, default: Path('data')
        The location of the data folder.
    """

    def __init__(self, data_folder: Path = Path('data')) -> None:

        self.data_folder = data_folder

        self.interim_folder = data_folder / 'interim'
        assert self.interim_folder.exists(), \
            f'{data_folder / "interim"} does not exist. Has the preprocesser been run?'

        self.output_folder = data_folder / 'features'
        if not self.output_folder.exists():
            self.output_folder.mkdir()

    def engineer(self, test_year: Union[int, List[int]],
                 target_variable: str = 'VHI'):
        """
        Take all the preprocessed data generated by the preprocessing classes, and turn it
        into a single training file to be ingested by the machine learning models.

        Arguments
        ----------
        test_year: Union[int, List[int]]
            Data to be used for testing. No data earlier than the earliest test year
            will be used for training.
            If a list is passed, a file for each year will be saved.
        target_variable: str = 'VHI'
            The variable to be predicted. Only this variable will be saved in the test
            netcdf files
        """
        data = self._make_dataset()

        if type(test_year) is int:
            test_year = [cast(int, test_year)]

        train, test = self._train_test_split(data, cast(List, test_year), target_variable)
        self._save(train, test)

    def _get_preprocessed_files(self) -> List[Path]:
        processed_files = []
        for subfolder in self.interim_folder.iterdir():
            if str(subfolder).endswith('_preprocessed') and subfolder.is_dir():
                processed_files.extend(list(subfolder.glob('*.nc')))
        return processed_files

    def _make_dataset(self) -> xr.Dataset:

        datasets = []
        dims = ['lon', 'lat']
        coords = {}
        for idx, file in enumerate(self._get_preprocessed_files()):
            print(f'Processing {file}')
            datasets.append(xr.open_dataset(file))

            if idx == 0:
                for dim in dims:
                    coords[dim] = datasets[idx][dim].values
            else:
                for dim in dims:
                    assert (datasets[idx][dim].values == coords[dim]).all(), \
                        f'{dim} is different! Was this run using the preprocessor?'

        main_dataset = datasets[0]
        for dataset in datasets[1:]:
            main_dataset = main_dataset.merge(dataset, join='inner')

        return main_dataset

    def _train_test_split(self, ds: xr.Dataset,
                          years: List[int],
                          target_variable: str,
                          pred_months: int = 11,
                          expected_length: Optional[int] = 11,
                          ) -> Tuple[xr.Dataset, DDict[int, DDict[int, Dict[str, xr.Dataset]]]]:
        years.sort()

        output_test_arrays: DDict[int, DDict[int, Dict[str, xr.Dataset]]] = \
            defaultdict(lambda: defaultdict(dict))

        train, test_datasets = self._train_test_split_single_month(ds, years[0],
                                                                   target_variable,
                                                                   1, pred_months,
                                                                   expected_length, True)
        if test_datasets is not None:
            output_test_arrays[years[0]][1] = test_datasets

        for year in years:
            for month in range(1, 13):
                if year > years[0] or month > 1:
                    # prevents the initial test set from being recalculated
                    _, subtest = self._train_test_split_single_month(ds, year,
                                                                     target_variable,
                                                                     month, pred_months,
                                                                     expected_length)
                    if subtest is not None:
                        output_test_arrays[year][month] = subtest

        return train, output_test_arrays

    @staticmethod
    def _train_test_split_single_month(ds: xr.Dataset,
                                       year: int,
                                       target_variable: str,
                                       target_month: int,
                                       pred_months: int,
                                       expected_length: Optional[int],
                                       make_train: bool = False,
                                       ) -> Tuple[Optional[xr.Dataset],
                                                  Optional[Dict[str, xr.Dataset]]]:

        print(f'Generating test data for year: {year}, target month: {target_month}')

        max_date = date(year, target_month, calendar.monthrange(year, target_month)[-1])
        mx_year, mx_month, max_train_date = minus_months(year, target_month, diff_months=1)
        _, _, min_date = minus_months(mx_year, mx_month, diff_months=pred_months)

        min_date_np = np.datetime64(str(min_date))
        max_date_np = np.datetime64(str(max_date))
        max_train_date_np = np.datetime64(str(max_train_date))

        print(f'Max date: {str(max_date)}, max train date: {str(max_train_date)}, '
              f'min train date: {str(min_date)}')

        if make_train:
            train = ds.time.values <= min_date_np
            train_ds = ds.isel(time=train)
        else:
            train_ds = None

        test_x = ((ds.time.values > min_date_np) & (ds.time.values <= max_train_date_np))
        test_y = ((ds.time.values > max_train_date_np) & (ds.time.values <= max_date_np))

        if sum(test_y) == 0:
            print('Wrong number of test y values! Got 0; returning None')
            return train_ds, None

        if expected_length is not None:
            if sum(test_x) != expected_length:
                print(f'Wrong number of test x values! Got {sum(test_x)} Returning None')

                return train_ds, None

        test_x_dataset = ds.isel(time=test_x)
        test_y_dataset = ds.isel(time=test_y)[target_variable].to_dataset()

        return train_ds, {'x': test_x_dataset, 'y': test_y_dataset}

    def _save(self, train: xr.Dataset, test: DDict[int, DDict[int, Dict[str, xr.Dataset]]]):
        train.to_netcdf(self.output_folder / 'train.nc')

        for year_key, val in test.items():

            for month_key, test_dict in val.items():

                test_folder = self.output_folder / f'test_{year_key}_{month_key}'
                test_folder.mkdir()

                for x_or_y, ds in test_dict.items():
                    ds.to_netcdf(test_folder / f'{x_or_y}.nc')
