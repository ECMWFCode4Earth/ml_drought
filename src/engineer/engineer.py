import numpy as np
import calendar
from dateutil.relativedelta import relativedelta
from datetime import date
from pathlib import Path
import xarray as xr

from typing import cast, Dict, List, Union, Tuple


class Engineer:
    """The engineer is responsible for taking all the data from the preprocessors,
    and saving a single training netcdf file to be ingested by machine learning models.

    Training and test sets are defined here, to ensure different machine learning models have
    access to the same data.

    Attributes:
    ----------
    data_folder: Path, default: Path('data')
        The location of the data folder.
    """

    def __init__(self, data_folder: Path = Path('data')) -> None:

        self.data_folder = data_folder

        self.interim_folder = data_folder / 'interim'
        assert self.interim_folder.exists(), \
            f'{data_folder / "interim"} does not exist. Has the preprocesser been run?'

        self.output_folder = data_folder / 'features'
        if not self.output_folder.exists():
            self.output_folder.mkdir()

    def engineer(self, test_year: Union[int, List[int]],
                 target_variable: str = 'VHI',
                 target_month: int = 6):
        """
        Take all the preprocessed data generated by the preprocessing classes, and turn it
        into a single training file to be ingested by the machine learning models.

        Arguments
        ----------
        test_year: Union[int, List[int]]
            Data to be used for testing. No data earlier than the earliest test year
            will be used for training.
            If a list is passed, a file for each year will be saved.
        target_variable: str = 'VHI'
            The variable to be predicted. Only this variable will be saved in the test
            netcdf files
        target_month: int = 6
            The month being predicted. Test data will consist of this month, plus
            11 months of data before
        """
        data = self._make_dataset()

        if type(test_year) is int:
            test_year = [cast(int, test_year)]

        train, test = self._train_test_split(data, cast(List, test_year), target_variable,
                                             target_month)
        self._save(train, test)

    def _get_preprocessed_files(self) -> List[Path]:
        processed_files = []
        for subfolder in self.interim_folder.iterdir():
            if str(subfolder).endswith('_preprocessed') and subfolder.is_dir():
                processed_files.extend(list(subfolder.glob('*.nc')))
        return processed_files

    def _make_dataset(self) -> xr.Dataset:

        datasets = []
        dims = ['lon', 'lat']
        coords = {}
        for idx, file in enumerate(self._get_preprocessed_files()):
            datasets.append(xr.open_dataset(file))

            if idx == 0:
                for dim in dims:
                    coords[dim] = datasets[idx][dim].values
            else:
                for dim in dims:
                    assert (datasets[idx][dim].values == coords[dim]).all(), \
                        f'{dim} is different! Was this run using the preprocessor?'

        main_dataset = datasets[0]
        for dataset in datasets[1:]:
            main_dataset = main_dataset.merge(dataset, join='inner')

        return main_dataset

    def _train_test_split(self, ds: xr.Dataset,
                          years: List[int],
                          target_variable: str,
                          target_month: int,
                          ) -> Tuple[xr.Dataset, Dict[int, xr.Dataset]]:
        years.sort()

        output_test_arrays = {}

        train, test = self._train_test_split_single_year(ds, years[0],
                                                         target_variable,
                                                         target_month)
        output_test_arrays[years[0]] = test

        if len(years) > 1:
            for year in years[1:]:
                _, subtest = self._train_test_split_single_year(ds, year,
                                                                target_variable,
                                                                target_month)
                output_test_arrays[year] = subtest

        return train, output_test_arrays

    @staticmethod
    def _train_test_split_single_year(ds: xr.Dataset,
                                      year: int,
                                      target_variable: str,
                                      target_month: int
                                      ) -> Tuple[xr.Dataset, xr.Dataset]:

        max_date = date(year, target_month, calendar.monthrange(year, target_month)[-1])
        min_date = max_date - relativedelta(years=1)
        min_date_np = np.datetime64(str(min_date))
        max_date_np = np.datetime64(str(max_date))

        train = ds.time.values <= min_date_np
        test = ((ds.time.values > min_date_np) & (ds.time.values <= max_date_np))

        test_dataset = ds.isel(time=test)[target_variable].to_dataset()

        return ds.isel(time=train), test_dataset

    def _save(self, train: xr.Dataset, test: Dict[int, xr.Dataset]):
        train.to_netcdf(self.output_folder / 'train.nc')

        for key, val in test.items():

            filename = f'test_{key}.nc'

            val.to_netcdf(self.output_folder / filename)
