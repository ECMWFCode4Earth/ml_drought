{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 365, discharge_spec, 13 stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/ml_drought\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# ignore warnings for now ...\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "if Path('.').absolute().parents[1].name == 'ml_drought':\n",
    "    os.chdir(Path('.').absolute().parents[1])\n",
    "\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import torch\n",
    "\n",
    "from typing import List, Union, Optional, Tuple, Dict\n",
    "\n",
    "data_dir = Path('data/')\n",
    "# data_dir = Path('/Volumes/Lees_Extend/data/zip_data')\n",
    "# data_dir = Path('/Volumes/Lees_Extend/data/ecmwf_sowc/data/')\n",
    "# plot_dir = Path('/Users/tommylees/Downloads')\n",
    "\n",
    "assert data_dir.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from src.utils import drop_nans_and_flatten\n",
    "\n",
    "from src.analysis import read_train_data, read_test_data, read_pred_data\n",
    "from src.analysis.evaluation import join_true_pred_da\n",
    "from src.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2020_04_07:171723_one_timestep_forecast',\n",
       "       '2020_04_13:090536_one_timestep_forecast',\n",
       "       '2020_04_13:091211_one_timestep_forecast',\n",
       "       '2020_04_13:144437_one_timestep_forecast',\n",
       "       '2020_04_13:155432_one_timestep_forecast',\n",
       "       '2020_04_13:171738_one_timestep_forecast',\n",
       "       '2020_04_15:095841_one_timestep_forecast',\n",
       "       '2020_04_15:124352_one_timestep_forecast',\n",
       "       '2020_04_15:135101_one_timestep_forecast', 'one_timestep_forecast',\n",
       "       'one_timestep_forecast_19epoch_static',\n",
       "       'one_timestep_forecast_1epoch',\n",
       "       'one_timestep_forecast_1epoch_static',\n",
       "       'one_timestep_forecast_20epoch',\n",
       "       'one_timestep_forecast_20epoch_static',\n",
       "       'one_timestep_forecast_ORIGINAL'], dtype='<U39')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(sorted([d.name for d in (data_dir / \"models/\").glob(\"*timestep*\")]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.array(sorted([d.name for d in (data_dir / \"features/one_timestep_forecast\").glob(\"*\")]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT =      '2020_04_15:095841_one_timestep_forecast'\n",
    "TRUE_EXPERIMENT = 'one_timestep_forecast'\n",
    "TARGET_VAR =      'discharge_spec'\n",
    "N_EPOCHS = 100\n",
    "\n",
    "assert (data_dir / f\"models/{EXPERIMENT}\").exists()\n",
    "assert (data_dir / f\"features/{TRUE_EXPERIMENT}\").exists()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the Dynamic DataLoader\n",
      "\tTarget Var: discharge_spec\n",
      "\tTest Years: [2011 2012 2013 2014 2015 2016]\n"
     ]
    }
   ],
   "source": [
    "# read in model\n",
    "ealstm = load_model(data_dir / f'models/{EXPERIMENT}/ealstm/model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading all .nc files from: data/models/2020_04_15:095841_one_timestep_forecast/ealstm\n",
      "All datasets loaded. Now combining ...\n"
     ]
    }
   ],
   "source": [
    "# read in model predictions\n",
    "ealstm_pred = read_pred_data('ealstm', data_dir, experiment=EXPERIMENT)\n",
    "ealstm_pred['station_id'] = ealstm_pred['station_id'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>&lt;xarray.Dataset&gt;\n",
       "Dimensions:              (station_id: 13, time: 16436)\n",
       "Coordinates:\n",
       "  * station_id           (station_id) int64 12002 15006 27009 ... 71001 84013\n",
       "  * time                 (time) datetime64[ns] 1970-10-01 ... 2015-09-30\n",
       "Data variables:\n",
       "    precipitation        (time, station_id) float64 ...\n",
       "    temperature          (time, station_id) float64 ...\n",
       "    discharge_spec       (time, station_id) float64 ...\n",
       "    peti                 (time, station_id) float64 ...\n",
       "    humidity             (time, station_id) float64 ...\n",
       "    shortwave_rad        (time, station_id) float64 ...\n",
       "    longwave_rad         (time, station_id) float64 ...\n",
       "    windspeed            (time, station_id) float64 ...\n",
       "    target_var_original  (time, station_id) float64 ...</pre>"
      ],
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:              (station_id: 13, time: 16436)\n",
       "Coordinates:\n",
       "  * station_id           (station_id) int64 12002 15006 27009 ... 71001 84013\n",
       "  * time                 (time) datetime64[ns] 1970-10-01 ... 2015-09-30\n",
       "Data variables:\n",
       "    precipitation        (time, station_id) float64 ...\n",
       "    temperature          (time, station_id) float64 ...\n",
       "    discharge_spec       (time, station_id) float64 ...\n",
       "    peti                 (time, station_id) float64 ...\n",
       "    humidity             (time, station_id) float64 ...\n",
       "    shortwave_rad        (time, station_id) float64 ...\n",
       "    longwave_rad         (time, station_id) float64 ...\n",
       "    windspeed            (time, station_id) float64 ...\n",
       "    target_var_original  (time, station_id) float64 ..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in the training data\n",
    "ds = xr.open_dataset(Path(f'data/features/{TRUE_EXPERIMENT}/data.nc'))\n",
    "\n",
    "# static_ds = xr.open_dataset(Path(f'data/features/static/data.nc'))\n",
    "all_static = xr.open_dataset(Path(f'data/interim/static/data.nc'))\n",
    "all_static['station_id'] = all_static['station_id'].astype(int)\n",
    "static_ds = all_static.drop(ealstm.static_ignore_vars)\n",
    "\n",
    "ds['station_id'] = ds['station_id'].astype(int)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the observed y_test\n",
    "times = ealstm_pred.time.values\n",
    "station_ids = ealstm_pred.station_id.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "** N Stations ignored: 0 **\n",
      "\n",
      "[] \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n** N Stations ignored: {ds.station_id.shape[0] - len(station_ids)} **\\n\")\n",
    "\n",
    "ignored_stations = sorted([st for st in ds.station_id.values if st not in station_ids])\n",
    "names = all_static.sel(station_id=ignored_stations)['gauge_name'].values\n",
    "print(np.array([f\"{i}: {nm}\" for i, nm in zip(ignored_stations, names)]), \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0014188763793992218, 1.1003196832674753\n",
      "1.4362033605575562, 1.5984694957733154\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'pred_da coordinates'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Coordinates:\n",
       "  * station_id  (station_id) int64 12002 15006 27009 27034 ... 54057 71001 84013\n",
       "  * time        (time) datetime64[ns] 2011-01-01 2011-01-02 ... 2015-09-30"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'true_da coordinates'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Coordinates:\n",
       "  * station_id  (station_id) int64 12002 15006 27009 27034 ... 54057 71001 84013\n",
       "  * time        (time) datetime64[ns] 2011-01-01 2011-01-02 ... 2015-09-30"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the predicted and true data\n",
    "# 'target_var_original' 'discharge_spec'\n",
    "y_test = ds[TARGET_VAR].sel(station_id=station_ids).sel(time=times)\n",
    "true_da = y_test\n",
    "\n",
    "# pred_da = np.exp(ealstm_pred['preds']) - 0.001\n",
    "pred_da = ealstm_pred['preds']\n",
    "\n",
    "print(f\"{true_da.mean().values}, {true_da.std().values}\")\n",
    "print(f\"{pred_da.mean().values}, {pred_da.std().values}\")\n",
    "\n",
    "# check that they are more or less correctly transformed\n",
    "# assert np.isclose(true_da.mean().values, pred_da.mean().values, atol=0.1)\n",
    "# assert np.isclose(true_da.std().values, pred_da.std().values, atol=0.4)\n",
    "\n",
    "print('\\n')\n",
    "display(\"pred_da coordinates\", pred_da.coords)\n",
    "display(\"true_da coordinates\", true_da.coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>discharge_spec</th>\n",
       "      <th>preds</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-01-01</th>\n",
       "      <td>12002</td>\n",
       "      <td>1.188148</td>\n",
       "      <td>2.360405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-02</th>\n",
       "      <td>12002</td>\n",
       "      <td>0.647627</td>\n",
       "      <td>2.197551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-03</th>\n",
       "      <td>12002</td>\n",
       "      <td>0.483043</td>\n",
       "      <td>2.019991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-04</th>\n",
       "      <td>12002</td>\n",
       "      <td>0.458058</td>\n",
       "      <td>2.079992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-05</th>\n",
       "      <td>12002</td>\n",
       "      <td>0.470628</td>\n",
       "      <td>2.361119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            station_id  discharge_spec     preds\n",
       "time                                            \n",
       "2011-01-01       12002        1.188148  2.360405\n",
       "2011-01-02       12002        0.647627  2.197551\n",
       "2011-01-03       12002        0.483043  2.019991\n",
       "2011-01-04       12002        0.458058  2.079992\n",
       "2011-01-05       12002        0.470628  2.361119"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# join the true and the pred data into one pd.DataFrame\n",
    "df = (\n",
    "    join_true_pred_da(\n",
    "        true_da, pred_da\n",
    "    ).to_dataframe()\n",
    "    .reset_index()\n",
    "    .set_index('time')\n",
    ")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the model training features\n",
    "LOGY = False\n",
    "ljust = 30\n",
    "\n",
    "print(\n",
    "    \"\", \"MODEL NAME: \".ljust(ljust), f\"{EXPERIMENT}\\n\",\n",
    "    \"Target Var: \".ljust(ljust), f\"{ealstm.target_var}\\n\",\n",
    "    \"Log y: \".ljust(ljust), f\"{LOGY}\\n\",\n",
    "    \"Normalize y: \".ljust(ljust), f\"{ealstm.normalize_y}\\n\",\n",
    "    \"Train Years: \".ljust(ljust), f\"{ds['time.year'].min().values}: {min(ealstm.test_years) -1}\\n\",\n",
    "    \"Test Years: \".ljust(ljust), f\"{[y for y in ealstm.test_years if y in ds['time.year'].values]}\\n\",\n",
    "    \"N Stations: \".ljust(ljust), f\"{len(df.station_id.unique())}\\n\",\n",
    "    \"Dynamic Variables: \".ljust(ljust), f\"{[v for v in list(ds.data_vars) if v not in list(set(ealstm.dynamic_ignore_vars))]}\\n\",\n",
    "    \"Static Variables: \".ljust(ljust), f\"{list(static_ds.data_vars)}\\n\", \n",
    "    \"Sequence Length: \".ljust(ljust), f\"{ealstm.seq_length}\\n\", \n",
    "    \"Final Linear Layer size: \".ljust(ljust), f\"{ealstm.dense_features}\\n\", \n",
    "    \"Static Embedding Size: \".ljust(ljust), f\"{ealstm.static_embedding_size}\\n\", \n",
    "    \"Num Epochs: \".ljust(ljust), f\"{N_EPOCHS}\\n\", \n",
    "#     \"VAR: \".ljust(ljust), f\"{VAR}\\n\", \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run performance metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.analysis.evaluation import (r2_score, rmse, spatial_rmse, spatial_r2, spatial_nse)\n",
    "from src.analysis.evaluation import temporal_rmse, temporal_r2, temporal_nse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate performance for each station (collapse time)\n",
    "rmse_da = spatial_rmse(y_test, pred_da)\n",
    "r2_da = spatial_r2(y_test, pred_da)\n",
    "nse_da = spatial_nse(y_test, pred_da)\n",
    "\n",
    "# calculate performance for each station (collapse space)\n",
    "rmse_time = temporal_rmse(y_test, pred_da)\n",
    "r2_time = temporal_r2(y_test, pred_da)\n",
    "nse_time = temporal_nse(y_test, pred_da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Mean Station RMSE: {rmse_da.mean().values:.2f}\")\n",
    "print(f\"Mean Station NSE: {(nse_da.where(nse_da > -np.inf)).mean().values:.2f}\")\n",
    "print(f\"Mean Station R2: {r2_da.mean().values:.2f}\")\n",
    "\n",
    "print(f\"\\n\\nMean Time RMSE: {rmse_time.mean().values:.2f}\")\n",
    "print(f\"Mean Time NSE: {nse_time.mean().values:.2f}\")\n",
    "print(f\"Mean Time R2: {r2_time.mean().values:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rmse and r2 df\n",
    "metrics_df = rmse_da.to_dataframe().drop(columns='time').rename(columns={\"preds\": \"rmse\"}).join(\n",
    "    r2_da.to_dataframe().drop(columns='time').rename(columns={\"preds\": \"r2\"})\n",
    ")\n",
    "metrics_df = metrics_df.join(\n",
    "    nse_da.to_dataframe().rename(columns={\"preds\": \"nse\"})\n",
    ")\n",
    "\n",
    "metrics_df = metrics_df.reset_index()\n",
    "metrics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEMPORAL rmse and r2 df\n",
    "metrics_time = rmse_time.to_dataframe().rename(columns={TARGET_VAR: \"rmse\"}).join(\n",
    "    r2_time.to_dataframe().rename(columns={TARGET_VAR: \"r2\"})\n",
    ")\n",
    "metrics_time = metrics_time.join(\n",
    "    nse_time.to_dataframe().rename(columns={TARGET_VAR: \"nse\"})\n",
    ")\n",
    "\n",
    "metrics_time = metrics_time.reset_index()\n",
    "metrics_time['time'] = [pd.to_datetime(t) for t in metrics_time.time]\n",
    "metrics_time.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nse_df = nse_da.sortby(nse_da).to_dataframe().reset_index().dropna()\n",
    "\n",
    "# replace the negative infinity value\n",
    "# nse_df['error'] = (nse_df.preds == -np.inf)\n",
    "# nse_df.loc[nse_df.preds == -np.inf, \"preds\"] = -125\n",
    "\n",
    "# ignore the negative infinity value\n",
    "# nse_df = nse_df.loc[nse_df.preds != -np.inf]\n",
    "\n",
    "# get cumsum of index\n",
    "nse_df['index'] = nse_df.index\n",
    "\n",
    "nse_df['negative'] = nse_df.preds < 0\n",
    "\n",
    "nse_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = nse_df.loc[nse_df['preds'] >= -0.1]\n",
    "median_nse = nse_df.loc[nse_df.preds != -np.inf, 'preds'].median()\n",
    "\n",
    "scale = 0.7\n",
    "fig, ax = plt.subplots(figsize=(12*scale, 8*scale))\n",
    "\n",
    "# plot the points\n",
    "sns.lineplot(x='preds', y='index', ax=ax, data=data)\n",
    "sns.scatterplot(x='preds', y='index', hue='negative', x_jitter=2, ax=ax, data=data, alpha=1, legend=False)\n",
    "\n",
    "ymax=nse_df['index'].max()\n",
    "ax.axvline(median_nse, ymin=0, ymax=ymax, color='k', ls='--', label='Median NSE', alpha=0.7)\n",
    "\n",
    "# beautify the plot\n",
    "ax.set_ylim(-5, ymax*1.1)\n",
    "ax.set_xlim(-0.1, 1)\n",
    "\n",
    "ax.legend()\n",
    "\n",
    "ax.set_title(f'Station NSE - Median: {median_nse:.2f}\\n{nse_df.negative.sum()} Stations with negative NSE')\n",
    "ax.set_xlabel('NSE')\n",
    "ax.set_ylabel('Cumulative Number of Stations');\n",
    "\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join to make geographical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "shp_path = Path(\n",
    "    \"/home/jovyan/runoff_uk_lstm/data/CAMELS/CAMELS_GB_DATASET/Catchment_Boundaries/CAMELS_GB_catchment_boundaries.shp\"\n",
    ")\n",
    "shp_path.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the shapefile\n",
    "geo_df = gpd.read_file(shp_path)\n",
    "geo_df['ID_STRING'] = geo_df['ID_STRING'].astype('int')\n",
    "geo_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create spatial dataframe\n",
    "assert metrics_df['station_id'].dtype == geo_df['ID_STRING'].dtype, \"Need to be the same type (integer)\"\n",
    "metrics_gdf = gpd.GeoDataFrame(\n",
    "    geo_df.set_index('ID_STRING').join(metrics_df.set_index('station_id'))\n",
    ")\n",
    "metrics_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = metrics_gdf.plot('rmse', legend=True)\n",
    "ax.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15, 8))\n",
    "opts = [\n",
    "    {\"vmin\": 0, \"vmax\": 0.8, 'cmap': 'viridis'},   # rmse   \n",
    "    {\"vmin\": 0, \"vmax\": 1, 'cmap': 'viridis_r'},    # nse   \n",
    "    {\"vmin\": 0, \"vmax\": 1, 'cmap': 'viridis_r'}    # r2  \n",
    "]\n",
    "\n",
    "for ix, metric in enumerate([\"rmse\", \"nse\", \"r2\"]):\n",
    "    ax = axs[ix]\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.2) # depends on the user needs\n",
    "\n",
    "    # legend_kwargs = {'label': metric.upper(), 'orientation': 'horizontal'}\n",
    "    metrics_gdf.plot(\n",
    "        column=metric, ax=ax, \n",
    "        cmap=opts[ix]['cmap'],legend=True, cax=cax,\n",
    "        vmin=opts[ix]['vmin'], vmax=opts[ix]['vmax'],\n",
    "    )  #, legend_kwds=legend_kwargs)\n",
    "\n",
    "    ax.set_title(f'{metric.upper()}')\n",
    "\n",
    "    ax.axis('off');\n",
    "\n",
    "fig.tight_layout(rect=[0, 0.03, 1, 0.965])\n",
    "fig.suptitle(\"Model Error\", size=14);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crooks and Martinez stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catchment_ids = [\"12002\", \"15006\", \"27009\", \"27034\", \"27041\", \"39001\",\n",
    "                 \"39081\", \"43021\", \"47001\", \"54001\", \"54057\", \"71001\", \"84013\", ]\n",
    "catchment_ids = [int(c_id) for c_id in catchment_ids]\n",
    "catchment_names = [\"Dee@Park\", \"Tay@Ballathie\", \"Ouse@Skelton\", \"Ure@Kilgram\", \"Derwent@Buttercrambe\", \"Thames@Kingston\",\n",
    "                   \"Ock@Abingdon\", \"Avon@Knapp\", \"Tamar@Gunnislake\", \"Severn@Bewdley\", \"Severn@Haw\", \"Ribble@Samlesbury\", \"Clyde@Daldowie\"]\n",
    "station_map = dict(zip(catchment_ids, catchment_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_catchment_ids = [c for (ix, c) in enumerate(catchment_ids) if c in ealstm_pred.station_id.values]\n",
    "valid_station_name = np.array(catchment_names)[[ix for (ix, c) in enumerate(catchment_ids) if c in ealstm_pred.station_id.values]]\n",
    "# for ix, (station_id, station_name) in enumerate(zip(valid_catchment_ids, valid_station_name)):\n",
    "#     print(f\"{station_name} ID: {station_id}\")\n",
    "#     print(f\"\\tRMSE: {rmse_da.sel(station_id=station_id).values:.2f}\")\n",
    "#     print(f\"\\tNSE: {nse_da.sel(station_id=station_id).values:.2f}\")\n",
    "#     print(f\"\\tR2: {r2_da.sel(station_id=station_id).values:.2f}\")\n",
    "#     print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = gpd.GeoDataFrame(\n",
    "    geo_df.set_index('ID_STRING')\n",
    "    .join(all_static[['gauge_name', 'gauge_lat', 'gauge_lon']]\n",
    "    .to_dataframe())\n",
    ")\n",
    "metrics_gdf = metadata.join(metrics_df.set_index('station_id'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 15))\n",
    "\n",
    "geo_df.plot(ax=ax, color='grey')\n",
    "metadata.loc[np.isin(metadata.index, valid_catchment_ids)].plot(\n",
    "    'gauge_name', ax=ax, edgecolor='k', color=None, legend=True,\n",
    ")\n",
    "\n",
    "ax.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_invalid_vals(x, y) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"check for infinite or nan values\n",
    "    \n",
    "    Required for np.polyfit:\n",
    "    https://stackoverflow.com/a/13693657/9940782\n",
    "    \"\"\"\n",
    "    isfinite = np.isfinite(y) & np.isfinite(x)\n",
    "    notnull = pd.notnull(y) & pd.notnull(x)\n",
    "    \n",
    "    x = x[isfinite & notnull]\n",
    "    y = y[isfinite & notnull]\n",
    "    \n",
    "    return x, y\n",
    "    \n",
    "\n",
    "def plot_scatter(x: np.ndarray, y: np.ndarray, ax, one_to_one: bool = True, **kwargs) -> plt.Axes:\n",
    "    \"\"\"Scatter plot of x vs. y\"\"\"\n",
    "    # plot scatter\n",
    "    ax.plot(x, y, 'kx', **kwargs)\n",
    "    \n",
    "    if one_to_one:\n",
    "        # plot 1:1 line\n",
    "        line_1_1_x = np.linspace(x.min(), x.max(), 10)\n",
    "        ax.plot(line_1_1_x, line_1_1_x, 'k--', label='1:1 Line', alpha=0.5)\n",
    "\n",
    "    return ax\n",
    "\n",
    "\n",
    "def plot_reg_line(x: np.ndarray, y: np.ndarray, ax, label: bool = True, **kwargs):\n",
    "    \"\"\"plot linear regression line of x vs. y\"\"\"\n",
    "    # plot regression line\n",
    "    x, y = remove_invalid_vals(x, y)\n",
    "    m, b = np.polyfit(x, y, 1)\n",
    "    reg = (m * x + b)\n",
    "    if label:\n",
    "        label = f'Regression Line: {m:.2f}'\n",
    "        ax.plot(x, reg, ls='--', label=label, **kwargs)\n",
    "    else:\n",
    "        ax.plot(x, reg, ls='--', **kwargs)\n",
    "\n",
    "    return ax\n",
    "\n",
    "\n",
    "def plot_station_scatter(\n",
    "    df: pd.DataFrame, station_id: str, metrics_df: Optional[pd.DataFrame] = None, ax=None,\n",
    "    target_var: str = 'discharge_spec',\n",
    "    station_name: Optional[str] = None\n",
    "):\n",
    "    # select station & data\n",
    "    d = df.query(f\"station_id == '{station_id}'\").drop(columns='station_id')\n",
    "    x = d[target_var]\n",
    "    y = d.preds\n",
    "    \n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    else:\n",
    "        fig = plt.gcf()\n",
    "    \n",
    "    # plot scatter\n",
    "    kwargs = dict(alpha=0.6, label='Data Point')\n",
    "    ax = plot_scatter(x, y, ax, **kwargs)\n",
    "\n",
    "    # plot regression line\n",
    "    kwargs = dict(color = '#7bd250')\n",
    "    ax = plot_reg_line(x, y, ax, **kwargs)\n",
    "\n",
    "    # make the plot pretty\n",
    "    ax.set_xlabel('Observed')\n",
    "    ax.set_ylabel('Predicted')\n",
    "    title = f'Station {station_id}' + f\" {station_name}\" if station_name is not None else f'Station {station_id}'\n",
    "    ax.set_title(title)\n",
    "\n",
    "    ax.legend();\n",
    "    \n",
    "    if False:\n",
    "        # making the plot pretty\n",
    "        for item in ([ax.title, ax.xaxis.label, ax.yaxis.label]\n",
    "                          + ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "                item.set_fontsize(12)\n",
    "\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    \n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "def plot_station(\n",
    "    df: pd.DataFrame, \n",
    "    station_id: str, \n",
    "    metrics_df: Optional[pd.DataFrame] = None, \n",
    "    ax=None,\n",
    "    station_name: Optional[str] = None,\n",
    "    plot_years: Optional[List[int]] = None,\n",
    "):\n",
    "    \"\"\"Plot the Observed vs. Preds for the station_id\"\"\"\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    else:\n",
    "        fig = plt.gcf()\n",
    "    \n",
    "    # plot the station\n",
    "    if plot_years is None:\n",
    "        df.query(f\"station_id == '{station_id}'\").drop(columns='station_id').plot(ax=ax)\n",
    "    else:\n",
    "        (\n",
    "            df.loc[np.isin(df.index.year, plot_years)]\n",
    "            .query(f\"station_id == '{station_id}'\")\n",
    "            .drop(columns='station_id').plot(ax=ax)\n",
    "        )\n",
    "    \n",
    "    # get the error metrics\n",
    "    rmse_val = metrics_df.query(f\"station_id == '{station_id}'\").rmse.values[0]\n",
    "    r2_val = metrics_df.query(f\"station_id == '{station_id}'\").r2.values[0]\n",
    "    nse_val = metrics_df.query(f\"station_id == '{station_id}'\").nse.values[0]\n",
    "    # set the title\n",
    "    station_title = f\"{station_id} {station_name}\" if station_name is not None else station_id\n",
    "    ax.set_title(f\"{station_title}\\nRMSE: {rmse_val:.2f} R2: {r2_val:.2f} NSE: {nse_val:.2f}\")\n",
    "    \n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_stations = ['22007', '27049', '28018', '31021', '31023', '34004', '35003', '39022', '41029', '51001', '55025', '57004', '83010']\n",
    "catchment_ids = [\"12002\", \"15006\", \"27009\", \"27034\", \"27041\", \"39001\", \"39081\", \"43021\", \"47001\", \"54001\", \"54057\", \"71001\", \"84013\",]\n",
    "catchment_names = [\"Dee@Park\", \"Tay@Ballathie\", \"Ouse@Skelton\", \"Ure@Kilgram\", \"Derwent@Buttercrambe\", \"Thames@Kingston\", \"Ock@Abingdon\", \"Avon@Knapp\", \"Tamar@Gunnislake\", \"Severn@Bewdley\", \"Severn@Haw\", \"Ribble@Samlesbury\", \"Clyde@Daldowie\"]\n",
    "station_map = dict(zip(catchment_ids, catchment_names))\n",
    "\n",
    "plot_years = [2011]\n",
    "scale = 0.8\n",
    "fig, axs = plt.subplots(13, 2, figsize=(12*scale, 6*scale*13))\n",
    "\n",
    "for ix, (station_id, station_name) in enumerate(zip(catchment_ids, catchment_names)):\n",
    "#     fig, axs = plt.subplots(1, 2, figsize=(12*scale, 6*scale))\n",
    "    try:\n",
    "        plot_station(df, station_id, metrics_df, ax=axs[ix, 0], station_name=station_name, plot_years=plot_years)\n",
    "        plot_station_scatter(df, station_id, metrics_df, axs[ix, 1])\n",
    "    except TypeError:\n",
    "        print(f\"** {station_name} data does not exist in the predictions! **\")\n",
    "        \n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ix, (station_id, station_name) in enumerate(zip(catchment_ids, catchment_names)):\n",
    "    rmse_val = metrics_df.query(f\"station_id == '{station_id}'\").rmse.values[0]\n",
    "    r2_val = metrics_df.query(f\"station_id == '{station_id}'\").r2.values[0]\n",
    "    nse_val = metrics_df.query(f\"station_id == '{station_id}'\").nse.values[0]\n",
    "    # set the title\n",
    "    station_title = f\"{station_id} {station_name}\" if station_name is not None else station_id\n",
    "    print(\n",
    "        f\"{station_title}\".ljust(30), \n",
    "        f\"-- RMSE: {rmse_val:.2f} -- R2: {r2_val:.2f} -- NSE: {nse_val:.2f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crooks_gdf = metrics_gdf.loc[np.isin(metrics_gdf.index, [int(c) for c in catchment_ids])]\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15, 15))\n",
    "\n",
    "for ax in axs:\n",
    "    metrics_gdf.plot(ax=ax, color='grey')\n",
    "    ax.axis('off')\n",
    "\n",
    "divider = make_axes_locatable(axs[0])\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.2) # depends on the user needs\n",
    "crooks_gdf.plot('rmse', ax=axs[0], legend=True, cax=cax, cmap='viridis')\n",
    "axs[0].set_title(f\"RMSE: {crooks_gdf['rmse'].mean():.2f}\")\n",
    "\n",
    "divider = make_axes_locatable(axs[1])\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.2) # depends on the user needs\n",
    "crooks_gdf.plot('nse', legend=True, ax=axs[1], cax=cax, cmap='viridis_r', vmin=0, vmax=0.6)\n",
    "axs[1].set_title(f\"NSE: {crooks_gdf['nse'].mean():.2f}\")\n",
    "\n",
    "divider = make_axes_locatable(axs[2])\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.2) # depends on the user needs\n",
    "crooks_gdf.plot('r2', legend=True, ax=axs[2], cax=cax, cmap='viridis_r', vmin=0, vmax=1)\n",
    "axs[2].set_title(f\"R2: {crooks_gdf['r2'].mean():.2f}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get vars on keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.preprocess._camels_static_metadata import (get_var_on_dtype, get_vars_on_keywords, get_vars_on_grouping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_ds.data_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_vars_on_keywords(all_static, 'lat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = ealstm.get_dataloader('train')\n",
    "type(dl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dl.__iter__().__next__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_mask = len(dl.valid_train_times)\n",
    "len_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.data import train_val_mask\n",
    "train_mask, val_mask = train_val_mask(len_mask, 0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measure model bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias = 100 * ((pred_da / true_da) - 1)\n",
    "bias.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bias.mean(dim='time').mean())\n",
    "print(bias.mean(dim='station_id').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nse_da.where(nse_da > -np.inf).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nse_df = nse_da.sortby(nse_da).to_dataframe().reset_index().dropna()\n",
    "\n",
    "# replace the negative infinity value\n",
    "# nse_df['error'] = (nse_df.preds == -np.inf)\n",
    "# nse_df.loc[nse_df.preds == -np.inf, \"preds\"] = -125\n",
    "\n",
    "# ignore the negative infinity value\n",
    "# nse_df = nse_df.loc[nse_df.preds != -np.inf]\n",
    "\n",
    "# get cumsum of index\n",
    "nse_df['index'] = nse_df.index\n",
    "\n",
    "nse_df['negative'] = nse_df.preds < 0\n",
    "\n",
    "nse_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series([i+1 for i in nse_df.index]).rolling(window=1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
