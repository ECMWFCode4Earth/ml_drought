{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run EALSTM with 365 days of input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "/home/jovyan/ml_drought\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# ignore warnings for now ...\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "if Path('.').absolute().parents[1].name == 'ml_drought':\n",
    "    os.chdir(Path('.').absolute().parents[1])\n",
    "\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import torch\n",
    "\n",
    "from typing import List, Union, Optional, Tuple, Dict\n",
    "\n",
    "data_dir = Path('data/')\n",
    "# data_dir = Path('/Volumes/Lees_Extend/data/zip_data')\n",
    "# data_dir = Path('/Volumes/Lees_Extend/data/ecmwf_sowc/data/')\n",
    "# plot_dir = Path('/Users/tommylees/Downloads')\n",
    "\n",
    "assert data_dir.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from src.utils import drop_nans_and_flatten\n",
    "\n",
    "from src.analysis import read_train_data, read_test_data, read_pred_data\n",
    "from src.analysis.evaluation import join_true_pred_da\n",
    "from src.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "['GABI_tEONLY_one_month_forecast_BOKU_VCI3M_our_vars_only_P_VCI', '2020_04_13:090536_one_timestep_forecast', 'one_month_forecast_BOKU_VCI3M_our_vars_only_P_VCI', 'one_month_forecast', 'one_month_forecast_RNN_predict_delta_norm_y_latlons_128', 'enso_robustness_boku_VCI_randomFalse', 'GABI_EXHAUSTED_one_month_forecast_BOKU_VCI3M_our_vars_only_P_VCI', '2020_04_13:171738_one_timestep_forecast', 'ealstm_omf_static_embedding', 'one_month_forecast_adede_only_target_VCI1M', 'robustness_boku_VCI', 'one_month_forecast_RNN_predict_delta_norm_y_prev_y_latlons_128', 'GABI_PEVtEONLY_es20_one_month_forecast_BOKU_VCI3M_our_vars_only_P_VCI', 'one_timestep_forecast_20epoch', '2020_02_17:123856_one_month_forecast_boku_VCI_precip_t2m_pet_E_SMroot_SMsurf_YESstatic_boku_VCI', 'one_month_forecast_RNN_predict_delta_norm_y_pass_prev_latlons', 'GABI_tEONLY_es10_one_month_forecast_BOKU_VCI3M_our_vars_only_P_VCI', '2020_04_13:155432_one_timestep_forecast', 'one_month_forecast_BOKU_boku_VCI_our_vars', 'ICLR_one_month_forecast_BOKU_boku_VCI_our_vars_ALL', 'one_month_forecast_BOKU_VCI1M_adede_only_vars', 'ICLR_one_month_forecast_BOKU_boku_VCI_our_vars_only_P_VCI', 'one_month_forecast_BASE_adede_vars_our_vars', 'one_month_forecast_BASE', '2020_02_14:090033_one_month_forecast_VCI_NOstatic_VCI', '2020_04_13:144437_one_timestep_forecast', '2020_04_07:171723_one_timestep_forecast', 'one_month_forecast_adede_only_target_VCI3M', '0_TEST_branch', '02_training_periods', 'one_month_forecast_RNN_predict_delta_norm_y_latlons', '.ipynb_checkpoints', 'one_timestep_forecast', 'one_month_forecast_VCI3M', '2020_02_14:085848_one_month_forecast_boku_VCI_precip_t2m_pet_E_SMroot_SMsurf_YESstatic_boku_VCI', '2020_02_14:084457_one_month_forecast_boku_VCI_NOstatic_boku_VCI', 'one_month_forecast_predict_delta_norm_y_latlons', '2020_02_14:085012_one_month_forecast_boku_VCI_precip_t2m_pet_E_SMroot_SMsurf_NOstatic_boku_VCI', 'one_month_forecast_RNN_v2_predict_delta_norm_y_latlons_256', 'one_month_forecast_predict_delta_ASAL_128', 'one_month_forecast_predict_delta', '2020_02_17:123014_one_month_forecast_boku_VCI_precip_t2m_pet_E_SMroot_SMsurf_NOstatic_boku_VCI', 'static_one_month_forecast', 'one_month_forecast_BOKU_VCI1M', 'one_month_forecast_BOKU_VCI3M_our_vars', 'one_month_forecast_BOKU_boku_VCI', 'variable_expts', 'one_month_forecast_predict_delta_norm_y_pass_prev_latlons', '2020_01_13:151544_nowcast_tommy', '2020_01_13:171421_nowcast_tommy', 'GABI_es20_one_month_forecast_BOKU_VCI3M_our_vars_ALL', 'one_timestep_forecast_ORIGINAL', 'one_timestep_forecast_20epoch_static', 'one_month_forecast_predict_delta_ASAL_tile2vec', 'one_month_forecast_unsupervised_warmup', '2020_02_17:122024_one_month_forecast_boku_VCI_NOstatic_boku_VCI', '2020_04_13:091211_one_timestep_forecast', 'one_timestep_forecast_1epoch', 'one_month_forecast_ASAL', 'one_month_forecast_NO_VCI', 'GABI_one_month_forecast_BOKU_VCI3M_our_vars_only_P_VCI', 'one_timestep_forecast_1epoch_static', 'ICLR_one_month_forecast_BOKU_VCI3M_our_vars_only_P_VCI', 'enso_robustness_boku_VCI_randomTrue', 'GABI_AGAIN_one_month_forecast_BOKU_VCI3M_our_vars_only_P_VCI', '2020_02_14:090510_one_month_forecast_VCI_precip_t2m_pet_E_SMroot_SMsurf_NOstatic_VCI', 'one_month_forecast_BOKU_VCI3M_adede_only_vars', 'one_month_forecast_BASE_static_vars', '2020_01_14:154939_nowcast_tommy', 'one_month_forecast_predict_delta_ASAL', 'one_timestep_forecast_19epoch_static', 'ICLR_one_month_forecast_BOKU_VCI3M_our_vars_ALL', 'old', 'one_month_forecast_BOKU_VCI3M', '2020_02_14:091317_one_month_forecast_VCI_precip_t2m_pet_E_SMroot_SMsurf_YESstatic_VCI']"
      ],
      "text/plain": [
       "['GABI_tEONLY_one_month_forecast_BOKU_VCI3M_our_vars_only_P_VCI',\n",
       " '2020_04_13:090536_one_timestep_forecast',\n",
       " 'one_month_forecast_BOKU_VCI3M_our_vars_only_P_VCI',\n",
       " 'one_month_forecast',\n",
       " 'one_month_forecast_RNN_predict_delta_norm_y_latlons_128',\n",
       " 'enso_robustness_boku_VCI_randomFalse',\n",
       " 'GABI_EXHAUSTED_one_month_forecast_BOKU_VCI3M_our_vars_only_P_VCI',\n",
       " '2020_04_13:171738_one_timestep_forecast',\n",
       " 'ealstm_omf_static_embedding',\n",
       " 'one_month_forecast_adede_only_target_VCI1M',\n",
       " 'robustness_boku_VCI',\n",
       " 'one_month_forecast_RNN_predict_delta_norm_y_prev_y_latlons_128',\n",
       " 'GABI_PEVtEONLY_es20_one_month_forecast_BOKU_VCI3M_our_vars_only_P_VCI',\n",
       " 'one_timestep_forecast_20epoch',\n",
       " '2020_02_17:123856_one_month_forecast_boku_VCI_precip_t2m_pet_E_SMroot_SMsurf_YESstatic_boku_VCI',\n",
       " 'one_month_forecast_RNN_predict_delta_norm_y_pass_prev_latlons',\n",
       " 'GABI_tEONLY_es10_one_month_forecast_BOKU_VCI3M_our_vars_only_P_VCI',\n",
       " '2020_04_13:155432_one_timestep_forecast',\n",
       " 'one_month_forecast_BOKU_boku_VCI_our_vars',\n",
       " 'ICLR_one_month_forecast_BOKU_boku_VCI_our_vars_ALL',\n",
       " 'one_month_forecast_BOKU_VCI1M_adede_only_vars',\n",
       " 'ICLR_one_month_forecast_BOKU_boku_VCI_our_vars_only_P_VCI',\n",
       " 'one_month_forecast_BASE_adede_vars_our_vars',\n",
       " 'one_month_forecast_BASE',\n",
       " '2020_02_14:090033_one_month_forecast_VCI_NOstatic_VCI',\n",
       " '2020_04_13:144437_one_timestep_forecast',\n",
       " '2020_04_07:171723_one_timestep_forecast',\n",
       " 'one_month_forecast_adede_only_target_VCI3M',\n",
       " '0_TEST_branch',\n",
       " '02_training_periods',\n",
       " 'one_month_forecast_RNN_predict_delta_norm_y_latlons',\n",
       " '.ipynb_checkpoints',\n",
       " 'one_timestep_forecast',\n",
       " 'one_month_forecast_VCI3M',\n",
       " '2020_02_14:085848_one_month_forecast_boku_VCI_precip_t2m_pet_E_SMroot_SMsurf_YESstatic_boku_VCI',\n",
       " '2020_02_14:084457_one_month_forecast_boku_VCI_NOstatic_boku_VCI',\n",
       " 'one_month_forecast_predict_delta_norm_y_latlons',\n",
       " '2020_02_14:085012_one_month_forecast_boku_VCI_precip_t2m_pet_E_SMroot_SMsurf_NOstatic_boku_VCI',\n",
       " 'one_month_forecast_RNN_v2_predict_delta_norm_y_latlons_256',\n",
       " 'one_month_forecast_predict_delta_ASAL_128',\n",
       " 'one_month_forecast_predict_delta',\n",
       " '2020_02_17:123014_one_month_forecast_boku_VCI_precip_t2m_pet_E_SMroot_SMsurf_NOstatic_boku_VCI',\n",
       " 'static_one_month_forecast',\n",
       " 'one_month_forecast_BOKU_VCI1M',\n",
       " 'one_month_forecast_BOKU_VCI3M_our_vars',\n",
       " 'one_month_forecast_BOKU_boku_VCI',\n",
       " 'variable_expts',\n",
       " 'one_month_forecast_predict_delta_norm_y_pass_prev_latlons',\n",
       " '2020_01_13:151544_nowcast_tommy',\n",
       " '2020_01_13:171421_nowcast_tommy',\n",
       " 'GABI_es20_one_month_forecast_BOKU_VCI3M_our_vars_ALL',\n",
       " 'one_timestep_forecast_ORIGINAL',\n",
       " 'one_timestep_forecast_20epoch_static',\n",
       " 'one_month_forecast_predict_delta_ASAL_tile2vec',\n",
       " 'one_month_forecast_unsupervised_warmup',\n",
       " '2020_02_17:122024_one_month_forecast_boku_VCI_NOstatic_boku_VCI',\n",
       " '2020_04_13:091211_one_timestep_forecast',\n",
       " 'one_timestep_forecast_1epoch',\n",
       " 'one_month_forecast_ASAL',\n",
       " 'one_month_forecast_NO_VCI',\n",
       " 'GABI_one_month_forecast_BOKU_VCI3M_our_vars_only_P_VCI',\n",
       " 'one_timestep_forecast_1epoch_static',\n",
       " 'ICLR_one_month_forecast_BOKU_VCI3M_our_vars_only_P_VCI',\n",
       " 'enso_robustness_boku_VCI_randomTrue',\n",
       " 'GABI_AGAIN_one_month_forecast_BOKU_VCI3M_our_vars_only_P_VCI',\n",
       " '2020_02_14:090510_one_month_forecast_VCI_precip_t2m_pet_E_SMroot_SMsurf_NOstatic_VCI',\n",
       " 'one_month_forecast_BOKU_VCI3M_adede_only_vars',\n",
       " 'one_month_forecast_BASE_static_vars',\n",
       " '2020_01_14:154939_nowcast_tommy',\n",
       " 'one_month_forecast_predict_delta_ASAL',\n",
       " 'one_timestep_forecast_19epoch_static',\n",
       " 'ICLR_one_month_forecast_BOKU_VCI3M_our_vars_ALL',\n",
       " 'old',\n",
       " 'one_month_forecast_BOKU_VCI3M',\n",
       " '2020_02_14:091317_one_month_forecast_VCI_precip_t2m_pet_E_SMroot_SMsurf_YESstatic_VCI']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[d.name for d in (data_dir / \"models/\").iterdir()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT =      '2020_04_07:171723_one_timestep_forecast'\n",
    "TRUE_EXPERIMENT = 'one_timestep_forecast'\n",
    "TARGET_VAR =      'discharge_spec'\n",
    "\n",
    "assert (data_dir / f\"models/{EXPERIMENT}\").exists()\n",
    "assert (data_dir / f\"features/{TRUE_EXPERIMENT}\").exists()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the Dynamic DataLoader\n",
      "\tTarget Var: discharge_spec\n",
      "\tTest Years: [2011 2012 2013 2014 2015 2016]\n"
     ]
    }
   ],
   "source": [
    "# read in model\n",
    "ealstm = load_model(data_dir / f'models/{EXPERIMENT}/ealstm/model.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading all .nc files from: data/models/2020_04_07:171723_one_timestep_forecast/ealstm\n",
      "All datasets loaded. Now combining ...\n"
     ]
    }
   ],
   "source": [
    "# read in model predictions\n",
    "ealstm_pred = read_pred_data('ealstm', data_dir, experiment=EXPERIMENT)\n",
    "ealstm_pred['station_id'] = ealstm_pred['station_id'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>&lt;xarray.Dataset&gt;\n",
       "Dimensions:         (station_id: 671, time: 16436)\n",
       "Coordinates:\n",
       "  * station_id      (station_id) int64 1001 2001 2002 ... 102001 106001 107001\n",
       "  * time            (time) datetime64[ns] 1970-10-01 1970-10-02 ... 2015-09-30\n",
       "Data variables:\n",
       "    precipitation   (time, station_id) float64 ...\n",
       "    temperature     (time, station_id) float64 ...\n",
       "    discharge_spec  (time, station_id) float64 ...\n",
       "    peti            (time, station_id) float64 ...\n",
       "    humidity        (time, station_id) float64 ...\n",
       "    shortwave_rad   (time, station_id) float64 ...\n",
       "    longwave_rad    (time, station_id) float64 ...\n",
       "    windspeed       (time, station_id) float64 ...</pre>"
      ],
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:         (station_id: 671, time: 16436)\n",
       "Coordinates:\n",
       "  * station_id      (station_id) int64 1001 2001 2002 ... 102001 106001 107001\n",
       "  * time            (time) datetime64[ns] 1970-10-01 1970-10-02 ... 2015-09-30\n",
       "Data variables:\n",
       "    precipitation   (time, station_id) float64 ...\n",
       "    temperature     (time, station_id) float64 ...\n",
       "    discharge_spec  (time, station_id) float64 ...\n",
       "    peti            (time, station_id) float64 ...\n",
       "    humidity        (time, station_id) float64 ...\n",
       "    shortwave_rad   (time, station_id) float64 ...\n",
       "    longwave_rad    (time, station_id) float64 ...\n",
       "    windspeed       (time, station_id) float64 ..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in the training data\n",
    "ds = xr.open_dataset(Path(f'data/features/{TRUE_EXPERIMENT}/data.nc'))\n",
    "\n",
    "# static_ds = xr.open_dataset(Path(f'data/features/static/data.nc'))\n",
    "all_static = xr.open_dataset(Path(f'data/interim/static/data.nc'))\n",
    "all_static['station_id'] = all_static['station_id'].astype(int)\n",
    "static_ds = all_static.drop(ealstm.static_ignore_vars)\n",
    "\n",
    "ds['station_id'] = ds['station_id'].astype(int)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the observed y_test\n",
    "times = ealstm_pred.time.values\n",
    "station_ids = ealstm_pred.station_id.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.038690107533828 3.6664953995713407\n",
      "-0.11442124 1.0627841\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-191d32e2fe18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# check that they are more or less correctly organised\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_da\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_da\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_da\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_da\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Get the predicted and true data\n",
    "# 'target_var_original'\n",
    "y_test = ds[TARGET_VAR].sel(station_id=station_ids).sel(time=times)\n",
    "true_da = y_test\n",
    "\n",
    "# pred_da = np.exp(ealstm_pred['preds']) - 0.001\n",
    "pred_da = ealstm_pred['preds']\n",
    "\n",
    "print(true_da.mean().values, true_da.std().values)\n",
    "print(pred_da.mean().values, pred_da.std().values)\n",
    "\n",
    "# check that they are more or less correctly organised\n",
    "assert np.isclose(true_da.mean().values, pred_da.mean().values, atol=0.1)\n",
    "assert np.isclose(true_da.std().values, pred_da.std().values, atol=0.4)\n",
    "\n",
    "print('\\n')\n",
    "display(\"pred_da coordinates\", pred_da.coords)\n",
    "display(\"true_da coordinates\", true_da.coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join the true and the pred data into one pd.DataFrame\n",
    "df = (\n",
    "    join_true_pred_da(\n",
    "        true_da, pred_da\n",
    "    ).to_dataframe()\n",
    "    .reset_index()\n",
    "    .set_index('time')\n",
    ")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# print the model training features\n",
    "logy=True\n",
    "ljust = 30\n",
    "\n",
    "print(\n",
    "    \"\", \"Target Var: \".ljust(ljust), f\"{ealstm.target_var}\\n\",\n",
    "    \"Log y: \".ljust(ljust), f\"{logy}\\n\",\n",
    "    \"Normalize y: \".ljust(ljust), f\"{ealstm.normalize_y}\\n\",\n",
    "    \"Train Years: \".ljust(ljust), f\"{ds['time.year'].min().values}: {min(ealstm.test_years) -1}\\n\",\n",
    "    \"Test Years: \".ljust(ljust), f\"{ealstm.test_years}\\n\",\n",
    "    \"N Stations: \".ljust(ljust), f\"{len(df.station_id.unique())}\\n\",\n",
    "    \"Dynamic Variables: \".ljust(ljust), f\"{[v for v in list(ds.data_vars) if v not in list(set(ealstm.dynamic_ignore_vars))]}\\n\",\n",
    "    \"Static Variables: \".ljust(ljust), f\"{list(static_ds.data_vars)}\\n\", \n",
    "    \"Sequence Length: \".ljust(ljust), f\"{ealstm.seq_length}\\n\", \n",
    "    \"Final Linear Layer size: \".ljust(ljust), f\"{ealstm.dense_features}\\n\", \n",
    "    \"Static Embedding Size: \".ljust(ljust), f\"{ealstm.static_embedding_size}\\n\", \n",
    "#     \"VAR: \".ljust(ljust), f\"{VAR}\\n\", \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run performance metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.analysis.evaluation import (r2_score, rmse, spatial_rmse, spatial_r2, spatial_nse)\n",
    "from src.analysis.evaluation import temporal_rmse, temporal_r2, temporal_nse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate performance for each station (collapse time)\n",
    "rmse_da = spatial_rmse(y_test, pred_da)\n",
    "r2_da = spatial_r2(y_test, pred_da)\n",
    "nse_da = spatial_nse(y_test, pred_da)\n",
    "\n",
    "# calculate performance for each station (collapse space)\n",
    "rmse_time = temporal_rmse(y_test, pred_da)\n",
    "r2_time = temporal_r2(y_test, pred_da)\n",
    "nse_time = temporal_nse(y_test, pred_da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Mean Station RMSE: {rmse_da.mean().values:.2f}\")\n",
    "print(f\"Mean Station NSE: {nse_da.mean().values:.2f}\")\n",
    "print(f\"Mean Station R2: {r2_da.mean().values:.2f}\")\n",
    "\n",
    "print(f\"\\n\\nMean Time RMSE: {rmse_time.mean().values:.2f}\")\n",
    "print(f\"Mean Time NSE: {nse_time.mean().values:.2f}\")\n",
    "print(f\"Mean Time R2: {r2_time.mean().values:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rmse and r2 df\n",
    "metrics_df = rmse_da.to_dataframe().drop(columns='time').rename(columns={\"preds\": \"rmse\"}).join(\n",
    "    r2_da.to_dataframe().drop(columns='time').rename(columns={\"preds\": \"r2\"})\n",
    ")\n",
    "metrics_df = metrics_df.join(\n",
    "    nse_da.to_dataframe().rename(columns={\"preds\": \"nse\"})\n",
    ")\n",
    "\n",
    "metrics_df = metrics_df.reset_index()\n",
    "metrics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEMPORAL rmse and r2 df\n",
    "metrics_time = rmse_time.to_dataframe().rename(columns={TARGET_VAR: \"rmse\"}).join(\n",
    "    r2_time.to_dataframe().rename(columns={TARGET_VAR: \"r2\"})\n",
    ")\n",
    "metrics_time = metrics_time.join(\n",
    "    nse_time.to_dataframe().rename(columns={TARGET_VAR: \"nse\"})\n",
    ")\n",
    "\n",
    "metrics_time = metrics_time.reset_index()\n",
    "metrics_time['time'] = [pd.to_datetime(t) for t in metrics_time.time]\n",
    "metrics_time.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nse_df = nse_da.sortby(nse_da).to_dataframe().reset_index().dropna()\n",
    "\n",
    "# replace the negative infinity value\n",
    "# nse_df['error'] = (nse_df.preds == -np.inf)\n",
    "# nse_df.loc[nse_df.preds == -np.inf, \"preds\"] = -125\n",
    "\n",
    "# ignore the negative infinity value\n",
    "# nse_df = nse_df.loc[nse_df.preds != -np.inf]\n",
    "\n",
    "# get cumsum of index\n",
    "nse_df['index'] = nse_df.index\n",
    "\n",
    "nse_df['negative'] = nse_df.preds < 0\n",
    "\n",
    "nse_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = nse_df.loc[nse_df['preds'] >= -0.1]\n",
    "median_nse = nse_df.loc[nse_df.preds != -np.inf, 'preds'].median()\n",
    "\n",
    "scale = 0.7\n",
    "fig, ax = plt.subplots(figsize=(12*scale, 8*scale))\n",
    "\n",
    "# plot the points\n",
    "# sns.lineplot(x='preds', y='index', ax=ax, data=data)\n",
    "sns.scatterplot(x='preds', y='index', hue='negative', x_jitter=2, ax=ax, data=data, alpha=0.4, legend=False)\n",
    "\n",
    "ymax = int(nse_df['index'].max() * 1.1)\n",
    "ax.axvline(median_nse, ymin=0, ymax=nse_df['index'].max() / ymax, color='k', ls='--', label='Median NSE', alpha=0.7)\n",
    "\n",
    "# beautify the plot\n",
    "ax.set_ylim(-5, ymax)\n",
    "ax.set_xlim(-0.1, 1)\n",
    "\n",
    "ax.legend(loc='upper left')\n",
    "\n",
    "ax.set_title(f'Station NSE - Median: {median_nse:.2f}\\n{nse_df.negative.sum()} Stations with negative NSE')\n",
    "ax.set_xlabel('NSE')\n",
    "ax.set_ylabel('Cumulative Number of Stations');\n",
    "\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crooks and Martinez stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catchment_ids = [\"12002\", \"15006\", \"27009\", \"27034\", \"27041\", \"39001\",\n",
    "                 \"39081\", \"43021\", \"47001\", \"54001\", \"54057\", \"71001\", \"84013\", ]\n",
    "catchment_ids = [int(c_id) for c_id in catchment_ids]\n",
    "catchment_names = [\"Dee@Park\", \"Tay@Ballathie\", \"Ouse@Skelton\", \"Ure@Kilgram\", \"Derwent@Buttercrambe\", \"Thames@Kingston\",\n",
    "                   \"Ock@Abingdon\", \"Avon@Knapp\", \"Tamar@Gunnislake\", \"Severn@Bewdley\", \"Severn@Haw\", \"Ribble@Samlesbury\", \"Clyde@Daldowie\"]\n",
    "station_map = dict(zip(catchment_ids, catchment_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_catchment_ids = [c for (ix, c) in enumerate(catchment_ids) if c in ealstm_pred.station_id.values]\n",
    "valid_station_name = np.array(catchment_names)[[ix for (ix, c) in enumerate(catchment_ids) if c in ealstm_pred.station_id.values]]\n",
    "# for ix, (station_id, station_name) in enumerate(zip(valid_catchment_ids, valid_station_name)):\n",
    "#     print(f\"{station_name} ID: {station_id}\")\n",
    "#     print(f\"\\tRMSE: {rmse_da.sel(station_id=station_id).values:.2f}\")\n",
    "#     print(f\"\\tNSE: {nse_da.sel(station_id=station_id).values:.2f}\")\n",
    "#     print(f\"\\tR2: {r2_da.sel(station_id=station_id).values:.2f}\")\n",
    "#     print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_station_scatter(\n",
    "    df: pd.DataFrame, station_id: str, metrics_df: Optional[pd.DataFrame] = None, ax=None,\n",
    "    target_var: str = 'discharge_spec',\n",
    "    station_name: Optional[str] = None\n",
    "):\n",
    "    # select station\n",
    "    d = df.query(f\"station_id == '{station_id}'\").drop(columns='station_id')\n",
    "    \n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    else:\n",
    "        fig = plt.gcf()\n",
    "    \n",
    "    # plot scatter\n",
    "    ax.plot(d[target_var], d.preds, 'kx', alpha=0.6, label='Data Point')\n",
    "    # plot 1:1 line\n",
    "    line_1_1_x = np.linspace(d[target_var].min(), d[target_var].max(), 10)\n",
    "    ax.plot(line_1_1_x, line_1_1_x, 'k--', label='1:1 Line')\n",
    "\n",
    "    ax.set_xlabel('Observed')\n",
    "    ax.set_ylabel('Predicted')\n",
    "    title = f'Station {station_id}' + f\" {station_name}\" if station_name is not None else f'Station {station_id}'\n",
    "    ax.set_title(title)\n",
    "\n",
    "    ax.legend();\n",
    "    \n",
    "    if False:\n",
    "        # making the plot pretty\n",
    "        for item in ([ax.title, ax.xaxis.label, ax.yaxis.label]\n",
    "                          + ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "                item.set_fontsize(12)\n",
    "\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    \n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "def plot_station(df: pd.DataFrame, station_id: str, metrics_df: Optional[pd.DataFrame] = None, ax=None,\n",
    "                station_name: Optional[str] = None):\n",
    "    \"\"\"Plot the Observed vs. Preds for the station_id\"\"\"\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    else:\n",
    "        fig = plt.gcf()\n",
    "    \n",
    "    # plot the station\n",
    "    df.query(f\"station_id == '{station_id}'\").drop(columns='station_id').plot(ax=ax)\n",
    "    \n",
    "    # get the error metrics\n",
    "    rmse_val = metrics_df.query(f\"station_id == '{station_id}'\").rmse.values[0]\n",
    "    r2_val = metrics_df.query(f\"station_id == '{station_id}'\").r2.values[0]\n",
    "    nse_val = metrics_df.query(f\"station_id == '{station_id}'\").nse.values[0]\n",
    "    # set the title\n",
    "    station_title = f\"{station_id} {station_name}\" if station_name is not None else station_id\n",
    "    ax.set_title(f\"{station_title}\\nRMSE: {rmse_val:.2f} R2: {r2_val:.2f} NSE: {nse_val:.2f}\")\n",
    "    \n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_stations = ['22007', '27049', '28018', '31021', '31023', '34004', '35003', '39022', '41029', '51001', '55025', '57004', '83010']\n",
    "catchment_ids = [\"12002\", \"15006\", \"27009\", \"27034\", \"27041\", \"39001\", \"39081\", \"43021\", \"47001\", \"54001\", \"54057\", \"71001\", \"84013\",]\n",
    "catchment_names = [\"Dee@Park\", \"Tay@Ballathie\", \"Ouse@Skelton\", \"Ure@Kilgram\", \"Derwent@Buttercrambe\", \"Thames@Kingston\", \"Ock@Abingdon\", \"Avon@Knapp\", \"Tamar@Gunnislake\", \"Severn@Bewdley\", \"Severn@Haw\", \"Ribble@Samlesbury\", \"Clyde@Daldowie\"]\n",
    "station_map = dict(zip(catchment_ids, catchment_names))\n",
    "\n",
    "scale = 0.8\n",
    "fig, axs = plt.subplots(13, 2, figsize=(12*scale, 6*scale*13))\n",
    "\n",
    "for ix, (station_id, station_name) in enumerate(zip(catchment_ids, catchment_names)):\n",
    "#     fig, axs = plt.subplots(1, 2, figsize=(12*scale, 6*scale))\n",
    "    try:\n",
    "        plot_station(df, station_id, metrics_df, ax=axs[ix, 0], station_name=station_name)\n",
    "        plot_station_scatter(df, station_id, metrics_df, axs[ix, 1])\n",
    "    except TypeError:\n",
    "        print(f\"** {station_name} data does not exist in the predictions! **\")\n",
    "        \n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ix, (station_id, station_name) in enumerate(zip(catchment_ids, catchment_names)):\n",
    "    rmse_val = metrics_df.query(f\"station_id == '{station_id}'\").rmse.values[0]\n",
    "    r2_val = metrics_df.query(f\"station_id == '{station_id}'\").r2.values[0]\n",
    "    nse_val = metrics_df.query(f\"station_id == '{station_id}'\").nse.values[0]\n",
    "    # set the title\n",
    "    station_title = f\"{station_id} {station_name}\" if station_name is not None else station_id\n",
    "    print(\n",
    "        f\"{station_title}\".ljust(30), \n",
    "        f\"-- RMSE: {rmse_val:.2f} -- R2: {r2_val:.2f} -- NSE: {nse_val:.2f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
