{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look for patterns in Delta NSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tommy/ml_drought\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# ignore warnings for now ...\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "if Path('.').absolute().parents[1].name == 'ml_drought':\n",
    "    os.chdir(Path('.').absolute().parents[1])\n",
    "\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "mpl.rcParams['figure.dpi'] = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_size = 14  #Â 10\n",
    "plt.rcParams.update(\n",
    "    {'axes.labelsize': label_size,\n",
    "     'legend.fontsize': label_size,\n",
    "     \"font.size\": 14,\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dir = Path('data/')\n",
    "data_dir = Path('/cats/datastore/data/')\n",
    "\n",
    "assert data_dir.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import drop_nans_and_flatten\n",
    "\n",
    "from src.analysis import read_train_data, read_test_data, read_pred_data\n",
    "from src.analysis.evaluation import join_true_pred_da\n",
    "from src.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../neuralhydrology\")\n",
    "\n",
    "from neuralhydrology.evaluation.metrics import nse, mse, rmse, kge, fdc_fms, fdc_fhv, fdc_flv, calculate_all_metrics, calculate_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in the CAMELS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the training data\n",
    "ds = xr.open_dataset(data_dir / \"RUNOFF/ALL_dynamic_ds.nc\")\n",
    "ds['station_id'] = ds['station_id'].astype(int)\n",
    "dynamic = ds\n",
    "\n",
    "all_static = xr.open_dataset(data_dir / f'RUNOFF/interim/static/data.nc')\n",
    "all_static['station_id'] = all_static['station_id'].astype(int)\n",
    "static = all_static"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read AWS Trained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ealstm_less_vars = pd.read_csv(data_dir / \"runs/ealstm_less_vars_2004_1707_1424/results_ealstm_less_vars_2004_1707_1424_E015.csv\")\n",
    "# ealstm_preds = xr.open_dataset(data_dir / \"RUNOFF/ealstm_epoch30_ensemble2/results.nc\")\n",
    "# ealstm_preds[\"station_id\"] = [int(sid) for sid in ealstm_preds[\"station_id\"]]\n",
    "# ealstm_preds = ealstm_preds.rename({\"discharge_spec_obs\": \"obs\", \"discharge_spec_sim\": \"sim\"})\n",
    "# ealstm_df = ealstm_preds.to_dataframe().reset_index()\n",
    "\n",
    "ealstm_df = pd.read_csv(data_dir / \"runs/ensemble_EALSTM/data_ENS.csv\").drop(\"Unnamed: 0\", axis=1)\n",
    "ealstm_df[\"time\"] = pd.to_datetime(ealstm_df[\"time\"])\n",
    "ealstm_preds = ealstm_df.set_index([\"station_id\", \"time\"]).to_xarray()\n",
    "\n",
    "ealstm_preds[\"station_id\"] = [int(sid) for sid in ealstm_preds[\"station_id\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_ensemble_df = pd.read_csv(\"/cats/datastore/data/runs/ensemble/data_ENS.csv\").drop(\"Unnamed: 0\", axis=1)\n",
    "lstm_ensemble_df[\"time\"] = pd.to_datetime(lstm_ensemble_df[\"time\"])\n",
    "lstm_ensemble = lstm_ensemble_df.set_index([\"station_id\", \"time\"]).to_xarray()\n",
    "lstm_preds = lstm_ensemble\n",
    "lstm_df = lstm_preds.to_dataframe().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>nse</th>\n",
       "      <th>kge</th>\n",
       "      <th>mse</th>\n",
       "      <th>fhv</th>\n",
       "      <th>fms</th>\n",
       "      <th>flv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10002</td>\n",
       "      <td>0.898328</td>\n",
       "      <td>0.857653</td>\n",
       "      <td>0.229347</td>\n",
       "      <td>-10.042169</td>\n",
       "      <td>20.175607</td>\n",
       "      <td>4.281218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10003</td>\n",
       "      <td>0.926555</td>\n",
       "      <td>0.881110</td>\n",
       "      <td>0.111980</td>\n",
       "      <td>-6.074578</td>\n",
       "      <td>1.342742</td>\n",
       "      <td>28.237229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1001</td>\n",
       "      <td>0.876090</td>\n",
       "      <td>0.920412</td>\n",
       "      <td>0.509755</td>\n",
       "      <td>3.647934</td>\n",
       "      <td>-23.746845</td>\n",
       "      <td>70.234474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101002</td>\n",
       "      <td>0.757246</td>\n",
       "      <td>0.647206</td>\n",
       "      <td>0.300506</td>\n",
       "      <td>-25.176707</td>\n",
       "      <td>-4.734227</td>\n",
       "      <td>73.409471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101005</td>\n",
       "      <td>0.824926</td>\n",
       "      <td>0.796430</td>\n",
       "      <td>0.208704</td>\n",
       "      <td>-18.346511</td>\n",
       "      <td>1.971726</td>\n",
       "      <td>45.197245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   station_id       nse       kge       mse        fhv        fms        flv\n",
       "0       10002  0.898328  0.857653  0.229347 -10.042169  20.175607   4.281218\n",
       "1       10003  0.926555  0.881110  0.111980  -6.074578   1.342742  28.237229\n",
       "2        1001  0.876090  0.920412  0.509755   3.647934 -23.746845  70.234474\n",
       "3      101002  0.757246  0.647206  0.300506 -25.176707  -4.734227  73.409471\n",
       "4      101005  0.824926  0.796430  0.208704 -18.346511   1.971726  45.197245"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_df = pd.read_csv(data_dir / \"runs/ensemble/metric_df.csv\", index_col=0)\n",
    "metric_df.columns = [c.lower() for c in metric_df.columns]\n",
    "metric_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FUSE Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_paths = [d for d in (data_dir / \"RUNOFF/FUSE/Timeseries_SimQ_Best/\").glob(\"*_Best_Qsim.txt\")]\n",
    "\n",
    "if not (data_dir / \"RUNOFF/ALL_fuse_ds.nc\").exists():\n",
    "    all_dfs = []\n",
    "    for txt in tqdm(all_paths):\n",
    "        df = pd.read_csv(txt, skiprows=3, header=0)\n",
    "        df.columns = [c.rstrip().lstrip() for c in df.columns]\n",
    "        df = df.rename(columns={\"YYYY\": \"year\", \"MM\": \"month\", \"DD\": \"day\"})\n",
    "        df[\"time\"] = pd.to_datetime(df[[\"year\", \"month\", \"day\"]])\n",
    "        station_id = int(str(txt).split(\"/\")[-1].split(\"_\")[0])\n",
    "        df[\"station_id\"] = [station_id for _ in range(len(df))]\n",
    "        df = df.drop([\"year\", \"month\", \"day\", \"HH\"], axis=1).set_index([\"station_id\", \"time\"])\n",
    "        all_dfs.append(df)\n",
    "        \n",
    "    fuse_ds = pd.concat(all_dfs).to_xarray()\n",
    "    fuse_ds.to_netcdf(data_dir / \"RUNOFF/ALL_fuse_ds.nc\")\n",
    "    \n",
    "else:\n",
    "    fuse_ds = xr.open_dataset(data_dir / \"RUNOFF/ALL_fuse_ds.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fuse_ds = fuse_ds.sel(time=slice('1998-01-01', '2009-01-01'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join with observations for stations that exist\n",
    "obs = (\n",
    "    ds.sel(station_id=np.isin(ds[\"station_id\"], fuse_ds[\"station_id\"]), time=fuse_ds[\"time\"])[\"discharge_spec\"]\n",
    ").rename(\"obs\")\n",
    "fuse_data = fuse_ds.sel(station_id=obs.station_id).merge(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
       "<defs>\n",
       "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
       "<title>Show/Hide data repr</title>\n",
       "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
       "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "</symbol>\n",
       "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
       "<title>Show/Hide attributes</title>\n",
       "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
       "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "</symbol>\n",
       "</defs>\n",
       "</svg>\n",
       "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
       " *\n",
       " */\n",
       "\n",
       ":root {\n",
       "  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n",
       "  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n",
       "  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n",
       "  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n",
       "  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n",
       "  --xr-background-color: var(--jp-layout-color0, white);\n",
       "  --xr-background-color-row-even: var(--jp-layout-color1, white);\n",
       "  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n",
       "}\n",
       "\n",
       ".xr-wrap {\n",
       "  min-width: 300px;\n",
       "  max-width: 700px;\n",
       "}\n",
       "\n",
       ".xr-header {\n",
       "  padding-top: 6px;\n",
       "  padding-bottom: 6px;\n",
       "  margin-bottom: 4px;\n",
       "  border-bottom: solid 1px var(--xr-border-color);\n",
       "}\n",
       "\n",
       ".xr-header > div,\n",
       ".xr-header > ul {\n",
       "  display: inline;\n",
       "  margin-top: 0;\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-obj-type,\n",
       ".xr-array-name {\n",
       "  margin-left: 2px;\n",
       "  margin-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-obj-type {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-sections {\n",
       "  padding-left: 0 !important;\n",
       "  display: grid;\n",
       "  grid-template-columns: 150px auto auto 1fr 20px 20px;\n",
       "}\n",
       "\n",
       ".xr-section-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-section-item input {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-item input + label {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label {\n",
       "  cursor: pointer;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label:hover {\n",
       "  color: var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-summary {\n",
       "  grid-column: 1;\n",
       "  color: var(--xr-font-color2);\n",
       "  font-weight: 500;\n",
       "}\n",
       "\n",
       ".xr-section-summary > span {\n",
       "  display: inline-block;\n",
       "  padding-left: 0.5em;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in + label:before {\n",
       "  display: inline-block;\n",
       "  content: 'âº';\n",
       "  font-size: 11px;\n",
       "  width: 15px;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label:before {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label:before {\n",
       "  content: 'â¼';\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label > span {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-summary,\n",
       ".xr-section-inline-details {\n",
       "  padding-top: 4px;\n",
       "  padding-bottom: 4px;\n",
       "}\n",
       "\n",
       ".xr-section-inline-details {\n",
       "  grid-column: 2 / -1;\n",
       "}\n",
       "\n",
       ".xr-section-details {\n",
       "  display: none;\n",
       "  grid-column: 1 / -1;\n",
       "  margin-bottom: 5px;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked ~ .xr-section-details {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-array-wrap {\n",
       "  grid-column: 1 / -1;\n",
       "  display: grid;\n",
       "  grid-template-columns: 20px auto;\n",
       "}\n",
       "\n",
       ".xr-array-wrap > label {\n",
       "  grid-column: 1;\n",
       "  vertical-align: top;\n",
       "}\n",
       "\n",
       ".xr-preview {\n",
       "  color: var(--xr-font-color3);\n",
       "}\n",
       "\n",
       ".xr-array-preview,\n",
       ".xr-array-data {\n",
       "  padding: 0 5px !important;\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-array-data,\n",
       ".xr-array-in:checked ~ .xr-array-preview {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-array-in:checked ~ .xr-array-data,\n",
       ".xr-array-preview {\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".xr-dim-list {\n",
       "  display: inline-block !important;\n",
       "  list-style: none;\n",
       "  padding: 0 !important;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list li {\n",
       "  display: inline-block;\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list:before {\n",
       "  content: '(';\n",
       "}\n",
       "\n",
       ".xr-dim-list:after {\n",
       "  content: ')';\n",
       "}\n",
       "\n",
       ".xr-dim-list li:not(:last-child):after {\n",
       "  content: ',';\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-has-index {\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       ".xr-var-list,\n",
       ".xr-var-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-var-item > div,\n",
       ".xr-var-item label,\n",
       ".xr-var-item > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-even);\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-var-item > .xr-var-name:hover span {\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-var-list > li:nth-child(odd) > div,\n",
       ".xr-var-list > li:nth-child(odd) > label,\n",
       ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-odd);\n",
       "}\n",
       "\n",
       ".xr-var-name {\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-var-dims {\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-var-dtype {\n",
       "  grid-column: 3;\n",
       "  text-align: right;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-preview {\n",
       "  grid-column: 4;\n",
       "}\n",
       "\n",
       ".xr-var-name,\n",
       ".xr-var-dims,\n",
       ".xr-var-dtype,\n",
       ".xr-preview,\n",
       ".xr-attrs dt {\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-var-name:hover,\n",
       ".xr-var-dims:hover,\n",
       ".xr-var-dtype:hover,\n",
       ".xr-attrs dt:hover {\n",
       "  overflow: visible;\n",
       "  width: auto;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".xr-var-attrs,\n",
       ".xr-var-data {\n",
       "  display: none;\n",
       "  background-color: var(--xr-background-color) !important;\n",
       "  padding-bottom: 5px !important;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
       ".xr-var-data-in:checked ~ .xr-var-data {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".xr-var-data > table {\n",
       "  float: right;\n",
       "}\n",
       "\n",
       ".xr-var-name span,\n",
       ".xr-var-data,\n",
       ".xr-attrs {\n",
       "  padding-left: 25px !important;\n",
       "}\n",
       "\n",
       ".xr-attrs,\n",
       ".xr-var-attrs,\n",
       ".xr-var-data {\n",
       "  grid-column: 1 / -1;\n",
       "}\n",
       "\n",
       "dl.xr-attrs {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  display: grid;\n",
       "  grid-template-columns: 125px auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt, dd {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  float: left;\n",
       "  padding-right: 10px;\n",
       "  width: auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt {\n",
       "  font-weight: normal;\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-attrs dt:hover span {\n",
       "  display: inline-block;\n",
       "  background: var(--xr-background-color);\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-attrs dd {\n",
       "  grid-column: 2;\n",
       "  white-space: pre-wrap;\n",
       "  word-break: break-all;\n",
       "}\n",
       "\n",
       ".xr-icon-database,\n",
       ".xr-icon-file-text2 {\n",
       "  display: inline-block;\n",
       "  vertical-align: middle;\n",
       "  width: 1em;\n",
       "  height: 1.5em !important;\n",
       "  stroke-width: 0;\n",
       "  stroke: currentColor;\n",
       "  fill: currentColor;\n",
       "}\n",
       "</style><div class='xr-wrap'><div class='xr-header'><div class='xr-obj-type'>xarray.Dataset</div></div><ul class='xr-sections'><li class='xr-section-item'><input id='section-4afd22ec-2275-4df8-ac13-b6eca4177676' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-4afd22ec-2275-4df8-ac13-b6eca4177676' class='xr-section-summary'  title='Expand/collapse section'>Dimensions:</label><div class='xr-section-inline-details'><ul class='xr-dim-list'><li><span class='xr-has-index'>station_id</span>: 519</li><li><span class='xr-has-index'>time</span>: 4018</li></ul></div><div class='xr-section-details'></div></li><li class='xr-section-item'><input id='section-47e495e1-e806-4843-a7ad-24e1e551b1fa' class='xr-section-summary-in' type='checkbox'  checked><label for='section-47e495e1-e806-4843-a7ad-24e1e551b1fa' class='xr-section-summary' >Coordinates: <span>(2)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>station_id</span></div><div class='xr-var-dims'>(station_id)</div><div class='xr-var-dtype'>int64</div><div class='xr-var-preview xr-preview'>1001 2001 2002 ... 102001 106001</div><input id='attrs-bd94d36e-941a-4092-bc49-9c12cc91a33d' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-bd94d36e-941a-4092-bc49-9c12cc91a33d' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-5bcd06eb-447f-4627-aacb-65965b5c02f2' class='xr-var-data-in' type='checkbox'><label for='data-5bcd06eb-447f-4627-aacb-65965b5c02f2' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><pre class='xr-var-data'>array([  1001,   2001,   2002, ..., 101005, 102001, 106001])</pre></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>time</span></div><div class='xr-var-dims'>(time)</div><div class='xr-var-dtype'>datetime64[ns]</div><div class='xr-var-preview xr-preview'>1998-01-01 ... 2008-12-31</div><input id='attrs-8e563b7f-9e44-4e7d-87ab-eb7186eae8f9' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-8e563b7f-9e44-4e7d-87ab-eb7186eae8f9' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-bd3c2152-7a5b-4c26-badb-9f26e9e99c08' class='xr-var-data-in' type='checkbox'><label for='data-bd3c2152-7a5b-4c26-badb-9f26e9e99c08' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><pre class='xr-var-data'>array([&#x27;1998-01-01T00:00:00.000000000&#x27;, &#x27;1998-01-02T00:00:00.000000000&#x27;,\n",
       "       &#x27;1998-01-03T00:00:00.000000000&#x27;, ..., &#x27;2008-12-29T00:00:00.000000000&#x27;,\n",
       "       &#x27;2008-12-30T00:00:00.000000000&#x27;, &#x27;2008-12-31T00:00:00.000000000&#x27;],\n",
       "      dtype=&#x27;datetime64[ns]&#x27;)</pre></li></ul></div></li><li class='xr-section-item'><input id='section-29c334e2-d409-47b4-af96-1e0ba8d8778a' class='xr-section-summary-in' type='checkbox'  checked><label for='section-29c334e2-d409-47b4-af96-1e0ba8d8778a' class='xr-section-summary' >Data variables: <span>(5)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span>SimQ_TOPMODEL</span></div><div class='xr-var-dims'>(station_id, time)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-f83d718c-6e39-4b68-a68e-86c68a6a5cd6' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-f83d718c-6e39-4b68-a68e-86c68a6a5cd6' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-f73c4f1e-177b-424a-bda6-8492a26bceac' class='xr-var-data-in' type='checkbox'><label for='data-f73c4f1e-177b-424a-bda6-8492a26bceac' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><pre class='xr-var-data'>[2085342 values with dtype=float64]</pre></li><li class='xr-var-item'><div class='xr-var-name'><span>SimQ_ARNOVIC</span></div><div class='xr-var-dims'>(station_id, time)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-beedce48-54c2-4987-9492-4de377a899c9' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-beedce48-54c2-4987-9492-4de377a899c9' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-3d3e19ac-dc93-4f84-bbcb-1a5e341e3396' class='xr-var-data-in' type='checkbox'><label for='data-3d3e19ac-dc93-4f84-bbcb-1a5e341e3396' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><pre class='xr-var-data'>[2085342 values with dtype=float64]</pre></li><li class='xr-var-item'><div class='xr-var-name'><span>SimQ_PRMS</span></div><div class='xr-var-dims'>(station_id, time)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-e92442ac-3c53-4d8c-9cad-0c2b1f22e108' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-e92442ac-3c53-4d8c-9cad-0c2b1f22e108' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-bb896551-b575-4251-b5b5-2b9004fa330f' class='xr-var-data-in' type='checkbox'><label for='data-bb896551-b575-4251-b5b5-2b9004fa330f' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><pre class='xr-var-data'>[2085342 values with dtype=float64]</pre></li><li class='xr-var-item'><div class='xr-var-name'><span>SimQ_SACRAMENTO</span></div><div class='xr-var-dims'>(station_id, time)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-a71d3002-636d-414a-9237-3e63f3588aba' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-a71d3002-636d-414a-9237-3e63f3588aba' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-5643cab6-293c-4763-998b-0e59eb2a38c4' class='xr-var-data-in' type='checkbox'><label for='data-5643cab6-293c-4763-998b-0e59eb2a38c4' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><pre class='xr-var-data'>[2085342 values with dtype=float64]</pre></li><li class='xr-var-item'><div class='xr-var-name'><span>obs</span></div><div class='xr-var-dims'>(time, station_id)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-882084b0-09d1-4f67-bb0d-9b6bed2d4c6b' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-882084b0-09d1-4f67-bb0d-9b6bed2d4c6b' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-2eb43cb6-9687-4143-ab13-29e674452c7b' class='xr-var-data-in' type='checkbox'><label for='data-2eb43cb6-9687-4143-ab13-29e674452c7b' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><pre class='xr-var-data'>[2085342 values with dtype=float64]</pre></li></ul></div></li><li class='xr-section-item'><input id='section-5c679b8a-9dd6-4bc7-ad75-5035f4f46d6a' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-5c679b8a-9dd6-4bc7-ad75-5035f4f46d6a' class='xr-section-summary'  title='Expand/collapse section'>Attributes: <span>(0)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'></dl></div></li></ul></div></div>"
      ],
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:          (station_id: 519, time: 4018)\n",
       "Coordinates:\n",
       "  * station_id       (station_id) int64 1001 2001 2002 ... 101005 102001 106001\n",
       "  * time             (time) datetime64[ns] 1998-01-01 1998-01-02 ... 2008-12-31\n",
       "Data variables:\n",
       "    SimQ_TOPMODEL    (station_id, time) float64 ...\n",
       "    SimQ_ARNOVIC     (station_id, time) float64 ...\n",
       "    SimQ_PRMS        (station_id, time) float64 ...\n",
       "    SimQ_SACRAMENTO  (station_id, time) float64 ...\n",
       "    obs              (time, station_id) float64 ..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuse_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Match Stations / Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stations_lstm = np.isin(lstm_preds.station_id, fuse_data.station_id)\n",
    "all_stations_ealstm = np.isin(ealstm_preds.station_id, fuse_data.station_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lstm_preds = lstm_preds.sel(station_id=all_stations_lstm, time=fuse_data.time)\n",
    "# ealstm_preds = ealstm_preds.sel(station_id=all_stations_ealstm, time=fuse_data.time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.drafts.calculate_error_scores import calculate_errors, error_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ealstm_metric_df = calculate_errors(ealstm_preds).set_index(\"station_id\")\n",
    "lstm_metric_df = calculate_errors(lstm_preds).set_index(\"station_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nse</th>\n",
       "      <th>kge</th>\n",
       "      <th>mse</th>\n",
       "      <th>fhv</th>\n",
       "      <th>fms</th>\n",
       "      <th>flv</th>\n",
       "      <th>rmse</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>station_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>0.876090</td>\n",
       "      <td>0.920412</td>\n",
       "      <td>0.509755</td>\n",
       "      <td>3.647934</td>\n",
       "      <td>-23.746845</td>\n",
       "      <td>70.234474</td>\n",
       "      <td>0.713971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>0.796159</td>\n",
       "      <td>0.737755</td>\n",
       "      <td>1.295476</td>\n",
       "      <td>-23.338750</td>\n",
       "      <td>-8.885240</td>\n",
       "      <td>8.945649</td>\n",
       "      <td>1.138190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>0.799168</td>\n",
       "      <td>0.721571</td>\n",
       "      <td>2.248968</td>\n",
       "      <td>-26.614591</td>\n",
       "      <td>-20.047770</td>\n",
       "      <td>54.950795</td>\n",
       "      <td>1.499656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3003</th>\n",
       "      <td>0.878744</td>\n",
       "      <td>0.851921</td>\n",
       "      <td>4.253649</td>\n",
       "      <td>-13.508330</td>\n",
       "      <td>-20.236829</td>\n",
       "      <td>54.121467</td>\n",
       "      <td>2.062438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4001</th>\n",
       "      <td>0.872644</td>\n",
       "      <td>0.860455</td>\n",
       "      <td>1.789749</td>\n",
       "      <td>-4.687964</td>\n",
       "      <td>-18.653824</td>\n",
       "      <td>39.811433</td>\n",
       "      <td>1.337815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 nse       kge       mse        fhv        fms        flv  \\\n",
       "station_id                                                                  \n",
       "1001        0.876090  0.920412  0.509755   3.647934 -23.746845  70.234474   \n",
       "2001        0.796159  0.737755  1.295476 -23.338750  -8.885240   8.945649   \n",
       "2002        0.799168  0.721571  2.248968 -26.614591 -20.047770  54.950795   \n",
       "3003        0.878744  0.851921  4.253649 -13.508330 -20.236829  54.121467   \n",
       "4001        0.872644  0.860455  1.789749  -4.687964 -18.653824  39.811433   \n",
       "\n",
       "                rmse  \n",
       "station_id            \n",
       "1001        0.713971  \n",
       "2001        1.138190  \n",
       "2002        1.499656  \n",
       "3003        2.062438  \n",
       "4001        1.337815  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nse</th>\n",
       "      <th>kge</th>\n",
       "      <th>mse</th>\n",
       "      <th>bias</th>\n",
       "      <th>log_nse</th>\n",
       "      <th>inv_kge</th>\n",
       "      <th>abs_pct_bias</th>\n",
       "      <th>mape</th>\n",
       "      <th>mam30_ape</th>\n",
       "      <th>rmse</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>station_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>0.876090</td>\n",
       "      <td>0.920412</td>\n",
       "      <td>0.509755</td>\n",
       "      <td>4.266320</td>\n",
       "      <td>0.785360</td>\n",
       "      <td>-0.009563</td>\n",
       "      <td>4.266320</td>\n",
       "      <td>74.735973</td>\n",
       "      <td>176.786561</td>\n",
       "      <td>0.713971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>0.796159</td>\n",
       "      <td>0.737755</td>\n",
       "      <td>1.295476</td>\n",
       "      <td>-12.189085</td>\n",
       "      <td>0.885491</td>\n",
       "      <td>0.839352</td>\n",
       "      <td>12.189085</td>\n",
       "      <td>21.224725</td>\n",
       "      <td>18.321161</td>\n",
       "      <td>1.138190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>0.799168</td>\n",
       "      <td>0.721571</td>\n",
       "      <td>2.248968</td>\n",
       "      <td>-7.375567</td>\n",
       "      <td>0.846839</td>\n",
       "      <td>0.381013</td>\n",
       "      <td>7.375567</td>\n",
       "      <td>44.421990</td>\n",
       "      <td>57.675247</td>\n",
       "      <td>1.499656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3003</th>\n",
       "      <td>0.878744</td>\n",
       "      <td>0.851921</td>\n",
       "      <td>4.253648</td>\n",
       "      <td>-0.086631</td>\n",
       "      <td>0.875849</td>\n",
       "      <td>0.329947</td>\n",
       "      <td>0.086631</td>\n",
       "      <td>45.625153</td>\n",
       "      <td>45.614187</td>\n",
       "      <td>2.062437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4001</th>\n",
       "      <td>0.872644</td>\n",
       "      <td>0.860455</td>\n",
       "      <td>1.789749</td>\n",
       "      <td>-3.644160</td>\n",
       "      <td>0.801445</td>\n",
       "      <td>0.571053</td>\n",
       "      <td>3.644160</td>\n",
       "      <td>29.394915</td>\n",
       "      <td>24.067408</td>\n",
       "      <td>1.337815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 nse       kge       mse       bias   log_nse   inv_kge  \\\n",
       "station_id                                                                \n",
       "1001        0.876090  0.920412  0.509755   4.266320  0.785360 -0.009563   \n",
       "2001        0.796159  0.737755  1.295476 -12.189085  0.885491  0.839352   \n",
       "2002        0.799168  0.721571  2.248968  -7.375567  0.846839  0.381013   \n",
       "3003        0.878744  0.851921  4.253648  -0.086631  0.875849  0.329947   \n",
       "4001        0.872644  0.860455  1.789749  -3.644160  0.801445  0.571053   \n",
       "\n",
       "            abs_pct_bias       mape   mam30_ape      rmse  \n",
       "station_id                                                 \n",
       "1001            4.266320  74.735973  176.786561  0.713971  \n",
       "2001           12.189085  21.224725   18.321161  1.138190  \n",
       "2002            7.375567  44.421990   57.675247  1.499656  \n",
       "3003            0.086631  45.625153   45.614187  2.062437  \n",
       "4001            3.644160  29.394915   24.067408  1.337815  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric_df[\"rmse\"] = np.sqrt(metric_df[\"mse\"])\n",
    "lstm_metric_df[\"rmse\"] = np.sqrt(lstm_metric_df[\"mse\"])\n",
    "ealstm_metric_df[\"rmse\"] = np.sqrt(ealstm_metric_df[\"mse\"])\n",
    "display(metric_df.set_index(\"station_id\").sort_index().head())\n",
    "display(lstm_metric_df.sort_index().head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FUSE - Calculate from Sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.drafts.calculate_error_scores import FuseErrors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "nse: 4it [00:07,  1.83s/it]\n",
      "kge: 4it [00:08,  2.03s/it]\n",
      "bias: 4it [00:04,  1.14s/it]\n",
      "rmse: 4it [00:04,  1.18s/it]\n",
      "log_nse: 4it [00:07,  1.97s/it]\n",
      "inv_kge: 4it [00:07,  1.99s/it]\n",
      "mape: 4it [00:08,  2.01s/it]\n",
      "abs_pct_bias: 4it [00:06,  1.71s/it]\n"
     ]
    }
   ],
   "source": [
    "fuse_errors_fp = data_dir / \"RUNOFF/0_fuse_errors.pkl\"\n",
    "fuse_class_fp = data_dir / \"RUNOFF/0_fuse_class.pkl\"\n",
    "\n",
    "if not (fuse_errors_fp).exists() or (fuse_class_fp).exists():\n",
    "    f = FuseErrors(fuse_data)\n",
    "    fuse_errors = f.fuse_errors\n",
    "    \n",
    "    pickle.dump(f, fuse_class_fp.open(\"wb\"))\n",
    "    pickle.dump(fuse_errors, fuse_errors_fp.open(\"wb\"))\n",
    "else:\n",
    "    f = pickle.load(fuse_class_fp.open(\"rb\"))\n",
    "    fuse_errors = pickle.load(fuse_errors_fp.open(\"rb\"))\n",
    "fuse_metric_df = fuse_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'shape' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-4f1f1533dc9e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfuse_bias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_metric_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bias\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfuse_nse_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_metric_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nse\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfuse_kge_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_metric_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"kge\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtopmodel_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"TOPMODEL\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ml_drought/scripts/drafts/calculate_error_scores.py\u001b[0m in \u001b[0;36mget_metric_df\u001b[0;34m(self, metric)\u001b[0m\n\u001b[1;32m    286\u001b[0m             \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfuse_errors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         ].droplevel(level=0, axis=1)\n\u001b[0;32m--> 288\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m             df = self.fuse_errors.loc[\n\u001b[1;32m    290\u001b[0m                 \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfuse_errors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'shape' is not defined"
     ]
    }
   ],
   "source": [
    "fuse_bias = f.get_metric_df(\"bias\")\n",
    "fuse_nse_df = f.get_metric_df(\"nse\")\n",
    "fuse_kge_df = f.get_metric_df(\"kge\")\n",
    "\n",
    "topmodel_metrics = f.get_model_df(\"TOPMODEL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nse_df = fuse_nse_df.join(\n",
    "    lstm_metric_df[[\"nse\"]].rename({\"nse\": \"LSTM\"}, axis=1).join(ealstm_metric_df[[\"nse\"]].rename({\"nse\": \"EALSTM\"}, axis=1))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate delta Metrics (all dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.drafts.calculate_error_scores import DeltaError\n",
    "\n",
    "# calculate all error metrics\n",
    "processor = DeltaError(ealstm_preds, lstm_preds, fuse_data)\n",
    "all_preds = processor.all_preds\n",
    "errors_dict = processor.calculate_all_errors(all_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calculate seasonal differences in scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasonal_deltas = defaultdict(dict)\n",
    "for season in [\"DJF\", \"MAM\", \"JJA\", \"SON\"]:\n",
    "    _preds = all_preds.sel(time=all_preds[\"time.season\"] == season)\n",
    "    seasonal_errors = processor.calculate_all_errors(_preds)\n",
    "    seasonal_deltas[season][\"LSTM\"], seasonal_deltas[season][\"EALSTM\"] = processor.calculate_all_delta_dfs(seasonal_errors)\n",
    "    seasonal_deltas[season][\"raw\"] = seasonal_errors\n",
    "    \n",
    "    \n",
    "# seasonal_deltas = processor.calculate_seasonal_deltas(all_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(seasonal_deltas[\"MAM\"][\"LSTM\"][\"nse\"].head())\n",
    "# display(seasonal_deltas[\"DJF\"][\"LSTM\"][\"nse\"].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_delta, ealstm_delta = processor.calculate_all_delta_dfs(errors_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_delta[\"nse\"].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lstm_delta[\"nse\"].to_csv(data_dir / \"RUNOFF/for_gemma/lstm_delta_nse.csv\")\n",
    "# lstm_delta[\"mse\"].to_csv(data_dir / \"RUNOFF/for_gemma/lstm_delta_mse.csv\")\n",
    "# lstm_delta[\"kge\"].to_csv(data_dir / \"RUNOFF/for_gemma/lstm_delta_kge.csv\")\n",
    "# # ealstm_delta[\"nse\"].to_csv(data_dir / \"RUNOFF/for_gemma/ealstm_deltanse.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### using the kratzert functions (more error metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    # calculate all error metrics\n",
    "    lstm_kratzert_results, ealstm_kratzert_results = processor.kratzert_errors(all_preds)\n",
    "    \n",
    "kratzert_results_file = data_dir / \"RUNOFF/kratzert_results.pkl\"\n",
    "if not kratzert_results_file.exists():\n",
    "    model_results = calc_kratzert_error_functions(all_preds)\n",
    "    pickle.dump(results, kratzert_results_file.open(\"wb\"))\n",
    "else:\n",
    "    results = pickle.load(kratzert_results_file.open(\"rb\"))\n",
    "    \n",
    "if False:\n",
    "    kra_lstm_delta_dict = processor.calculate_all_kratzert_deltas(results, ref_model=\"LSTM\")\n",
    "    kra_lstm_delta = processor.get_formatted_dataframe(lstm_delta_dict, format=\"metric\")\n",
    "\n",
    "    kra_ealstm_delta_dict = processor.calculate_all_kratzert_deltas(results, ref_model=\"EALSTM\")\n",
    "    kra_ealstm_delta = processor.get_formatted_dataframe(ealstm_delta_dict, format=\"metric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lstm_kratzert_results[\"NSE\"].head(2)\n",
    "print(lstm_delta[\"nse\"].drop(\"EALSTM\", axis=1).median().median())\n",
    "print(ealstm_delta[\"nse\"].drop(\"LSTM\", axis=1).median().median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(lstm_delta[\"nse\"].describe())\n",
    "display(ealstm_delta[\"nse\"].describe())\n",
    "# display(lstm_metric_deltas[\"NSE\"].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore Delta NSEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_delta_nse = lstm_delta[\"nse\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxplot_deltas(deltas: pd.DataFrame, metric: str, ylim=[-1 ,1], ref_model: str = \"LSTM\"):\n",
    "    sns.boxplot(data=deltas[metric], palette=sns.color_palette())\n",
    "    ax = plt.gca()\n",
    "    ax.set_ylim(ylim)\n",
    "    ax.axhline(0, ls=\":\", color=\"k\", label=\"No Improvement\")\n",
    "    ax.set_ylabel(f\"$\\Delta${metric}\")\n",
    "    ax.legend()\n",
    "    ax.set_title(f\"$\\Delta${metric} for each Model vs. {ref_model}\")\n",
    "    sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots()\n",
    "boxplot_deltas(lstm_delta, metric=\"nse\")\n",
    "f, ax = plt.subplots()\n",
    "boxplot_deltas(ealstm_delta, metric=\"nse\", ref_model=\"EALSTM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "def kde_plot_deltas(delta_df: pd.DataFrame, metric: str = \"nse\", xlim: Tuple[float] = (-1, 1)):\n",
    "        kde_kws = {\"clip\": (-1, 1)}\n",
    "        hist_kws = {\"range\": (-1, 1), \"density\": True}\n",
    "\n",
    "        f, ax = plt.subplots()\n",
    "        [\n",
    "            sns.distplot(delta_df[metric][c], ax=ax, kde_kws=kde_kws, hist_kws=hist_kws, hist=False, label=c) \n",
    "            for c in delta_df[metric].columns if c != \"EALSTM\"\n",
    "        ]\n",
    "        ax.set_xlim((-1, 1))\n",
    "        ax.axvline(0, ls=\":\", color=\"k\")\n",
    "        ax.set_xlabel(\"$\\Delta$NSE\")\n",
    "        ax.legend()\n",
    "        sns.despine()\n",
    "        \n",
    "        \n",
    "kde_plot_deltas(lstm_delta, metric=\"nse\", xlim=(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_seasonal_dfs = {}\n",
    "for season in [\"DJF\", \"MAM\", \"JJA\", \"SON\"]:\n",
    "    lstm_seasonal_dfs[season] = seasonal_deltas[season][\"LSTM\"][\"nse\"]\n",
    "    \n",
    "ealstm_seasonal_dfs = {}\n",
    "for season in [\"DJF\", \"MAM\", \"JJA\", \"SON\"]:\n",
    "    ealstm_seasonal_dfs[season] = seasonal_deltas[season][\"EALSTM\"][\"nse\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(lstm_seasonal_dfs[\"DJF\"].head())\n",
    "display(lstm_seasonal_dfs[\"MAM\"].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import DefaultDict\n",
    "\n",
    "#Â LSTM\n",
    "metric = \"nse\"\n",
    "ref_model = \"LSTM\"\n",
    "\n",
    "def plot_seasonal_ecdfs(seasonal_deltas: DefaultDict, metric: str = \"nse\", ref_model: str = \"LSTM\", clip: Tuple[float] = (-1, 3)):\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(6*2, 4*2))\n",
    "\n",
    "    for ix, model in enumerate([\"TOPMODEL\", \"ARNOVIC\", \"PRMS\", \"SACRAMENTO\"]):\n",
    "        ax = axs[np.unravel_index(ix, (2, 2))]\n",
    "        for season in [\"DJF\", \"MAM\", \"JJA\", \"SON\"]:\n",
    "            sns.distplot(\n",
    "                seasonal_deltas[season][ref_model][metric].loc[:, model].dropna(), \n",
    "                label=season, \n",
    "                kde_kws = {\"clip\": (-1, 3), \"linewidth\":1, \"cumulative\": True}, \n",
    "                hist=False, ax=ax\n",
    "            )\n",
    "\n",
    "            ax.axvline(0, ls=\":\", color=\"k\", alpha=0.6)\n",
    "            ax.set_xlabel(f\"$\\Delta${metric.upper()} ({ref_model})\")\n",
    "            ax.set_title(model)\n",
    "            if ix != 0:\n",
    "                ax.get_legend().remove()\n",
    "\n",
    "            sns.despine()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    \n",
    "plot_seasonal_ecdfs(seasonal_deltas, metric=\"nse\", ref_model=\"LSTM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_bins(data: pd.Series, n_bins: int=4) -> pd.DataFrame:\n",
    "#     assert all(np.isfinite(data)), \"Weird behaviour with nans. Drop them. `data.dropna()`\"\n",
    "#     #Â get the groups where greater than zero\n",
    "#     zero_indexes = data.loc[data < 0].index\n",
    "#     out_series = pd.concat([\n",
    "#         pd.qcut(data.loc[data > 0], q=n_bins),\n",
    "#         pd.Series([pd.Interval(-np.inf, 0) for _ in range((data < 0).sum())], index=zero_indexes).astype(\"category\"),\n",
    "#     ])\n",
    "#     out_series.name = \"group\"\n",
    "    \n",
    "#     # ordered categories\n",
    "#     out_series = out_series.astype(\"category\")\n",
    "#     out_series = out_series.cat.as_ordered()\n",
    "#     # create 2 columns of categories and code\n",
    "#     df = pd.DataFrame({\"category\": out_series, \"code\": out_series.cat.codes})\n",
    "\n",
    "#     return df\n",
    "\n",
    "\n",
    "def create_custom_binned_data(data) -> pd.DataFrame:\n",
    "    bins = pd.IntervalIndex.from_tuples([(-np.inf, 0), (0, 0.05), (0.05, 0.1), (0.1, 0.2), (0.2, np.inf)])\n",
    "    bin_vals = pd.cut(season_deltanse[\"value\"], bins, retbins=False)\n",
    "    bin_vals = bin_vals.cat.as_ordered()\n",
    "    bin_codes = bin_vals.cat.codes\n",
    "    \n",
    "    df = pd.DataFrame({\"category\": bin_vals, \"code\": bin_codes})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasonal_deltas[\"DJF\"][\"LSTM\"][\"nse\"]\n",
    "seasonal_deltas[\"MAM\"][\"LSTM\"][\"nse\"]\n",
    "seasonal_deltas[\"SON\"][\"LSTM\"][\"nse\"]\n",
    "dd = seasonal_deltas[\"JJA\"][\"LSTM\"][\"nse\"]\n",
    "\n",
    "# flattened.pivot_table(values=['value'], index=\"station_id\", columns=['variable'], aggfunc=lambda x: x)\n",
    "all_season_deltanse = []\n",
    "for season in [\"DJF\", \"MAM\", \"JJA\", \"SON\"]:\n",
    "    dd = seasonal_deltas[season][\"LSTM\"][\"nse\"]\n",
    "    flattened = dd.reset_index().melt(id_vars=[\"station_id\"])\n",
    "    flattened[\"season\"] = season\n",
    "    all_season_deltanse.append(flattened)\n",
    "\n",
    "season_deltanse = pd.concat(all_season_deltanse).dropna()\n",
    "# season_deltanse.join(create_custom_binned_data(season_deltanse[\"value\"]))\n",
    "binned_ = create_custom_binned_data(season_deltanse[\"value\"])\n",
    "season_deltanse[\"category\"] = binned_[\"category\"]\n",
    "season_deltanse[\"code\"] = binned_[\"code\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(season_deltanse[\"value\"], clip=(0, 1))\n",
    "ax = plt.gca()\n",
    "for boundary in season_deltanse[\"category\"].cat.categories.left[1:]:\n",
    "    ax.axvline(boundary, ls=\":\", alpha=1, color=\"grey\")\n",
    "    \n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = season_deltanse.groupby([\"category\", \"season\"]).count()[\"code\"].reset_index().rename(dict(code=\"count\"), axis=1)\n",
    "C[\"pct\"] = (C[\"count\"] / C.groupby(\"season\").sum()[\"count\"].loc[C[\"season\"]].values) * 100\n",
    "C[\"season\"] = pd.Categorical(C[\"season\"], ordered=True)\n",
    "C[\"season\"] = C[\"season\"].cat.reorder_categories([\"SON\", \"DJF\", \"MAM\", \"JJA\"])\n",
    "\n",
    "C.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(dir(pd.Categorical(C[\"season\"], ordered=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12, 8))\n",
    "sns.barplot(y=\"pct\", x=\"category\", hue=\"season\", data=C, palette=\"plasma\", ax=ax)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation = 45, ha=\"right\");\n",
    "ax.set_ylabel(\"Percent of âNSE in Bin\")\n",
    "ax.set_xlabel(\"âNSE Bin\")\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened.set_index(\"station_id\").stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Groundwater"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "\n",
    "def plot_static_feature_ordered_scatter(\n",
    "    delta_data: Dict[str, pd.DataFrame],\n",
    "    metric: str = \"nse\", \n",
    "    ylim: Tuple[float] = (-0.5, 1.6), \n",
    "    feature: str = \"aridity\",\n",
    "    kwargs: Dict = {},\n",
    "):\n",
    "    data = delta_data[metric].join(static[feature].to_dataframe())\n",
    "\n",
    "    f, axs = plt.subplots(2, 2)\n",
    "\n",
    "    for ix, model in enumerate([\"TOPMODEL\", \"ARNOVIC\", \"PRMS\", \"SACRAMENTO\"]):\n",
    "        ax_ix = np.unravel_index(ix, (2, 2))\n",
    "        ax = axs[ax_ix]\n",
    "        sorted_index = data[model].sort_values().index\n",
    "        s = ax.scatter(\n",
    "            np.arange(len(data[model])), \n",
    "            data[model].sort_values().loc[sorted_index], \n",
    "            c=data[feature].loc[sorted_index],\n",
    "            **kwargs\n",
    "        )\n",
    "        ax.axhline(ls=\":\", color=\"k\", alpha=0.5, label=\"No Improvement\")\n",
    "        ax.set_title(f\"{model} Delta {metric.upper()}\")\n",
    "        ax.set_ylim(ylim)\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_xticks([])\n",
    "\n",
    "        sns.despine()\n",
    "        if ax_ix[1] == 0:\n",
    "            ax.set_ylabel(\"$\\Delta$NSE\")\n",
    "        else:\n",
    "            ax.set_yticklabels([])\n",
    "            ax.set_yticks([])\n",
    "        if ax_ix[0] == 1:\n",
    "            ax.set_xlabel(\"Basin\")\n",
    "\n",
    "    \n",
    "    # colorbar\n",
    "    f.tight_layout()\n",
    "    f.subplots_adjust(right=0.8)\n",
    "    cbar_ax = f.add_axes([0.85, 0.15, 0.05, 0.7])\n",
    "    cbar = f.colorbar(s, cax=cbar_ax)\n",
    "    cbar.set_label(feature.capitalize())\n",
    "\n",
    "    \n",
    "def plot_static_feature_scatter(\n",
    "    delta_data: Dict[str, pd.DataFrame],\n",
    "    metric: str = \"nse\", \n",
    "    ylim: Tuple[float] = (0, 1), \n",
    "    xlim: Tuple[float] = (-0.5, 1.6), \n",
    "    feature: str = \"aridity\",\n",
    "    kwargs: Dict = {},\n",
    "):\n",
    "    data = delta_data[metric].join(static[feature].to_dataframe())\n",
    "\n",
    "    f, axs = plt.subplots(2, 2)\n",
    "\n",
    "    for ix, model in enumerate([\"TOPMODEL\", \"ARNOVIC\", \"PRMS\", \"SACRAMENTO\"]):\n",
    "        ax_ix = np.unravel_index(ix, (2, 2))\n",
    "        ax = axs[ax_ix]\n",
    "        sorted_index = data[model].index\n",
    "        s = ax.scatter(\n",
    "            data[model].loc[sorted_index], \n",
    "            data[feature].loc[sorted_index],\n",
    "            c=data[feature].loc[sorted_index],\n",
    "            **kwargs\n",
    "        )\n",
    "        ax.axvline(0, ls=\":\", color=\"k\", alpha=0.5, label=\"No Improvement\")\n",
    "        ax.set_title(f\"{model} Delta {metric.upper()}\")\n",
    "        ax.set_ylim(ylim)\n",
    "        ax.set_xlim(xlim)\n",
    "        sns.despine()\n",
    "        if ax_ix[1] == 0:\n",
    "            ax.set_ylabel(f\"{feature}\")\n",
    "        else:\n",
    "            ax.set_yticklabels([])\n",
    "            ax.set_yticks([])\n",
    "        if ax_ix[0] == 1:\n",
    "            ax.set_xlabel(\"$\\Delta$NSE\")\n",
    "\n",
    "    # colorbar\n",
    "    f.tight_layout()\n",
    "    f.subplots_adjust(right=0.8)\n",
    "    cbar_ax = f.add_axes([0.85, 0.15, 0.05, 0.7])\n",
    "    cbar = f.colorbar(s, cax=cbar_ax)\n",
    "    cbar.set_label(feature.capitalize())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_static_feature_ordered_scatter(lstm_delta, metric=\"nse\", feature=\"baseflow_index\", kwargs={\"s\": None, \"marker\":\"o\", \"s\": 7})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_static_feature_scatter(lstm_delta, metric=\"nse\", feature=\"baseflow_index\", kwargs={\"vmin\":None, \"vmax\":None, \"s\": 7})\n",
    "# plot_static_feature_scatter(lstm_delta, metric=\"nse\", feature=\"area\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discretize the DeltaNSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â get the continuous static features with few nans\n",
    "float_static = static.to_dataframe().loc[:, static.to_dataframe().dtypes == \"float64\"]\n",
    "float_static = float_static.loc[:, ~(float_static.isnull().mean() > 0.25)]\n",
    "\n",
    "\n",
    "\n",
    "def create_bins(data: pd.Series, n_bins: int=4) -> pd.DataFrame:\n",
    "    #Â get the groups where greater than zero\n",
    "    zero_indexes = data.loc[data < 0].index\n",
    "    out_series = pd.concat([\n",
    "        pd.qcut(data.loc[data > 0], q=n_bins),\n",
    "        pd.Series([pd.Interval(-np.inf, 0) for _ in range((data < 0).sum())], index=zero_indexes).astype(\"category\"),\n",
    "    ])\n",
    "    out_series.name = \"group\"\n",
    "    \n",
    "    # ordered categories\n",
    "    out_series = out_series.astype(\"category\")\n",
    "    out_series = out_series.cat.as_ordered()\n",
    "    # create 2 columns of categories and code\n",
    "    df = pd.DataFrame({\"category\": out_series, \"code\": out_series.cat.codes})\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def create_model_delta_bins_with_static(\n",
    "    delta_data = lstm_delta,\n",
    "    metric = \"nse\",\n",
    "    model = \"TOPMODEL\",\n",
    "    static_variable = \"baseflow_index\"\n",
    "):\n",
    "    model_delta = delta_data[metric][model]\n",
    "    binned = create_bins(model_delta)\n",
    "    \n",
    "    #Â join to static data\n",
    "    data = binned.join(float_static[static_variable])\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def boxplot_discretized_delta_nse(data: pd.DataFrame, static_variable: str, model: str, ax, swarm: bool = True, swarm_kwargs: Dict = {\"size\": 2}):\n",
    "    assert all(np.isin([\"category\", static_variable], data.columns)), \"calculate discretized bins with `create_model_delta_bins_with_static` function\"\n",
    "    \n",
    "    sns.boxplot(x=\"category\", y=static_variable, data=data, ax=ax)\n",
    "    if swarm:\n",
    "        sns.swarmplot(x=\"category\", y=static_variable, data=data, color=\".25\", ax=ax, **swarm_kwargs)\n",
    "\n",
    "    #Â prettier labels\n",
    "    labels = []\n",
    "    for category in data[\"category\"].cat.categories:\n",
    "        labels.append(f\"{category.left:.2f} > x < {category.right:.2f}\")\n",
    "\n",
    "    ax.set_xticklabels(labels, rotation = 45, ha=\"right\")\n",
    "    ax.set_xlabel(\"$\\Delta$NSE Bin\")\n",
    "    ax.set_ylabel(static_variable)\n",
    "    ax.set_title(f\"{model} Discretized $\\Delta$NSE\")\n",
    "    sns.despine()\n",
    "    \n",
    "\n",
    "delta_data = lstm_delta\n",
    "metric = \"nse\"\n",
    "model = \"TOPMODEL\"\n",
    "static_variable = \"baseflow_index\"\n",
    "\n",
    "# f, ax = plt.subplots()\n",
    "# data = create_model_delta_bins_with_static(lstm_delta, metric, model, static_variable)\n",
    "# boxplot_discretized_delta_nse(data, static_variable, model, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â join all into one big plot\n",
    "d = lstm_delta[\"nse\"].drop(\"EALSTM\", axis=1).melt()\n",
    "index = np.tile(lstm_delta[\"nse\"].index, 4)\n",
    "d.index = index\n",
    "\n",
    "binned = create_bins(d.value, n_bins=6).join(float_static[\"baseflow_index\"])\n",
    "\n",
    "# f, ax = plt.subplots()\n",
    "# boxplot_discretized_delta_nse(binned, \"variable\", \"All Models\", ax=ax, swarm=False)\n",
    "# binned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â histogram of all data from \n",
    "out = lstm_delta[\"nse\"].drop(\"EALSTM\", axis=1).melt()\n",
    "index = np.tile(lstm_delta[\"nse\"].index, 4)\n",
    "out.index = index\n",
    "\n",
    "\n",
    "#Â PLOT HIST\n",
    "plt.hist(out[\"value\"], bins=100, range=(-0.1, 1), alpha=0.6);\n",
    "cutoffs = np.array(binned[\"category\"].cat.categories.right)[:-1]\n",
    "ax = plt.gca()\n",
    "for c in cutoffs:\n",
    "    ax.axvline(c, ls=\":\", label=f\"{c:.2f}\")\n",
    "ax.legend()\n",
    "ax.set_xlim(-0.1, 1)\n",
    "\n",
    "ax.set_xlabel(\"$\\Delta$NSE\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_bins(float_static[\"baseflow_index\"], n_bins=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binned = create_bins(float_static[\"baseflow_index\"], n_bins=6).join(float_static[\"baseflow_index\"])\n",
    "\n",
    "#Â PLOT HIST\n",
    "plt.hist(binned[\"baseflow_index\"], bins=100, range=(-0.1, 1), alpha=0.6);\n",
    "cutoffs = np.array(binned[\"category\"].cat.categories.right)[:-1]\n",
    "ax = plt.gca()\n",
    "for c in cutoffs:\n",
    "    ax.axvline(c, ls=\":\", label=f\"{c:.2f}\")\n",
    "ax.legend()\n",
    "ax.set_xlim(-0.1, 1)\n",
    "\n",
    "ax.set_xlabel(\"baseflow index\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TO PLOT EACH MODEL SEPARATELY\n",
    "\n",
    "# delta_data = lstm_delta\n",
    "# metric = \"nse\"\n",
    "# # model = \"TOPMODEL\"\n",
    "# static_variable = \"baseflow_index\"\n",
    "\n",
    "# f, axs = plt.subplots(2, 2, figsize=(6*1.5, 4*1.5))\n",
    "# for ix, model in enumerate([\"TOPMODEL\", \"ARNOVIC\", \"PRMS\", \"SACRAMENTO\"]):\n",
    "#     ax_ix = np.unravel_index(ix, (2, 2))\n",
    "#     ax = axs[ax_ix]\n",
    "\n",
    "#     data = create_model_delta_bins_with_static(lstm_delta, metric, model, static_variable)\n",
    "#     boxplot_discretized_delta_nse(data, static_variable, model, ax=ax, swarm_kwargs={\"size\": 2})\n",
    "    \n",
    "#     fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lstm_errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SCATTER Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "#Â SPLINE FUNCTIONS\n",
    "from typing import Union\n",
    "def sort_values_by_x(x: Union[np.ndarray, pd.Series], y: Union[np.ndarray, pd.Series]) -> Union[np.ndarray, pd.Series]:\n",
    "    sort = np.argsort(x)\n",
    "    try:\n",
    "        x = x.iloc[sort]\n",
    "        y = y.iloc[sort]\n",
    "    except AttributeError:\n",
    "        x = x[sort]\n",
    "        y = y[sort]\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def strict_increasing(x: pd.Series, y: pd.Series) -> Tuple[pd.Series]:\n",
    "    # TODO: convert to using np.argsort to maintain x,y pairing\n",
    "    x, y = sort_values_by_x(x, y)\n",
    "\n",
    "    strictly_increasing_x = [True]\n",
    "    strictly_increasing_x.extend(np.diff(x) > 0)\n",
    "    x_inc = x[strictly_increasing_x]\n",
    "    y_inc = y[strictly_increasing_x]\n",
    "    \n",
    "    return x_inc, y_inc\n",
    "\n",
    "\n",
    "def return_finite_only(x: np.ndarray, y: np.ndarray) -> Tuple[np.ndarray]:\n",
    "    x = x[np.isfinite(x) & np.isfinite(y)]\n",
    "    y = y[np.isfinite(x) & np.isfinite(y)]\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def cubic_spline(x: pd.Series, y: pd.Series) -> Callable:\n",
    "    from scipy.interpolate import CubicSpline\n",
    "    # https://stackoverflow.com/a/43613728/9940782\n",
    "    #Â dropnans\n",
    "    x, y = return_finite_only(x, y)\n",
    "    \n",
    "    #Â strictly increasing\n",
    "    x, y = strict_increasing(x, y)\n",
    "    \n",
    "    # fit cubic spline\n",
    "    cs = CubicSpline(x, y, bc_type=\"natural\")\n",
    "    return cs\n",
    "\n",
    "\n",
    "def gaussian_kernel_smoother(x: pd.Series, y: pd.Series, sigma: float = 2, dropnan: bool = False) -> Tuple[np.ndarray]:\n",
    "    from scipy import ndimage\n",
    "    if dropnan:\n",
    "        x, y = return_finite_only(x, y)\n",
    "\n",
    "    #Â https://stackoverflow.com/a/32905652/9940782\n",
    "    x_g1d = ndimage.gaussian_filter1d(x, sigma, mode=\"reflect\")\n",
    "    y_g1d = ndimage.gaussian_filter1d(y, sigma, mode=\"reflect\")\n",
    "    \n",
    "    return x_g1d, y_g1d\n",
    "\n",
    "\n",
    "def univariate_spline(x: pd.Series, y: pd.Series, **kwargs) -> Callable:\n",
    "    \"\"\"\n",
    "    kwargs:\n",
    "        k: Degree of the smoothing spline\n",
    "        s: smoothing parameter (often requires fitting)\n",
    "    \"\"\"\n",
    "    from scipy import interpolate\n",
    "    x, y = return_finite_only(x, y)\n",
    "\n",
    "    #Â strictly increasing\n",
    "    x, y = strict_increasing(x, y)\n",
    "\n",
    "    spl = interpolate.UnivariateSpline(x, y, **kwargs)\n",
    "    \n",
    "    return spl\n",
    "\n",
    "\n",
    "def smooth_lowess(x, y, kwargs: Dict = {}) -> Tuple[pd.Series]:\n",
    "    from statsmodels.nonparametric.smoothers_lowess import lowess\n",
    "\n",
    "    #Â wrapper for statsmodels lowess\n",
    "    try:\n",
    "        smooth_y = lowess(y, x, return_sorted=False, **kwargs)\n",
    "    except AttributeError:\n",
    "        x, y = x.values.flatten(), y.values.flatten()\n",
    "        smooth_y = lowess(y, x, return_sorted=False, **kwargs)\n",
    "    \n",
    "    df = x.rename(\"x\").to_frame()\n",
    "    df[\"y\"] = smooth_y\n",
    "    df = df.dropna().sort_values(\"x\")\n",
    "    return df[\"x\"], df[\"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "\n",
    "# [v for v in static.data_vars]\n",
    "delta_data = lstm_delta[\"nse\"]\n",
    "feature = \"baseflow_index\"\n",
    "metric = \"nse\"\n",
    "kwargs = {\"vmin\": 0.6, \"vmax\": 1, \"marker\": \"x\"}\n",
    "\n",
    "\n",
    "def plot_scatter_delta_nse_static(\n",
    "    delta_data: pd.DataFrame, \n",
    "    metric: str = \"nse\", \n",
    "    feature: str = \"baseflow_index\", \n",
    "    ylim: Tuple[Optional[float]] = (None, None),\n",
    "    absolute_data: pd.DataFrame = None,\n",
    "    spline: bool = True,\n",
    "    spline_kwargs: Dict = {\"s\": 9, \"k\": 3},\n",
    "    kwargs: Dict = {}\n",
    "):\n",
    "    models = [\"TOPMODEL\", \"ARNOVIC\", \"PRMS\", \"SACRAMENTO\"]\n",
    "    assert all(np.isin(models, delta_data[metric].columns))\n",
    "    #Â get X and y variables\n",
    "    data = delta_data[metric].join(static[feature].to_dataframe())\n",
    "    x = data[feature].astype(\"float64\")\n",
    "    \n",
    "    #Â get the color variable (z)\n",
    "    if absolute_data is not None:\n",
    "        #Â set the color to be the absolute NSE for that basin (LSTM/EALSTM)\n",
    "        absolute_data = absolute_data.loc[data.index, metric].astype(\"float64\")\n",
    "        \n",
    "    f, axs = plt.subplots(2, 2, figsize=(6*2, 4*2))\n",
    "\n",
    "    for ix, model in enumerate(models):\n",
    "        y = data[model].astype(\"float64\")\n",
    "\n",
    "        ax = axs[np.unravel_index(ix, (2, 2))]\n",
    "        s = ax.scatter(\n",
    "            x, y,\n",
    "            c=data[feature] if absolute_data is None else absolute_data,\n",
    "            **kwargs\n",
    "        )\n",
    "        ax.axhline(ls=\":\", color=\"k\", alpha=0.5, label=\"No Improvement\")\n",
    "        ax.set_title(f\"{model}\")\n",
    "        ax.set_ylim(ylim)\n",
    "\n",
    "        if np.unravel_index(ix, (2, 2))[1] == 0:\n",
    "            ax.set_ylabel(f\"$\\Delta${metric.upper()}\")\n",
    "        if np.unravel_index(ix, (2, 2))[0] == 1:\n",
    "            ax.set_xlabel(f\"{feature.capitalize()}\")\n",
    "            \n",
    "        if spline:\n",
    "            sm_x, sm_y = smooth_lowess(x, y)\n",
    "            ax.plot(sm_x, sm_y, c=\"k\", ls=\"--\")\n",
    "        sns.despine()\n",
    "\n",
    "    # colorbar\n",
    "    f.tight_layout()\n",
    "    f.subplots_adjust(right=0.8)\n",
    "    cbar_ax = f.add_axes([0.85, 0.15, 0.05, 0.7])\n",
    "    cbar = f.colorbar(s, cax=cbar_ax)\n",
    "    cbar.set_label(feature.capitalize() if absolute_data is None else f\"LSTM Absolute NSE\")\n",
    "    \n",
    "    return f, axs, data\n",
    "    \n",
    "\n",
    "feature = \"baseflow_index\"\n",
    "f, axs, data = plot_scatter_delta_nse_static(\n",
    "    lstm_delta, \"nse\", feature, \n",
    "    absolute_data=lstm_metric_df,   #Â None\n",
    "    kwargs=kwargs, \n",
    "    spline=True,\n",
    "    spline_kwargs=dict(k=2, s=100),\n",
    "    ylim=(-0.5, 1.5),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = static[\"baseflow_index\"].to_dataframe().join(lstm_metric_df[\"nse\"].rename(\"LSTM\")).join(ealstm_metric_df[\"nse\"].rename(\"EALSTM\"))\n",
    "d.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit splines ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://www.science.smith.edu/~jcrouser/SDS293/labs/lab13-py.html\n",
    "# https://www.analyticsvidhya.com/blog/2018/03/introduction-regression-splines-python-codes/\n",
    "# https://stackoverflow.com/questions/51321100/python-natural-smoothing-splines\n",
    "\n",
    "from patsy import dmatrix, build_design_matrices\n",
    "import statsmodels.api as sm\n",
    "\n",
    "bfi = d.dropna()[\"baseflow_index\"]\n",
    "X = dmatrix(\"bs(x, include_intercept=True, knots=[ 0.3, 0.4, 0.6, 0.8, 0.9])\", data=dict(x=bfi))\n",
    "\n",
    "w = np.ones(6)\n",
    "w = w / w.sum(axis=0, keepdims=1)\n",
    "\n",
    "y = d.dropna()[\"LSTM\"].values.reshape(-1, 1)\n",
    "fit = sm.GLM(y, X).fit()\n",
    "params = fit.params\n",
    "\n",
    "# dmatrix(X.design_info, data=dict(lstm=np.linspace(0.21, 0.89, 10)))\n",
    "# X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.title(\"B-spline basis example (degree=3)\");\n",
    "x = np.linspace(0., 1., 100)\n",
    "y = dmatrix(\"bs(x, df=6, degree=3, include_intercept=True)\", {\"x\": x})\n",
    "b = np.array([1, 1.3, 0.6, 0.9, 0.4, 1.6, 0.7])\n",
    "\n",
    "# b = params\n",
    "# x = lstm\n",
    "# y = X\n",
    "\n",
    "plt.plot(x, y*b);\n",
    "plt.plot(x, np.dot(y, b), color='k', linewidth=3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = static[\"baseflow_index\"].to_dataframe().join(lstm_metric_df[\"nse\"].rename(\"LSTM\")).join(ealstm_metric_df[\"nse\"].rename(\"EALSTM\"))\n",
    "\n",
    "d = nse_df.join(static[\"baseflow_index\"].to_dataframe())\n",
    "d = d.dropna()\n",
    "d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_smooth_line(df: pd.DataFrame, feature: str, model: str, ax):\n",
    "    px, py = smooth_lowess(df[feature], df[model])\n",
    "    ax.plot(px, py, label=model, ls=\"-\")\n",
    "    return ax\n",
    "\n",
    "\n",
    "\n",
    "def plot_scatter_lowess_feature_nse(feature: str):\n",
    "    d = nse_df.join(static[feature].to_dataframe()).dropna()\n",
    "    \n",
    "    alpha_scatter = 0.3\n",
    "    s = 4\n",
    "\n",
    "    f, ax = plt.subplots()\n",
    "    ax.scatter(d[feature], d[\"LSTM\"], color=sns.color_palette()[0], marker=\"x\", alpha=alpha_scatter, s=s)\n",
    "    ax = plot_smooth_line(df=d, feature=feature, model=\"LSTM\", ax=ax)\n",
    "\n",
    "    ax.scatter(d[feature], d[\"EALSTM\"], color=sns.color_palette()[1], marker=\"x\", alpha=alpha_scatter, s=s)\n",
    "    ax = plot_smooth_line(df=d, feature=feature, model=\"EALSTM\", ax=ax)\n",
    "\n",
    "    if \"PRMS\" in d.columns:\n",
    "        ax.scatter(d[feature], d[\"PRMS\"], color=sns.color_palette()[2], marker=\"x\", alpha=alpha_scatter, s=s)\n",
    "        ax = plot_smooth_line(df=d, feature=feature, model=\"PRMS\", ax=ax)\n",
    "\n",
    "        ax.scatter(d[feature], d[\"Sacramento\"], color=sns.color_palette()[3], marker=\"x\", alpha=alpha_scatter, s=s)\n",
    "        ax = plot_smooth_line(df=d, feature=feature, model=\"Sacramento\", ax=ax)\n",
    "\n",
    "        ax.scatter(d[feature], d[\"TOPMODEL\"], color=sns.color_palette()[4], marker=\"x\", alpha=alpha_scatter, s=s)\n",
    "        ax = plot_smooth_line(df=d, feature=feature, model=\"TOPMODEL\", ax=ax)\n",
    "\n",
    "        ax.scatter(d[feature], d[\"VIC\"], color=sns.color_palette()[5], marker=\"x\", alpha=alpha_scatter, s=s)\n",
    "        ax = plot_smooth_line(df=d, feature=feature, model=\"VIC\", ax=ax)\n",
    "\n",
    "    ax.set_xlabel(feature)\n",
    "    ax.set_ylabel(\"NSE\")\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.legend()\n",
    "    sns.despine()\n",
    "    return ax\n",
    "\n",
    "    \n",
    "ax = plot_scatter_lowess_feature_nse(\"aridity\")\n",
    "ax.set_xlabel(\"Aridity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plot_scatter_lowess_feature_nse(\"baseflow_index\")\n",
    "ax.set_xlabel(\"Baseflow Index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Runoff Coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_wateryear(dt):\n",
    "    \"\"\"https://stackoverflow.com/a/52615358/9940782\"\"\"\n",
    "    dt = pd.Timestamp(dt)\n",
    "    if dt.month >= 10:\n",
    "        return(pd.datetime(dt.year+1,1,1).year)\n",
    "    else:\n",
    "        return(pd.datetime(dt.year,1,1).year)\n",
    "\n",
    "ds_wy = ds.assign_coords(wy=(\"time\", [assign_wateryear(dt) for dt in ds.time.values]))\n",
    "lstm_preds_wy = lstm_preds.assign_coords(wy=(\"time\", [assign_wateryear(dt) for dt in lstm_preds.time.values]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wy_sum = ds_wy.groupby(\"wy\").sum(dim=\"time\")\n",
    "runoff_coeff_obs = (wy_sum[\"discharge_spec\"] / wy_sum[\"precipitation\"]).mean(\"wy\")\n",
    "obs_rc = runoff_coeff_obs.to_dataframe(\"runoff_coeff\")\n",
    "obs_rc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_wy_sum = lstm_preds_wy.groupby(\"wy\").sum(dim=\"time\")\n",
    "runoff_coeff_sim = (lstm_wy_sum[\"sim\"] / wy_sum[\"precipitation\"].sel(wy=lstm_wy_sum[\"wy\"])).mean(\"wy\")\n",
    "sim_rc = runoff_coeff_sim.to_dataframe(\"runoff_coeff\")\n",
    "sim_rc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc_comparison = obs_rc.rename({\"runoff_coeff\": \"obs\",}, axis=1).join(sim_rc.rename({\"runoff_coeff\": \"sim\",}, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "static = static.merge(obs_rc.to_xarray())\n",
    "plot_scatter_lowess_feature_nse(\"runoff_coeff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_test = [\"low_q_freq\", \"Q95\", \"baseflow_index_ceh\", \"aridity\"]\n",
    "feature = \"low_q_freq\"\n",
    "# f, axs, data = plot_scatter_delta_nse_static(\n",
    "#     lstm_delta, \"nse\", feature, \n",
    "#     absolute_data=lstm_metric_df,\n",
    "#     spline_kwargs=dict(k=3, s=100),\n",
    "#     kwargs=kwargs, ylim=(-0.5, 1.5)\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bin / discretize functions marginalia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def bin_and_attach_static_features(delta_dict, metric: str = \"nse\"):\n",
    "#     # create bin boundaries \n",
    "#     cutoff = np.linspace(0, 1, 6)\n",
    "#     cutoff = np.insert(cutoff, 0, -np.inf)\n",
    "\n",
    "#     # remove nans from the delta df\n",
    "#     bin_data = delta_dict[\"nse\"].dropna()\n",
    "\n",
    "#     # split into groups\n",
    "#     binned_data = pd.DataFrame(np.digitize(bin_data, cutoff, right=True))\n",
    "#     binned_data.index = bin_data.index\n",
    "#     binned_data.columns = bin_data.columns\n",
    "#     binned_data = binned_data.join(float_static)\n",
    "    \n",
    "#     return binned_data, cutoff\n",
    "    \n",
    "\n",
    "# def discretize(data, bins):\n",
    "#     split = np.array_split(np.sort(data), bins)\n",
    "#     cutoffs = [x[-1] for x in split]\n",
    "#     cutoffs = cutoffs[:-1]\n",
    "# #     discrete = np.digitize(data, cutoffs, right=True)\n",
    "#     return cutoffs\n",
    "\n",
    "# # binned_data, cutoff = bin_and_attach_static_features(lstm_delta)\n",
    "# # binned_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ealstm_delta_nse = ealstm_delta[\"nse\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(lstm_delta_nse.mean())\n",
    "display(ealstm_delta_nse.median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### % Delta NSE > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_delta_nse_ltx = lstm_delta_nse.dropna() #.drop(\"EALSTM\", axis=1)\n",
    "ealstm_delta_nse_ltx = ealstm_delta_nse.dropna() #.drop(\"LSTM\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"% Basins where $\\Delta$NSE > 0\"\n",
    "latex_df = pd.concat(\n",
    "    [\n",
    "        ((lstm_delta_nse_ltx > 0).sum(axis=0) / lstm_delta_nse_ltx.count()).to_frame().rename({0: \"LSTM\"}, axis=1),\n",
    "        ((ealstm_delta_nse_ltx > 0).sum(axis=0) / ealstm_delta_nse_ltx.count()).to_frame().rename({0: \"EA LSTM\"}, axis=1)\n",
    "    ], axis=1\n",
    ")\n",
    "# latex_df.columns = [(\"% Basins where $\\Delta$NSE > 0\", \"LSTM\"), (\"% Basins where $\\Delta$NSE > 0\", \"EA LSTM\")]\n",
    "latex_df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(latex_df.to_latex(float_format=\"%.2f\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spatial Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "assert (data_dir / \"RUNOFF/natural_earth_hires/ne_10m_admin_0_countries.shp\").exists(), \"Download the natural earth hires from https://www.naturalearthdata.com/http//www.naturalearthdata.com/download/10m/cultural/ne_10m_admin_0_countries.zip\"\n",
    "\n",
    "world = gpd.read_file(data_dir / \"RUNOFF/natural_earth_hires/ne_10m_admin_0_countries.shp\")\n",
    "uk = world.query(\"ADM0_A3 == 'GBR'\")\n",
    "uk.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matching_stations = list(set(fuse_ds.station_id.values).intersection(set(lstm_preds.station_id.values)))\n",
    "len(matching_stations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shp_path = data_dir / \"CAMELS_GB_DATASET/Catchment_Boundaries/CAMELS_GB_catchment_boundaries.shp\"\n",
    "assert shp_path.exists()\n",
    "\n",
    "# load in the shapefile\n",
    "geo_df = gpd.read_file(shp_path)\n",
    "geo_df['ID_STRING'] = geo_df['ID_STRING'].astype('int')\n",
    "geo_df.crs = {'init' :'epsg:27700'}  # 4277  27700"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_df = lstm_delta_nse.reset_index()\n",
    "# display(delta_df.head())\n",
    "\n",
    "polygons = False\n",
    "\n",
    "# create spatial dataframe\n",
    "assert delta_df['station_id'].dtype == geo_df['ID_STRING'].dtype, \"Need to be the same type (integer)\"\n",
    "delta_gdf = gpd.GeoDataFrame(\n",
    "    geo_df.set_index('ID_STRING').join(delta_df.set_index('station_id'))\n",
    ").loc[matching_stations]\n",
    "\n",
    "\n",
    "if not polygons:\n",
    "    static_df = static.to_dataframe()\n",
    "    d = static_df[[\"gauge_lat\", \"gauge_lon\"]]\n",
    "\n",
    "    points = gpd.GeoSeries(gpd.points_from_xy(d[\"gauge_lon\"], d[\"gauge_lat\"]), index=d.index)\n",
    "    points.name = \"geometry\"\n",
    "    delta_gdf = delta_gdf.drop(\"geometry\", axis=1).join(points)\n",
    "    delta_gdf.crs = {'init' :'epsg:4326'}\n",
    "\n",
    "\n",
    "delta_gdf = delta_gdf.to_crs(epsg=4326)\n",
    "\n",
    "delta_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catchment_ids = [int(c) for c in [\"12002\", \"15006\", \"27009\", \"27034\", \"27041\", \"39001\", \"39081\", \"43021\", \"47001\", \"54001\", \"54057\", \"71001\", \"84013\",]]\n",
    "names = static[\"gauge_name\"].to_dataframe()\n",
    "poly = geo_df.set_index(\"ID\").loc[catchment_ids].join(names).to_crs(epsg=4326)\n",
    "pts = gpd.GeoDataFrame(points.loc[catchment_ids]).join(names)\n",
    "\n",
    "color = None  #Â sns.color_palette()[0] None\n",
    "\n",
    "f, ax = plt.subplots(figsize=(15, 6))\n",
    "points.plot(ax=ax, color=\"grey\", alpha=0.6, markersize=2)\n",
    "uk.plot(facecolor='none', edgecolor='k', ax=ax, linewidth=0.3)\n",
    "poly.plot(ax=ax, facecolor=\"grey\",  alpha=0.5, edgecolor=\"k\", linewidth=0.5)  #Â \"gauge_name\", cmap=\"Dark2\",\n",
    "pts.plot(ax=ax, color=color, edgecolor=\"k\")  # \"gauge_name\", cmap=\"Dark2\", legend=True\n",
    "\n",
    "ax.axis('off')\n",
    "ax.set_xlim([-8.2, 2.1])\n",
    "ax.set_ylim([50, 59.5])\n",
    "\n",
    "\n",
    "# for x, y, label in zip(pts.geometry.x, pts.geometry.y, pts.name):\n",
    "#     ax.annotate(label, xy=(x, y), xytext=(3, 3), textcoords=\"offset points\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# poly[\"gauge_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_spatial_dataframe(delta_df: pd.DataFrame, geo_df: gpd.GeoDataFrame, polygon: bool = False) -> gpd.GeoDataFrame:\n",
    "    matching_stations = list(set(fuse_ds.station_id.values).intersection(set(lstm_preds.station_id.values)))\n",
    "    assert delta_df['station_id'].dtype == geo_df['ID_STRING'].dtype, \"Need to be the same type (integer)\"\n",
    "    delta_gdf = gpd.GeoDataFrame(\n",
    "        geo_df.set_index('ID_STRING').join(delta_df.set_index('station_id'))\n",
    "    ).loc[matching_stations]\n",
    "    if not polygons:\n",
    "        static_df = static.to_dataframe()\n",
    "        d = static_df[[\"gauge_lat\", \"gauge_lon\"]]\n",
    "\n",
    "        points = gpd.GeoSeries(gpd.points_from_xy(d[\"gauge_lon\"], d[\"gauge_lat\"]), index=d.index)\n",
    "        points.name = \"geometry\"\n",
    "        delta_gdf = delta_gdf.drop(\"geometry\", axis=1).join(points)\n",
    "        delta_gdf.crs = {'init' :'epsg:4326'}\n",
    "\n",
    "\n",
    "    delta_gdf = delta_gdf.to_crs(epsg=4326)\n",
    "    \n",
    "    return delta_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_delta_gdf = create_spatial_dataframe(delta_df=lstm_delta_nse.dropna().reset_index(), geo_df=geo_df)\n",
    "ealstm_delta_gdf = create_spatial_dataframe(delta_df=ealstm_delta_nse.dropna().reset_index(), geo_df=geo_df)\n",
    "\n",
    "# lstm_delta_gdf.to_file(data_dir / \"RUNOFF/delta_shp_files/lstm.shp\")\n",
    "# ealstm_delta_gdf.to_file(data_dir / \"RUNOFF/delta_shp_files/ealstm.shp\")\n",
    "\n",
    "# #Â write shapefile of locations\n",
    "# gauge_names = static.to_dataframe()[\"gauge_name\"]\n",
    "# lstm_delta_gdf[[\"ID\", \"geometry\"]].join(gauge_names).to_file(data_dir/\"RUNOFF/point_shp.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(lstm_delta_gdf.head())\n",
    "display(ealstm_delta_gdf.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lighter colors are the basins that have a higher delta NSE than the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_wb = xr.open_dataset(data_dir / \"RUNOFF/bool_water_balance_20pct.nc\")\n",
    "bool_wb = bool_wb.to_array().isel(variable=0).drop(\"variable\")\n",
    "wb_stations = bool_wb.where(bool_wb, drop=True).station_id\n",
    "non_wb_stations = bool_wb.where(~bool_wb, drop=True).station_id\n",
    "wb_stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_gdf.loc[np.isin(delta_gdf[\"ID\"], wb_stations.values)].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, List, Tuple\n",
    "\n",
    "\n",
    "def _cdf_plot(data, label: str, ax, **kwargs) -> ax:\n",
    "    sns.kdeplot(\n",
    "        data,\n",
    "        cumulative=True,\n",
    "        legend=False, ax=ax,\n",
    "        label=label,\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "    return ax\n",
    "\n",
    "def plot_cdf(error_data, metric: str, models: List[str], clip: Optional[Tuple] = None, ax = None):\n",
    "    colors = sns.color_palette()\n",
    "    kwargs_dict = {\n",
    "        \"TOPMODEL\": {\"linewidth\": 2, \"alpha\":0.8, \"color\": colors[2], \"clip\": clip},\n",
    "        \"PRMS\": {\"linewidth\": 2, \"alpha\":0.8, \"color\": colors[3], \"clip\": clip},\n",
    "        \"ARNOVIC\": {\"linewidth\": 2, \"alpha\":0.8, \"color\": colors[4], \"clip\": clip},\n",
    "        \"VIC\": {\"linewidth\": 2, \"alpha\":0.8, \"color\": colors[4], \"clip\": clip},\n",
    "        \"SACRAMENTO\": {\"linewidth\": 2, \"alpha\":0.8, \"color\": colors[5], \"clip\": clip},\n",
    "        \"EALSTM\": {\"linewidth\": 3, \"alpha\": 1, \"color\": colors[1], \"clip\": clip},\n",
    "        \"LSTM\": {\"linewidth\": 3, \"alpha\": 1, \"color\": colors[0], \"clip\": clip},\n",
    "    }\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(12, 3))\n",
    "\n",
    "    for ix, model in enumerate(models):\n",
    "        data = error_data[model].dropna()\n",
    "        label = f\"{model}: {error_data[model].median():.2f}\"\n",
    "        kwargs = kwargs_dict[model]\n",
    "        ax = _cdf_plot(data, label, ax=ax, **kwargs) \n",
    "\n",
    "        ax.axvline(error_data[model].dropna().median(), ls=\"--\", color=kwargs_dict[model][\"color\"])\n",
    "\n",
    "    ax.set_xlim(clip)\n",
    "    ax.set_xlabel(metric)\n",
    "    ax.set_ylabel(\"Cumulative density\")\n",
    "    title = f\"Cumuluative Density Function of Station {metric} Scores\"\n",
    "    ax.set_title(title)\n",
    "    sns.despine()\n",
    "    ax.legend()\n",
    "    \n",
    "    return ax\n",
    "\n",
    "# ax = plot_cdf(q95_rmse_df, metric=\"RMSE\", sids=ml_sids, clip=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isin(delta_gdf[\"ID\"], wb_stations.values).sum()\n",
    "(~np.isin(delta_gdf[\"ID\"], wb_stations.values)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"TOPMODEL\", \"ARNOVIC\", \"PRMS\", \"SACRAMENTO\"]\n",
    "\n",
    "f, axs = plt.subplots(2, 1, figsize=((12, 4*2)))\n",
    "ax = axs[0]\n",
    "plot_cdf(delta_gdf.loc[np.isin(delta_gdf[\"ID\"], wb_stations.values)], metric=\"ânse\", models=models, clip=(0, 0.8), ax=ax)\n",
    "ax.set_title(\"âNSE in Water Balancing Stations [n=323]\")\n",
    "ax.grid()\n",
    "\n",
    "ax = axs[1]\n",
    "plot_cdf(delta_gdf.loc[~np.isin(delta_gdf[\"ID\"], wb_stations.values)], metric=\"ânse\", models=models, clip=(0, 0.8), ax=ax)\n",
    "ax.set_title(\"âNSE in Non Water Balancing Stations [n=195]\")\n",
    "ax.grid()\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delta_gdf.loc[np.isin(delta_gdf[\"ID\"], wb_stations.values), \"TOPMODEL\"]\n",
    "# delta_gdf.loc[(~np.isin(delta_gdf[\"ID\"], wb_stations.values)), \"TOPMODEL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip=(0, 0.8)\n",
    "colors = sns.color_palette()\n",
    "linewidth = 2\n",
    "wb_kwargs = {\n",
    "    \"TOPMODEL\": {\"linewidth\": linewidth, \"alpha\": 0.8, \"color\": colors[2], \"clip\": clip},\n",
    "    \"PRMS\": {\"linewidth\": linewidth, \"alpha\": 0.8, \"color\": colors[3], \"clip\": clip},\n",
    "    \"ARNOVIC\": {\"linewidth\": linewidth, \"alpha\": 0.8, \"color\": colors[4], \"clip\": clip},\n",
    "    \"VIC\": {\"linewidth\": linewidth, \"alpha\": 0.8, \"color\": colors[4], \"clip\": clip},\n",
    "    \"SACRAMENTO\": {\"linewidth\": linewidth, \"alpha\": 0.8, \"color\": colors[5], \"clip\": clip},\n",
    "}\n",
    "nonwb_kwargs = {\n",
    "    \"TOPMODEL\": {\"linewidth\": linewidth, \"alpha\": 0.8, \"color\": colors[2], \"clip\": clip, \"ls\": \"--\"},\n",
    "    \"PRMS\": {\"linewidth\": linewidth, \"alpha\": 0.8, \"color\": colors[3], \"clip\": clip, \"ls\": \"--\"},\n",
    "    \"ARNOVIC\": {\"linewidth\": linewidth, \"alpha\": 0.8, \"color\": colors[4], \"clip\": clip, \"ls\": \"--\"},\n",
    "    \"VIC\": {\"linewidth\": linewidth, \"alpha\": 0.8, \"color\": colors[4], \"clip\": clip, \"ls\": \"--\"},\n",
    "    \"SACRAMENTO\": {\"linewidth\": linewidth, \"alpha\": 0.8, \"color\": colors[5], \"clip\": clip, \"ls\": \"--\"},\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "f, axs = plt.subplots(len(models), 1, figsize=((12, 3 * len(models))))\n",
    "for ix, model in enumerate(models):\n",
    "    ax = axs[ix]\n",
    "    _wb_data = delta_gdf.loc[np.isin(delta_gdf[\"ID\"], wb_stations.values), model]\n",
    "    _non_wb_data = delta_gdf.loc[~np.isin(delta_gdf[\"ID\"], wb_stations.values), model]\n",
    "    _cdf_plot(data=_wb_data, label=f\"{model} Water Balance\", ax=ax, **wb_kwargs[model])\n",
    "    _cdf_plot(data=_non_wb_data, label=f\"{model} Non-Water Balance\", ax=ax, **nonwb_kwargs[model])\n",
    "    ax.set_xlim(clip)\n",
    "    ax.legend()\n",
    "    ax.grid()\n",
    "    sns.despine()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WATER_BALANCE_ONLY = False\n",
    "\n",
    "markersize = 10\n",
    "kwargs = {\"vmin\": 0, \"vmax\": 0.25, \"cmap\": \"viridis\", \"markersize\": markersize}\n",
    "models = [\"TOPMODEL\", \"SACRAMENTO\", \"ARNOVIC\", \"PRMS\"]\n",
    "\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "f, axs = plt.subplots(1, 4, figsize=(15, 6*4))\n",
    "\n",
    "\n",
    "for model, ax in zip(models, axs):\n",
    "#     delta_gdf.plot(model, ax=ax, **kwargs)\n",
    "    ax.set_title(f\"$\\Delta$NSE ({model})\")\n",
    "    # plot the surrounding lines\n",
    "    uk.plot(facecolor='none', edgecolor='k', ax=ax, linewidth=0.3)\n",
    "    # plot the chloropleth\n",
    "    if WATER_BALANCE_ONLY:\n",
    "        delta_gdf.loc[np.isin(delta_gdf[\"ID\"], wb_stations.values)].plot(model, ax=ax, **kwargs);\n",
    "    else:\n",
    "        delta_gdf.plot(model, ax=ax, **kwargs);\n",
    "    ax.set_xlim([-8.2, 2.1])\n",
    "    ax.set_ylim([50, 59.5])\n",
    "\n",
    "\n",
    "# divider = make_axes_locatable(axs[3])\n",
    "# cax = divider.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "# uk.plot(facecolor='none', edgecolor='k', ax=axs[3], linewidth=0.3)\n",
    "# delta_gdf.plot(\"PRMS\", ax=axs[3], legend=True, cax=cax, **kwargs)\n",
    "\n",
    "for ax in axs:\n",
    "    ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_point_static_gdf(feature: str) -> gpd.GeoDataFrame:\n",
    "    gdf = geo_df.set_index(\"ID\").join(static[feature].to_dataframe()).to_crs(epsg=4326)\n",
    "    gdf = gpd.GeoDataFrame(gdf.drop(\"geometry\", axis=1).join(points))\n",
    "    return gdf\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "variable = \"baseflow_index\"\n",
    "vrange = (None, None)\n",
    "\n",
    "g = make_point_static_gdf(variable)\n",
    "vrange = (\n",
    "    np.max([0, g[variable].describe()[\"25%\"] - (g[variable].describe()[\"std\"] * 0.5)]),\n",
    "    g[variable].describe()[\"75%\"] + (g[variable].describe()[\"std\"] * 0.5)\n",
    ")\n",
    "label = \"Baseflow Index\"\n",
    "# label = \"$\\Delta$NSE\"\n",
    "\n",
    "\n",
    "f, ax = plt.subplots(figsize=(12, 8))\n",
    "# gplt.polyplot(uk, ax=ax)\n",
    "uk.plot(facecolor='none', edgecolor='k', ax=ax, linewidth=0.3)\n",
    "g.plot(variable, ax=ax, vmin=vrange[0], vmax=vrange[1], cmap=\"viridis\", legend=True, legend_kwds={\"label\": label})\n",
    "# delta_gdf.plot(model, ax=ax, legend=True, legend_kwds={\"label\": label}, **kwargs);\n",
    "ax.axis('off');\n",
    "ax.set_xlim([-8.2, 2.1])\n",
    "ax.set_ylim([50, 59.5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geoplot as gplt\n",
    "import matplotlib\n",
    "# https://github.com/ResidentMario/geoplot/blob/bdffcd6763b8c948ce4d0308855a4df7ef9b7f1e/geoplot/geoplot.py#L467\n",
    "# https://residentmario.github.io/geoplot/plot_references/plot_reference.html\n",
    "#Â Note: can't get the legend for this data\n",
    "\n",
    "f, axs = plt.subplots(1, 4, figsize=(15, 6*4))\n",
    "\n",
    "for model, ax in zip(models, axs):\n",
    "#     delta_gdf.plot(model, ax=ax, **kwargs)\n",
    "    ax.set_title(f\"$\\Delta$NSE ({model})\")\n",
    "    \n",
    "    gplt.polyplot(uk, ax=ax)\n",
    "#     delta_gdf.plot(model, ax=ax, vmin=0, vmax=0.15)\n",
    "    cmap = matplotlib.cm.get_cmap('viridis')\n",
    "    gplt.kdeplot(\n",
    "        delta_gdf[[model, \"geometry\"]], \n",
    "        cmap=cmap, \n",
    "        shade=True, \n",
    "        shade_lowest=False, clip=uk, ax=ax, \n",
    "#         **{\"vmin\": 0, \"vmax\": 0.05}\n",
    "    )\n",
    "    ax.set_xlim([-8.2, 2.1])\n",
    "    ax.set_ylim([50, 59.5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_point_static_gdf(feature: str) -> gpd.GeoDataFrame:\n",
    "    gdf = geo_df.set_index(\"ID\").join(static[feature].to_dataframe()).to_crs(epsg=4326)\n",
    "    gdf = gpd.GeoDataFrame(gdf.drop(\"geometry\", axis=1).join(points))\n",
    "    return gdf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # geo_df\n",
    "# q_mean = geo_df.set_index(\"ID\").join(static[\"q_mean\"].to_dataframe()).to_crs(epsg=4326)\n",
    "# q_mean = gpd.GeoDataFrame(q_mean.drop(\"geometry\", axis=1).join(points))\n",
    "q_mean = make_point_static_gdf(\"q_mean\")\n",
    "\n",
    "# # q_mean.crs = {'init' :'epsg:4326'}\n",
    "\n",
    "# f, ax = plt.subplots()\n",
    "# cmap = matplotlib.cm.get_cmap('plasma')\n",
    "# gplt.polyplot(uk, ax=ax)\n",
    "# gplt.kdeplot(\n",
    "#     q_mean[[\"q_mean\", \"geometry\"]], \n",
    "#     cmap=cmap, \n",
    "#     shade=True, \n",
    "#     shade_lowest=True, clip=uk, ax=ax, \n",
    "#     **{\"vmin\": None, \"vmax\": 2.640000}\n",
    "# )\n",
    "# # ax.set_xlim([-8.2, 2.1])\n",
    "# # ax.set_ylim([50, 59.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable = \"q_mean\"\n",
    "vrange = (None, None)\n",
    "\n",
    "g = make_point_static_gdf(variable)\n",
    "vrange = (\n",
    "    np.max([0, g[variable].describe()[\"25%\"] - (g[variable].describe()[\"std\"] * 0.5)]),\n",
    "    g[variable].describe()[\"75%\"] + (g[variable].describe()[\"std\"] * 0.5)\n",
    ")\n",
    "label = variable + \" [mm day$^{-1}$]\"\n",
    "\n",
    "\n",
    "f, ax = plt.subplots(figsize=(12, 8))\n",
    "# gplt.polyplot(uk, ax=ax)\n",
    "uk.plot(facecolor='none', edgecolor='k', ax=ax, linewidth=0.3)\n",
    "g.plot(variable, ax=ax, vmin=vrange[0], vmax=vrange[1], cmap=\"viridis\", legend=True, legend_kwds={\"label\": label})\n",
    "ax.axis('off');\n",
    "ax.set_xlim([-8.2, 2.1])\n",
    "ax.set_ylim([50, 59.5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable = \"low_prec_freq\"\n",
    "\n",
    "# g = make_point_static_gdf(variable)\n",
    "# vrange = (None, None)\n",
    "# vrange = (\n",
    "#     np.max([0, g[variable].describe()[\"25%\"] - (g[variable].describe()[\"std\"] * 0.5)]),\n",
    "#     g[variable].describe()[\"75%\"] + (g[variable].describe()[\"std\"] * 0.5)\n",
    "# )\n",
    "# label = variable + \" [mm day$^{-1}$]\"\n",
    "\n",
    "# f, ax = plt.subplots(figsize=(12, 8))\n",
    "# # gplt.polyplot(uk, ax=ax)\n",
    "# uk.plot(facecolor='none', edgecolor='k', ax=ax, linewidth=0.3)\n",
    "# g.plot(variable, ax=ax, vmin=vrange[0], vmax=vrange[1], cmap=\"viridis\", legend=True, legend_kwds={\"label\": label})\n",
    "# ax.axis('off');\n",
    "# ax.set_xlim([-8.2, 2.1])\n",
    "# ax.set_ylim([50, 59.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable = \"low_prec_freq\"\n",
    "\n",
    "# g = make_point_static_gdf(variable)\n",
    "# vrange = (None, None)\n",
    "# vrange = (\n",
    "#     np.max([0, g[variable].describe()[\"25%\"] - (g[variable].describe()[\"std\"] * 0.5)]),\n",
    "#     g[variable].describe()[\"75%\"] + (g[variable].describe()[\"std\"] * 0.5)\n",
    "# )\n",
    "# label = variable + \" [mm day$^{-1}$]\"\n",
    "\n",
    "# f, ax = plt.subplots(figsize=(12, 8))\n",
    "# # gplt.polyplot(uk, ax=ax)\n",
    "# uk.plot(facecolor='none', edgecolor='k', ax=ax, linewidth=0.3)\n",
    "# g.plot(variable, ax=ax, vmin=vrange[0], vmax=vrange[1], cmap=\"viridis\", legend=True, legend_kwds={\"label\": label})\n",
    "# ax.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "\n",
    "def plot_static_feature_map(feature: str, label: str = None, ax = None, cmap: str = \"viridis\"):\n",
    "    if ax is None:\n",
    "        f, ax = plt.subplots()\n",
    "    else:\n",
    "        f = plt.gcf()\n",
    "    g = make_point_static_gdf(feature)\n",
    "\n",
    "    vrange = (\n",
    "        np.max([0, g[feature].describe()[\"25%\"] - (g[feature].describe()[\"std\"] * 0.5)]),\n",
    "        g[feature].describe()[\"75%\"] + (g[feature].describe()[\"std\"] * 0.5)\n",
    "    )\n",
    "    \n",
    "    uk.plot(facecolor='none', edgecolor='k', ax=ax, linewidth=0.3)\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.new_vertical(size=\"5%\", pad=0.7, pack_start=True)\n",
    "    f.add_axes(cax)\n",
    "\n",
    "    g.plot(feature, ax=ax, vmin=vrange[0], vmax=vrange[1], cmap=cmap, legend=True, cax=cax, legend_kwds={\"label\": label, \"orientation\": \"horizontal\"})\n",
    "    ax.axis('off');\n",
    "    ax.set_xlim([-8.2, 2.1])\n",
    "    ax.set_ylim([50, 59.5])\n",
    "\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(15, 8))\n",
    "\n",
    "feature = \"q_mean\"\n",
    "label = \" Mean Discharge (Q) [mm day$^{-1}$]\"\n",
    "plot_static_feature_map(feature=feature, label=label, ax=axs[0])\n",
    "\n",
    "feature = \"Q5\"\n",
    "label = feature + \" [mm day$^{-1}$]\"\n",
    "plot_static_feature_map(feature=feature, label=label, ax=axs[1])\n",
    "\n",
    "feature = \"low_prec_freq\"\n",
    "label = \"Frequency of dry days (< 1 mm d$^{-1}$1) [d yr$^{-1}$]\"\n",
    "plot_static_feature_map(feature=feature, label=label, ax=axs[2], cmap=\"Reds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore Delta NSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What patterns in delta nse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spearmans Rank Correlation between static features & DeltaNSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_nse = lstm_delta_nse\n",
    "stations = [sid for sid in delta_nse[\"TOPMODEL\"].dropna().index]\n",
    "models = [\"TOPMODEL\", \"PRMS\", \"SACRAMENTO\", \"ARNOVIC\"]\n",
    "\n",
    "# numerical non nan rows\n",
    "static_ = static_df.loc[stations, (static_df.dtypes == \"float64\")]\n",
    "static_ = static_df.loc[:, ~(static_df.isnull().mean(axis=0) > 0)]\n",
    "\n",
    "all_spearmans = {}\n",
    "for model in models:\n",
    "    spearmans_rank = defaultdict(dict)\n",
    "    for static_feature in static_.columns:\n",
    "        a = static_df.loc[stations, static_feature]\n",
    "        b = delta_nse.loc[stations, model]\n",
    "        assert a.isnull().mean() == 0, f\"{static_feature}\"\n",
    "\n",
    "        res = spearmanr(a, b)\n",
    "        spearmans_rank[static_feature][\"correlation\"] = res.correlation\n",
    "        spearmans_rank[static_feature][\"pvalue\"] = res.pvalue\n",
    "\n",
    "    spear_df = pd.DataFrame(spearmans_rank).T.reset_index().rename({\"index\": \"feature\"}, axis=1)\n",
    "    all_spearmans[model] = spear_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "\n",
    "def get_intersection_of_significant_features(all_spearmans: Dict[str, pd.DataFrame],p=0.01) -> List[str]:\n",
    "    # get the features that have a significant correlation (p<0.01)\n",
    "    all_features = []\n",
    "    \n",
    "    models = [\"TOPMODEL\", \"PRMS\", \"SACRAMENTO\", \"ARNOVIC\"]\n",
    "    for ix, model in enumerate(models):\n",
    "        sign_df = all_spearmans[model].loc[all_spearmans[model][\"pvalue\"] < p]\n",
    "        all_features.append(sign_df[\"feature\"].to_list())\n",
    "\n",
    "    intersecting_features = set.intersection(*[set(feat) for feat in all_features])\n",
    "    return list(intersecting_features)\n",
    "\n",
    "intersecting_features = get_intersection_of_significant_features(all_spearmans, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_long_form_dataset(all_spearmans: Dict[str, pd.DataFrame]) -> pd.DataFrame:\n",
    "    # create long form dataset\n",
    "    all_correlations = []\n",
    "    models = [k for k in all_spearmans.keys()]\n",
    "    for ix, model in enumerate(models):\n",
    "        df = all_spearmans[model]\n",
    "        df[\"model\"] = [model for _ in range(len(df))]\n",
    "        all_correlations.append(df)\n",
    "\n",
    "    all_correlations = pd.concat(all_correlations)\n",
    "    return all_correlations\n",
    "\n",
    "all_correlations = create_long_form_dataset(all_spearmans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_largest = 10\n",
    "# def plot_the_10_significant_highest_correlations(all_spearmans: Dict[str, pd.DataFrame], p_value: float = 0.01, n_largest:int = 10):\n",
    "# 1. get intersection of features for all models that have p<p_value\n",
    "intersecting_features = get_intersection_of_significant_features(all_spearmans, 0.01)\n",
    "#Â 2. create long form dataframe\n",
    "all_correlations = create_long_form_dataset(all_spearmans)\n",
    "# 3. subset the features that are significant for all models\n",
    "all_correlations = all_correlations.loc[np.isin(all_correlations[\"feature\"], intersecting_features)]\n",
    "# drop the matching baseflow index\n",
    "all_correlations = all_correlations[~np.isin(all_correlations[\"feature\"], [\"baseflow_index_ceh\", \"\"])]\n",
    "#Â 4. subset the n features with the largest mean correlation (across the 4 models)\n",
    "n_largest_features = all_correlations.groupby(\"feature\").median()[\"correlation\"].abs().nlargest(n_largest).index\n",
    "all_correlations = all_correlations.loc[np.isin(all_correlations[\"feature\"], n_largest_features)]\n",
    "all_correlations = all_correlations.sort_values([\"correlation\"])\n",
    "# 5. subset the n largest features\n",
    "all_correlations\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "sns.barplot(x=\"feature\", y=\"correlation\", data=all_correlations, ax=ax, color=\"grey\")   # hue=\"model\", \n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha=\"right\")\n",
    "ax.set_title(f\"Top {n_largest} features: Abs(Correlation($\\Delta$NSE, Feature))\")\n",
    "ax.set_ylabel(\"$\\\\rho$($\\Delta$NSE, feature)\")\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â plot correlation for top n features for each model (split by model delta nse)\n",
    "if False:\n",
    "    f, axs = plt.subplots(4, 1, figsize=(12, 4*4))\n",
    "    plot_all = False\n",
    "    nlargest = 10\n",
    "\n",
    "    for ix, model in enumerate(models):\n",
    "        ax = axs[ix]\n",
    "        if plot_all:\n",
    "            #Â only select those with p values below X point\n",
    "            sign_df = all_spearmans[model].loc[all_spearmans[model][\"pvalue\"] < 0.01]\n",
    "            sign_df.sort_values(\"correlation\").set_index(\"feature\")[\"correlation\"].plot.bar(ax=ax)\n",
    "        else:\n",
    "            #Â Plot Intersecting features\n",
    "            intersect_df = all_spearmans[model].set_index(\"feature\").loc[list(intersecting_features)]\n",
    "            n_largest_features = intersect_df[\"correlation\"].abs().nlargest(nlargest).index\n",
    "            sort_df = intersect_df.loc[n_largest_features].sort_values(\"correlation\")[\"correlation\"]\n",
    "            sort_df.plot.bar(ax=ax)\n",
    "        ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha=\"right\")\n",
    "        ax.set_title(\"Correlation($Delta$NSE$_{\" + model + \"}$, Static Features)\")\n",
    "        ax.set_ylabel(\"$\\\\rho$\")\n",
    "        sns.despine()\n",
    "\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sign_df.set_index(\"feature\")[\"correlation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_spearmans[\"TOPMODEL\"][\"feature\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sign_features = {}\n",
    "for model in models:\n",
    "    #Â only select those with p values below X point\n",
    "    sign_df = all_spearmans[model].loc[all_spearmans[model][\"pvalue\"] < 0.01]\n",
    "    sign_features[model] = sign_df[\"feature\"].values\n",
    "\n",
    "# features across all four models\n",
    "sets = [set(v) for v in sign_features.values()]\n",
    "features_for_analysis = list(sets[0].intersection(sets[1]).intersection(sets[2]).intersection(sets[3]))\n",
    "features_for_analysis\n",
    "len(features_for_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other correlation plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot ordered plot of correlation of features for EACH model and ALL significant  features\n",
    "if False:\n",
    "    for model in models:\n",
    "        #Â only select those with p values below X point\n",
    "        sign_df = all_spearmans[model].loc[all_spearmans[model][\"pvalue\"] < 0.01]\n",
    "\n",
    "        f, ax = plt.subplots(figsize=(12, 4))\n",
    "        # spear_df.reindex(spear_df[\"correlation\"].abs().sort_values(ascending=False).index)\n",
    "        sign_df.sort_values(\"correlation\").set_index(\"feature\")[\"correlation\"].plot.bar(ax=ax)\n",
    "        ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha=\"right\")\n",
    "        ax.set_title(\"Correlation($Delta$NSE$_{\" + model + \"}$, Static Features)\")\n",
    "        ax.set_ylabel(\"$\\\\rho$\")\n",
    "        sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Â Plot the normalised values of NSE vs. static feature - regression plots\n",
    "if False:\n",
    "    from sklearn.preprocessing import normalize, MinMaxScaler\n",
    "    stations = [sid for sid in delta_nse[\"TOPMODEL\"].dropna().index]\n",
    "\n",
    "    norm_static = pd.DataFrame(MinMaxScaler().fit_transform(static))\n",
    "    norm_static.columns = static.columns\n",
    "    norm_static.index = static.index\n",
    "\n",
    "    delta_nse_nonans = delta_nse.dropna()\n",
    "    norm_nse = pd.DataFrame(MinMaxScaler().fit_transform(delta_nse_nonans))\n",
    "    norm_nse.columns = delta_nse_nonans.columns\n",
    "    norm_nse.index = delta_nse_nonans.index\n",
    "\n",
    "    n_rows = (len(features_for_analysis) // 2) + (len(features_for_analysis) % 2)\n",
    "    f, axs = plt.subplots(n_rows, 2, figsize=(3*2, 2*n_rows))\n",
    "    for ix, static_feature in enumerate(features_for_analysis):\n",
    "        ax_ix = np.unravel_index(ix, (n_rows, 2))\n",
    "        ax = axs[ax_ix]\n",
    "\n",
    "        # get the X, y data\n",
    "        sort_index = norm_nse.loc[stations, model].sort_values(ascending=True).index\n",
    "        y = norm_static.loc[stations, static_feature].reindex(sort_index)\n",
    "        x = norm_nse.loc[stations, model].reindex(sort_index)\n",
    "        ax.scatter(x, y)\n",
    "\n",
    "        # plot regression\n",
    "        coef = np.polyfit(x, y, 1)\n",
    "        poly1d_fn = np.poly1d(coef) \n",
    "        y_hat = poly1d_fn(x)\n",
    "        ax.plot(x, y_hat, ls=\":\", color=\"k\", label=f\"{coef[0]:.2f}\")\n",
    "\n",
    "        ax.set_title(static_feature)\n",
    "        ax.legend()\n",
    "\n",
    "        if ax_ix[0] == n_rows - 1:\n",
    "            ax.set_xlabel(\"$\\Delta$NSE\")\n",
    "        sns.despine()\n",
    "\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Where does the LSTM do worse?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import colors\n",
    "\n",
    "cmap = colors.ListedColormap([\"grey\", sns.color_palette()[0]])\n",
    "\n",
    "f, axs = plt.subplots(1, 4, figsize=(12, 8*4))\n",
    "\n",
    "worse_basins = {}\n",
    "for ix, model in enumerate(models):\n",
    "    ax = axs[ix]\n",
    "    ax.set_title(model)\n",
    "    delta_gdf[f\"{model}_bool\"] = delta_gdf[model] < 0\n",
    "    #Â delta_gdf.plot(f\"{model}_bool\", ax=ax, cmap=cmap, markersize=10)\n",
    "    delta_gdf.loc[delta_gdf[model] > 0].plot(f\"{model}_bool\", ax=ax, color=\"grey\", markersize=10)\n",
    "    delta_gdf.loc[delta_gdf[model] < 0].plot(f\"{model}_bool\", ax=ax, color=\"blue\", markersize=None)\n",
    "    \n",
    "    worse_basins[model] = delta_gdf.loc[delta_gdf[model] < 0].index\n",
    "    \n",
    "for ax in axs:\n",
    "    ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten = lambda t: [item for sublist in t for item in sublist]\n",
    "\n",
    "all_worse_sids = set(flatten(worse_basins.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{len(all_worse_sids)} Catchments that LSTMs Worse (than ANY conceptual)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def smooth_lowess(x, y, kwargs: Dict = {}) -> Tuple[pd.Series]:\n",
    "#     from statsmodels.nonparametric.smoothers_lowess import lowess\n",
    "\n",
    "#     #Â wrapper for statsmodels lowess\n",
    "#     try:\n",
    "#         smooth_y = lowess(y, x, return_sorted=False, **kwargs)\n",
    "#     except AttributeError:\n",
    "#         x, y = x.values.flatten(), y.values.flatten()\n",
    "#         smooth_y = lowess(y, x, return_sorted=False, **kwargs)\n",
    "    \n",
    "#     df = x.rename(\"x\").to_frame()\n",
    "#     df[\"y\"] = smooth_y\n",
    "#     df = df.dropna().sort_values(\"x\")\n",
    "#     return df[\"x\"], df[\"y\"]\n",
    "\n",
    "# import patsy\n",
    "# patsy.dmatrix(\"\")\n",
    "\n",
    "def lr_line(x: pd.Series, y: pd.Series) -> np.array:\n",
    "    x_unique = np.unique(x)\n",
    "    \n",
    "    # fit the coefficients\n",
    "    reg = np.polyfit(x, y, 1)\n",
    "    #Â make a prediction\n",
    "    lm = np.poly1d(reg)\n",
    "    y_hat = lm(x_unique)\n",
    "\n",
    "    return x_unique, y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xvar = \"baseflow_index\"\n",
    "yvar = \"q_mean\"\n",
    "yvar = \"Q95\"\n",
    "spline = True\n",
    "\n",
    "# f, axs = plt.subplots(1, 2)\n",
    "\n",
    "# ax = axs[0]\n",
    "\n",
    "f, ax = plt.subplots()\n",
    "x = static[xvar].to_dataframe()\n",
    "y = static[yvar].to_dataframe()\n",
    "\n",
    "ax.scatter(x, y, alpha=0.7)\n",
    "# x_uq, y_hat = lr_line(x[xvar], y[yvar])\n",
    "# ax.plot(x_uq, y_hat, color=\"k\", ls=\"--\")\n",
    "\n",
    "ax.set_xlabel(xvar)\n",
    "ax.set_ylabel(yvar)\n",
    "\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import patsy\n",
    "x_1d = x[xvar]\n",
    "y_1d = y[yvar]\n",
    "X = patsy.dmatrix(\"bs(x_1d, df=6, degree=3, include_intercept=True) - 1\")\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.LinearRegression()\n",
    "\n",
    "clf.fit(X, y_1d)\n",
    "yhat = clf.predict(X)\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dir(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which basins do all 3 of the conceptual models outperform the LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conceptual_better = delta_gdf[[c for c in delta_gdf.columns if \"bool\" in c]]\n",
    "# conceptual_better[np.any(conceptual_better, axis=1)]\n",
    "worse_stations = [sid for sid in conceptual_better[np.all(conceptual_better, axis=1)].index if sid in matching_stations]\n",
    "len(conceptual_better[np.all(conceptual_better, axis=1)])\n",
    "worse_stations\n",
    "len(worse_stations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_stations(stations):\n",
    "    f, ax = plt.subplots() \n",
    "\n",
    "    delta_gdf.loc[~np.isin(delta_gdf.index, stations)].plot(f\"{model}_bool\", ax=ax, color=\"grey\", markersize=10)\n",
    "    delta_gdf.loc[np.isin(delta_gdf.index, stations)].plot(f\"{model}_bool\", ax=ax, color=\"blue\", markersize=None)\n",
    "    ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots() \n",
    "\n",
    "delta_gdf.loc[~np.isin(delta_gdf.index, worse_stations)].plot(f\"{model}_bool\", ax=ax, color=\"grey\", markersize=10)\n",
    "delta_gdf.loc[np.isin(delta_gdf.index, worse_stations)].plot(f\"{model}_bool\", ax=ax, color=\"blue\", markersize=None)\n",
    "ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fuse_errors_fp = data_dir / \"RUNOFF/0_fuse_errors.pkl\"\n",
    "fuse_class_fp = data_dir / \"RUNOFF/0_fuse_class.pkl\"\n",
    "\n",
    "f_class = pickle.load(fuse_class_fp.open(\"rb\"))\n",
    "fuse_errors = pickle.load(fuse_errors_fp.open(\"rb\"))\n",
    "vic_error = f_class.get_model_df(\"VIC\")\n",
    "prms_error = f_class.get_model_df(\"PRMS\")\n",
    "top_error = f_class.get_model_df(\"TOPMODEL\")\n",
    "sac_error = f_class.get_model_df(\"Sacramento\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# worse_df\n",
    "order_ = nse_df.loc[[int(sid) for sid in all_worse_sids]].drop(\"Name\", axis=1)\n",
    "order_ = (order_[\"LSTM\"] - order_.drop(\"LSTM\", axis=1).T).min().sort_values()\n",
    "\n",
    "print(f\"Median Absolute Delta NSE for the Stations where DeltaNSE < 0: {order_.abs().median():.02f}\")\n",
    "print(order_.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worse_nse = nse_df.loc[[int(sid) for sid in all_worse_sids]]\n",
    "len(worse_nse)\n",
    "worse_nse.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lstm_metric_df\n",
    "worse_nse = nse_df.loc[[int(sid) for sid in all_worse_sids]]\n",
    "\n",
    "worse_df = worse_nse.reset_index().set_index([\"index\", \"Name\"]).stack().reset_index(-1).rename({\"level_2\": \"model\", 0: \"nse\"}, axis=1).reset_index(\"Name\")\n",
    "worse_df = worse_df.reset_index().rename({\"index\": \"station_id\"}, axis=1).astype({\"station_id\": str})\n",
    "\n",
    "#Â order from greatest difference to minimum difference\n",
    "worse_df = worse_df.set_index(\"station_id\").loc[[str(sid) for sid in order_.index]]\n",
    "\n",
    "# len(worse_df)\n",
    "worse_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the RAW NSEs for the comparison models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = 1.1\n",
    "\n",
    "# plot_data = worse_df \n",
    "# plot_data[\"nse\"] = plot_data[\"nse\"] + np.random.normal(0, 0.01, len(plot_data[\"nse\"]))\n",
    "# TOPMODEL (green), VIC (red), PRMS (purple), Sacramento\n",
    "model_order = [\"LSTM\", \"EALSTM\", \"TOPMODEL\", \"VIC\", \"PRMS\", \"Sacramento\"]\n",
    "abs_ = True\n",
    "f, ax = plt.subplots(figsize=(12*scale, 4*scale))\n",
    "\n",
    "colors = sns.color_palette()[1: len(model_order)]\n",
    "for ix, model in enumerate(model_order[1:]):\n",
    "    plot_data = worse_df.loc[worse_df[\"model\"] == model]\n",
    "    ax.scatter(plot_data[\"Name\"], plot_data[\"nse\"], color=colors[ix], s=60, label=model)\n",
    "\n",
    "plot_data = worse_df.loc[worse_df[\"model\"] == \"LSTM\"]\n",
    "ax.scatter(plot_data[\"Name\"], plot_data[\"nse\"], color=\"k\", marker=\"x\", s=100, label=\"LSTM\")\n",
    "\n",
    "# sns.scatterplot(x=\"Name\", y=\"nse\", hue=\"model\", data=worse_df, hue_order=model_order, )\n",
    "# ax.set_xticklabels(rotation = 45, ha=\"right\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "\n",
    "ax.set_xlabel(\"Station\")\n",
    "ax.set_ylabel(\"NSE\")\n",
    "ax.set_ylim(0, 1)\n",
    "ax.legend()\n",
    "\n",
    "#Â Plot the raw difference\n",
    "ax2 = ax.twinx()\n",
    "if abs_:\n",
    "    ax2.bar(plot_data[\"Name\"], abs(order_), alpha=0.3)\n",
    "    ax2.set_ylim(0, 1)\n",
    "    ax2.set_ylabel(\"Absolute $\\Delta$NSE\")\n",
    "else:\n",
    "    ax2.bar(plot_data[\"Name\"], order_, alpha=0.3)\n",
    "    ax2.set_ylim(-0.7, 0)\n",
    "    ax2.set_ylabel(\"$\\Delta$NSE\")\n",
    "# sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data[\"Name\"].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "static = all_static\n",
    "station_names = static[\"gauge_name\"].to_dataframe()\n",
    "\n",
    "worse_stations_ = worse_stations\n",
    "#Â ANY worse basins = 33\n",
    "# worse_stations = [int(sid) for sid in all_worse_sids]\n",
    "#Â ALL worse basins = 3\n",
    "# worse_stations = [int(sid) for sid in worse_stations_]\n",
    "\n",
    "f, axs = plt.subplots(len(worse_stations), 1, figsize=(6, 3*len(worse_stations)))\n",
    "for ix, sid in enumerate(lstm_preds.sel(station_id=worse_stations).station_id):\n",
    "    ax = axs[ix]\n",
    "    #Â LSTM\n",
    "    lstm_preds.sel(station_id=sid, time=lstm_preds[\"time.year\"] == 2007)[\"sim\"].plot(ax=ax, **{\"label\": \"LSTM\", \"linewidth\": 1})\n",
    "\n",
    "    # conceptual models\n",
    "    fuse_d = fuse_ds.sel(station_id=sid, time=fuse_ds[\"time.year\"] == 2007)\n",
    "    for v in [str(v) for v in fuse_d.data_vars]:\n",
    "        fuse_d[v].plot(ax=ax, **{\"label\": str(v).replace(\"SimQ_\", \"\"), \"linewidth\": 1})\n",
    "    \n",
    "    # obs\n",
    "    lstm_preds.sel(station_id=sid, time=lstm_preds[\"time.year\"] == 2007)[\"obs\"].plot(ax=ax, color=\"k\", ls=\":\", **{\"label\": \"Observation\"})\n",
    "    \n",
    "    #Â title\n",
    "    name = str(station_names.loc[int(sid)][0])\n",
    "    nse = float(lstm_metric_df.loc[int(sid), \"nse\"])\n",
    "    top_nse = top_error.loc[int(sid)][\"nse\"]\n",
    "    vic_nse = vic_error.loc[int(sid)][\"nse\"]\n",
    "    prm_nse = prms_error.loc[int(sid)][\"nse\"]\n",
    "    sac_nse = sac_error.loc[int(sid)][\"nse\"]\n",
    "    ax.set_title(\n",
    "        f\"{name}\\n\"\n",
    "        f\"LSTM: {nse:.2f} -- TOP: {top_nse:.2f} -- Sac: {sac_nse:.2f} -- PRMS: {prm_nse:.2f} -- VIC: {vic_nse:.2f}\"\n",
    "    )\n",
    "    if ix == 0:\n",
    "        ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "sns.despine()\n",
    "\n",
    "worse_stations = worse_stations_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure the difference between Catchments - KS Test \n",
    "- [Scipy implementation](https://stats.stackexchange.com/questions/354035/how-to-compare-the-data-distribution-of-2-datasets)\n",
    "- This is a two-sided test for the null hypothesis that 2 independent samples are drawn from the same continuous distribution. The alternative hypothesis can be either âtwo-sidedâ (default), âlessâ or âgreaterâ.\n",
    "- If the p-value is high, then we cannot reject the hypothesis that the distributions of the two samples are the same\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ks_2samp\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (static_df.dtypes == \"float64\").sum()\n",
    "better_stations = np.isin(static_df.index, conceptual_better.any(axis=1).index[conceptual_better.any(axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wilcoxon_results = defaultdict(dict)\n",
    "for static_feature in static_df.loc[:, static_df.dtypes == \"float64\"].columns:\n",
    "    test_result = ks_2samp(\n",
    "        static_df.loc[better_stations, static_feature],\n",
    "        static_df.loc[[ix for ix in static_df.index if ix not in better_stations], static_feature]\n",
    "    )\n",
    "    wilcoxon_results[static_feature][\"statistic\"] = test_result.statistic\n",
    "    wilcoxon_results[static_feature][\"pvalue\"] = test_result.pvalue\n",
    "    \n",
    "ks_df = pd.DataFrame(wilcoxon_results).T.reset_index().rename({\"index\": \"static_feature\"}, axis=1)\n",
    "ks_df.sort_values(\"pvalue\").head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_for_worse = static_df.loc[better_stations, ks_df.loc[ks_df[\"pvalue\"] < 0.05, \"static_feature\"]]\n",
    "static_for_better = static_df.loc[[ix for ix in static_df.index if ix not in better_stations], ks_df.loc[ks_df[\"pvalue\"] < 0.05, \"static_feature\"]]\n",
    "display(static_for_better.head())\n",
    "display(static_for_worse.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot ECDFs for features with significant difference\n",
    "1. Get the basins where ANY of the conceptual models outperform the LSTM models\n",
    "1. calculate the KS statistic for all of the continuous static features \n",
    "1. Select the static features that KS statistic is p < 0.05\n",
    "1. Plot those as ECDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ecdf(x: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Calculate empirical cummulative density function\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : np.ndarray\n",
    "        Array containing the data\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    x : np.ndarray\n",
    "        Array containing the sorted metric values\n",
    "    y : np.ndarray]\n",
    "        Array containing the sorted cdf values\n",
    "    \"\"\"\n",
    "    xs = np.sort(x)\n",
    "    ys = np.arange(1, len(xs) + 1) / float(len(xs))\n",
    "    return xs, ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axs = plt.subplots(16, 4, figsize=(3*4, 1*16))\n",
    "\n",
    "static_feature = \"frac_high_perc\"\n",
    "\n",
    "for ix, static_feature in enumerate(static_for_better.columns):\n",
    "    ax = axs[np.unravel_index(ix, (16, 4))]\n",
    "    #Â sns.kdeplot(static_for_better.loc[:, static_feature].dropna(), ax=ax, label=\"Better\", shade=False, cumulative=True, legend=False if ix != 0 else True)\n",
    "    #Â sns.kdeplot(static_for_worse.loc[:, static_feature].dropna(), ax=ax, label=\"Worse\", shade=False, cumulative=True, legend=False if ix != 0 else True)\n",
    "    ax.plot(*ecdf(static_for_better.loc[:, static_feature].dropna()), label=\"Better\")\n",
    "    ax.plot(*ecdf(static_for_worse.loc[:, static_feature].dropna()), label=\"Worse\")\n",
    "\n",
    "    ax.set_title(static_feature)\n",
    "    ax.axis(\"off\")\n",
    "    \n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Central Belt of Scotland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import folium\n",
    "g = make_point_static_gdf(\"baseflow_index\")\n",
    "gjson = g.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_stations(stations):\n",
    "    f, ax = plt.subplots() \n",
    "    isin_stations = delta_gdf.loc[np.isin(delta_gdf.index, stations)].index\n",
    "    \n",
    "    delta_gdf.loc[~np.isin(delta_gdf.index, stations)].plot(f\"{model}_bool\", ax=ax, color=\"grey\", markersize=10)\n",
    "    delta_gdf.loc[np.isin(delta_gdf.index, stations)].plot(f\"{model}_bool\", ax=ax, color=\"blue\", markersize=None)\n",
    "    ax.axis('off')\n",
    "    return isin_stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = np.append(np.arange(84000, 84100), np.arange(83000, 83100))\n",
    "# stations = \n",
    "stations = np.append(np.arange(15000, 18100), np.arange(85000, 85100))\n",
    "# stations = np.arange(15000, 15100)\n",
    "# plot_stations(stations=stations)\n",
    "\n",
    "c_scotland_stations = plot_stations(stations=stations)\n",
    "print(len(c_scotland_stations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KDEPLOT = True\n",
    "metric = \"nse\"\n",
    "\n",
    "f, ax = plt.subplots()\n",
    "if KDEPLOT:\n",
    "    sns.kdeplot(metric_df[metric], ax=ax, clip=(0, 1), cumulative=True, label=\"All of GB\")\n",
    "    sns.kdeplot((metric_df.set_index(\"station_id\").loc[c_scotland_stations, metric]), ax=ax, clip=(0, 1), cumulative=True, label=\"Scotland\")\n",
    "else:\n",
    "    sns.distplot(metric_df[metric], ax=ax, label=\"All of GB\")\n",
    "    sns.distplot((metric_df.set_index(\"station_id\").loc[c_scotland_stations, metric]), ax=ax, label=\"Scotland\")\n",
    "\n",
    "ax.set_xlim(0, 1)\n",
    "sns.despine()\n",
    "ax.set_xlabel(metric)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = np.concatenate([np.arange(40000, 41100), np.arange(39010, 39020)])\n",
    "# stations = np.arange(38000, 41100)\n",
    "# stations = np.arange(41000, 41100)\n",
    "# stations = np.arange(39010, 39020)\n",
    "if True:\n",
    "    se_stations = plot_stations(stations=stations)\n",
    "    print(len(se_stations))\n",
    "#     se_stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metric_df\n",
    "# lstm_error_df\n",
    "# lstm_metric_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(lstm_metric_df.loc[se_stations, \"nse\"]).median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KDEPLOT = False\n",
    "metric = \"bias\"\n",
    "\n",
    "f, ax = plt.subplots()\n",
    "if KDEPLOT:\n",
    "    sns.kdeplot(lstm_metric_df[metric], ax=ax, clip=(0, 1) if metric in [\"nse\", \"kge\"] else None, cumulative=True, label=\"All of GB\")\n",
    "    sns.kdeplot((lstm_metric_df.loc[se_stations, metric]), ax=ax, clip=(0, 1) if metric in [\"nse\", \"kge\"] else None, cumulative=True, label=\"SE England\")\n",
    "else:\n",
    "    sns.distplot(lstm_metric_df[metric], ax=ax, label=\"All of GB\")\n",
    "    sns.distplot((lstm_metric_df.loc[se_stations, metric]), ax=ax, label=\"SE England\")\n",
    "\n",
    "if metric in [\"nse\", \"kge\"]:\n",
    "    ax.set_xlim(0, 1)\n",
    "elif metric == \"bias\":\n",
    "    ax.axvline(0, ls=\"--\", alpha=0.5, color=\"grey\")\n",
    "sns.despine()\n",
    "ax.set_xlabel(metric)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_delta[\"nse\"]\n",
    "\n",
    "KDEPLOT = True\n",
    "metric = \"nse\"\n",
    "model = \"TOPMODEL\"\n",
    "f, ax = plt.subplots()\n",
    "\n",
    "\n",
    "if KDEPLOT:\n",
    "    sns.kdeplot(lstm_delta[metric][model], ax=ax, clip=(0, 1) if metric in [\"nse\", \"kge\"] else None, cumulative=True, label=\"All of GB\")\n",
    "    sns.kdeplot((lstm_delta[metric].loc[se_stations, model]), ax=ax, clip=(0, 1) if metric in [\"nse\", \"kge\"] else None, cumulative=True, label=\"SE England\")\n",
    "else:\n",
    "    sns.distplot(lstm_delta[metric][model], ax=ax, label=\"All of GB\", bins=20, norm_hist=True)\n",
    "    sns.distplot(lstm_delta[metric].loc[se_stations, model], ax=ax, label=\"SE England\", bins=20, norm_hist=True)\n",
    "\n",
    "if metric in [\"nse\", \"kge\"]:\n",
    "    if KDEPLOT:\n",
    "        ax.set_xlim(0, 1)\n",
    "    else:\n",
    "        ax.set_xlim(-1, 1)\n",
    "elif metric == \"bias\":\n",
    "    ax.axvline(0, ls=\"--\", alpha=0.5, color=\"grey\")\n",
    "sns.despine()\n",
    "ax.set_xlabel(\"â\" + metric)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?sns.distplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metric_se = []\n",
    "all_metric = \n",
    "metric = \"nse\"\n",
    "for model in models:\n",
    "    all_metric_se.append(lstm_delta[metric].loc[se_stations, model])\n",
    "    all_metric.append(lstm_delta[metric][model])\n",
    "    print(f\"SE Stations Median {model} â{metric}: {lstm_delta[metric].loc[se_stations, model].median():.2f}\")\n",
    "    print(f\"ALL Stations Median {model}  â{metric}: {lstm_delta[metric][model].median():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"SE Median â: {(pd.concat(all_metric_se)).median():.2f}\")\n",
    "print(f\"SE Median â: {(pd.concat(all_metric)).median():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Analysis supersedes the T Test (BEST)\n",
    "- [BEST Python tool](https://best.readthedocs.io/en/latest/)\n",
    "- [BEST in PyMC3](https://docs.pymc.io/notebooks/BEST.html)\n",
    "- [Using R and Stan w/BRMS](https://vuorre.netlify.app/post/2017/01/02/how-to-compare-two-groups-with-robust-bayesian-estimation-using-r-stan-and-brms/)\n",
    "- [Original Paper](https://jkkweb.sitehost.iu.edu/BEST/BEST.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What characteristics where we do better / worse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Worse?\n",
    "worse_cments_top = static_df[(lstm_delta_nse < 0)[\"TOPMODEL\"]]\n",
    "worse_cments_sac = static_df[(lstm_delta_nse < 0)[\"Sacramento\"]]\n",
    "worse_cments_vic = static_df[(lstm_delta_nse < 0)[\"VIC\"]]\n",
    "worse_cments_prms = static_df[(lstm_delta_nse < 0)[\"PRMS\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.distplot(worse_cments_top[\"aridity\"], label=\"TOPMODEL\")\n",
    "# sns.distplot(worse_cments_sac[\"aridity\"], label=\"Sacramento\")\n",
    "# sns.distplot(worse_cments_vic[\"aridity\"], label=\"VIC\")\n",
    "# sns.distplot(worse_cments_prms[\"aridity\"], label=\"PRMS\")\n",
    "# plt.legend()\n",
    "# sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is delta NSE predictable?\n",
    "Random forests tuning ([DataScienceMedium](https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74))\n",
    "- n_estimators = number of trees in the foreset\n",
    "- max_features = max number of features considered for splitting a node\n",
    "- max_depth = max number of levels in each decision tree\n",
    "- min_samples_split = min number of data points placed in a node before the node is split\n",
    "- min_samples_leaf = min number of data points allowed in a leaf node\n",
    "\n",
    "[Sklearn Docs - RF Parameters](https://scikit-learn.org/stable/modules/ensemble.html#random-forest-parameters): \n",
    "- main parameters to adjust when using these methods is `n_estimators` and `max_features`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rfpimp import (\n",
    "    importances, \n",
    "    plot_importances, \n",
    "    plot_corr_heatmap, \n",
    "    feature_corr_matrix, \n",
    "    feature_dependence_matrix,\n",
    "    plot_dependence_heatmap\n",
    ")\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\"\"\"\n",
    "    rf = RandomForestRegressor(\n",
    "        random_state = 42,\n",
    "        n_estimators=200, # 200 100\n",
    "        max_features=50,  #Â 50  10\n",
    "        max_depth=100,    #Â 100  5 \n",
    "        min_samples_split=2, # 2\n",
    "        min_samples_leaf=1,  # 1\n",
    "        oob_score=False,   # True\n",
    "    )\n",
    "    \n",
    "    rf = RandomForestRegressor(\n",
    "        random_state=42, \n",
    "        n_estimators=200,\n",
    "        max_features=100//3,\n",
    "    )\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = lstm_delta[\"nse\"]  #Â ealstm_delta[\"nse\"]\n",
    "\n",
    "static_df = static.to_dataframe()\n",
    "names = static_df[\"gauge_name\"]\n",
    "#Â get floats with <25% nan\n",
    "static_df = static_df.loc[:, (static_df.dtypes == \"float64\") & (static_df.isna().mean(axis=0) < 0.25)]\n",
    "static_df = names.to_frame().join(static_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"TOPMODEL\"\n",
    "models = ['TOPMODEL', 'SACRAMENTO', 'ARNOVIC', 'PRMS']\n",
    "\n",
    "# training pairs\n",
    "stations = targets.dropna().index\n",
    "X = static_df.drop(\"gauge_name\", axis=1).loc[stations]\n",
    "Y = targets.loc[stations, model]\n",
    "# display(X.head())\n",
    "# display(Y.head())\n",
    "\n",
    "\n",
    "# Fix the basins used for Train/Test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.1)\n",
    "train_index = X_train.index\n",
    "test_index = X_test.index\n",
    "\n",
    "for model in tqdm(models):\n",
    "    Y = targets[model].dropna()\n",
    "    X = static_df.drop(\"gauge_name\", axis=1).loc[Y.index]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = X.loc[train_index], X.loc[test_index], Y.loc[train_index], Y.loc[test_index]\n",
    "    rf = RandomForestRegressor(\n",
    "        random_state=42, \n",
    "        n_estimators=200,\n",
    "        max_features=100//3,\n",
    "    )\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    print(model)\n",
    "    print(f\"Train R2 Score: {rf.score(X_train, y_train):.02f}\")\n",
    "    print(f\"Test R2 Score: {rf.score(X_test, y_test):.02f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train RandomForests on the model performances // Delta NSE\n",
    "- [sklearn implementation](https://github.com/scikit-learn/scikit-learn/pull/13146)\n",
    "- [post here](https://explained.ai/rf-importance/)\n",
    "- [rfpimp package](https://github.com/parrt/random-forest-importances/blob/master/src/rfpimp.py#L263)\n",
    "\n",
    "### How this works\n",
    "- $y$ = delta_NSE\n",
    "- $X$ = static features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rfpimp import (\n",
    "    importances, \n",
    "    plot_importances, \n",
    "    plot_corr_heatmap, \n",
    "    feature_corr_matrix, \n",
    "    feature_dependence_matrix,\n",
    "    plot_dependence_heatmap\n",
    ")\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_features = [\n",
    "    # Â HydroGeology\n",
    "    [\"inter_high_perc\", \"inter_mod_perc\", \"inter_low_perc\",],\n",
    "    [\"frac_high_perc\", \"frac_mod_perc\", \"frac_low_perc\",],\n",
    "    [\"low_nsig_perc\", \"nsig_low_perc\",],\n",
    "    \"no_gw_perc\",\n",
    "    # Topography\n",
    "    [\"gauge_lat\", \"gauge_lon\",],\n",
    "    [\n",
    "        \"gauge_elev\",\n",
    "        \"elev_mean\",\n",
    "        \"elev_min\",\n",
    "        \"elev_10\",\n",
    "        \"elev_50\",\n",
    "        \"elev_90\",\n",
    "        \"elev_max\",\n",
    "    ],\n",
    "    \"dpsbar\",\n",
    "    # Â Soil Properties\n",
    "    [\"sand_perc\", \"silt_perc\", \"clay_perc\", \"organic_perc\",],\n",
    "    [\"bulkdens\", \"bulkdens_5\", \"bulkdens_50\", \"bulkdens_95\",],\n",
    "    [\n",
    "        \"tawc\", \"tawc_5\", \"tawc_50\", \"tawc_95\"\n",
    "    ],\n",
    "    [\n",
    "        \"porosity_cosby\",\n",
    "        \"porosity_cosby_5\",\n",
    "        \"porosity_cosby_50\",\n",
    "        \"porosity_cosby_95\",\n",
    "        \"porosity_hypres\",\n",
    "        \"porosity_hypres_5\",\n",
    "        \"porosity_hypres_50\",\n",
    "        \"porosity_hypres_95\",\n",
    "    ],\n",
    "    [\n",
    "        \"conductivity_cosby\",\n",
    "        \"conductivity_cosby_5\",\n",
    "        \"conductivity_cosby_50\",\n",
    "        \"conductivity_cosby_95\",\n",
    "        \"conductivity_hypres\",\n",
    "        \"conductivity_hypres_5\",\n",
    "        \"conductivity_hypres_50\",\n",
    "        \"conductivity_hypres_95\",\n",
    "    ],\n",
    "    [\"root_depth\", \"root_depth_5\", \"root_depth_50\", \"root_depth_95\",],\n",
    "    [\n",
    "        \"soil_depth_pelletier\",\n",
    "        \"soil_depth_pelletier_5\",\n",
    "        \"soil_depth_pelletier_50\",\n",
    "        \"soil_depth_pelletier_95\",\n",
    "    ],\n",
    "    # Â Hydrologic Attributes\n",
    "    \"q_mean\",\n",
    "    \"runoff_ratio\",\n",
    "    \"stream_elas\",\n",
    "    \"slope_fdc\",\n",
    "    [\"baseflow_index\", \"baseflow_index_ceh\",],\n",
    "    \"hfd_mean\",\n",
    "    \"Q5\",\n",
    "    \"Q95\",\n",
    "    [\"high_q_freq\", \"low_q_freq\", \"zero_q_freq\",],\n",
    "    [\"high_q_dur\", \"low_q_dur\",],\n",
    "    # Â climatic indices\n",
    "    \"p_mean\",\n",
    "    \"pet_mean\",\n",
    "    \"aridity\",\n",
    "    \"p_seasonality\",\n",
    "    \"frac_snow\",\n",
    "    \"high_prec_freq\",\n",
    "    \"high_prec_dur\",\n",
    "    \"low_prec_freq\",\n",
    "    \"low_prec_dur\",\n",
    "    # Â landcover\n",
    "    \"dwood_perc\",\n",
    "    \"ewood_perc\",\n",
    "    \"grass_perc\",\n",
    "    \"shrub_perc\",\n",
    "    \"crop_perc\",\n",
    "    \"urban_perc\",\n",
    "    \"inwater_perc\",\n",
    "    \"bares_perc\",\n",
    "    # human influence\n",
    "    \"surfacewater_abs\",\n",
    "    \"groundwater_abs\",\n",
    "    \"discharges\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "def flatten(list_of_lists: List[Union[str, List]]):\n",
    "    flattened = []\n",
    "    for item in list_of_lists:\n",
    "        if type(item) == list:\n",
    "            flattened.extend([i for i in item])\n",
    "        else:\n",
    "            flattened.append(item)\n",
    "        \n",
    "    return flattened\n",
    "\n",
    "cont_features = flatten(groups_of_colinear_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = [\n",
    "    \"dom_land_cover\",\n",
    "    \"high_prec_timing\",\n",
    "    \"low_prec_timing\",\n",
    "]\n",
    "numerical_features = [\n",
    "    \"reservoir_cap\"\n",
    "]\n",
    "numerical_features.extend(cont_features)\n",
    "\n",
    "important_features = [\n",
    "    # topography\n",
    "    \"gauge_lat\", \n",
    "    \"gauge_lon\",\n",
    "    \"gauge_elev\",\n",
    "    \"dpsbar\",\n",
    "    # Hydrologic Attributes\n",
    "    \"q_mean\",\n",
    "    \"runoff_ratio\",\n",
    "    \"stream_elas\",\n",
    "    \"slope_fdc\",\n",
    "    \"baseflow_index\",\n",
    "    \"Q5\",\n",
    "    \"Q95\",\n",
    "    # Â climatic indices\n",
    "    \"p_mean\",\n",
    "    \"pet_mean\",\n",
    "    \"aridity\",\n",
    "    \"frac_snow\",\n",
    "    # landcover\n",
    "    \"dwood_perc\",\n",
    "    \"ewood_perc\",\n",
    "    \"grass_perc\",\n",
    "    \"shrub_perc\",\n",
    "    \"crop_perc\",\n",
    "    \"urban_perc\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â get train pairs\n",
    "Ys = delta_nse.dropna()\n",
    "\n",
    "X = static_df.loc[:, numerical_features + categorical_features]\n",
    "X = X.loc[Ys.index, important_features]\n",
    "\n",
    "assert len(X) == len(Ys)\n",
    "display(Ys.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â Processing and fitting pipeline\n",
    "categorical_pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "numerical_pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "#     ('normalizer', ),\n",
    "#     ('dimensional_reduction', PCA(n_components=4))\n",
    "])\n",
    "\n",
    "preprocessing = ColumnTransformer(\n",
    "    [\n",
    "        ('cat', categorical_pipe, categorical_features),\n",
    "        ('num', numerical_pipe, numerical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessing = ColumnTransformer(\n",
    "    [\n",
    "        (\"num\", numerical_pipe, important_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "rf = Pipeline([\n",
    "    ('preprocess', preprocessing),\n",
    "    ('Regressor', RandomForestRegressor(random_state=1, max_features=0.1, oob_score=True))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical_pipe.fit_transform(X[categorical_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(X, Ys);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances(rf, X, Ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"RF train accuracy: %0.3f\" % rf.score(X, Ys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = permutation_importance(rf, X, Ys, n_repeats=10,\n",
    "                                random_state=42, n_jobs=2)\n",
    "sorted_idx = result.importances_mean.argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 20))\n",
    "ax.boxplot(result.importances[sorted_idx].T,\n",
    "           vert=False, labels=X.columns[sorted_idx])\n",
    "ax.set_title(\"Permutation Importances (train set)\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_plot_feature(feature: str):\n",
    "    f, ax = plt.subplots()\n",
    "    d = delta_nse.join(static_df[feature])\n",
    "\n",
    "    ax.scatter(d[feature], d[\"TOPMODEL\"], marker=\"x\", label=\"TOPMODEL\", alpha=0.5, color=sns.color_palette()[0])\n",
    "    ax.scatter(d[feature], d[\"Sacramento\"], marker=\"x\", label=\"Sacramento\", alpha=0.5, color=sns.color_palette()[1])\n",
    "    ax.scatter(d[feature], d[\"VIC\"], marker=\"x\", label=\"VIC\", alpha=0.5, color=sns.color_palette()[2])\n",
    "    ax.scatter(d[feature], d[\"PRMS\"], marker=\"x\", label=\"PRMS\", alpha=0.5, color=sns.color_palette()[3])\n",
    "    \n",
    "    # plot linear regressions\n",
    "    #Â m, b = np.polyfit(d[feature], d[\"TOPMODEL\"], 1)\n",
    "\n",
    "    ax.set_ylim(-1, 1)\n",
    "    ax.set_ylabel(\"$\\Delta$NSE\")\n",
    "    ax.set_xlabel(feature)\n",
    "    plt.legend()\n",
    "    sns.despine()\n",
    "    \n",
    "\n",
    "scatter_plot_feature(\"crop_perc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
