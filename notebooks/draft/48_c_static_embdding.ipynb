{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# interpret static embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from ruamel.yaml import YAML\n",
    "mpl.rcParams['figure.dpi'] = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dir = Path('data/')\n",
    "data_dir = Path('/cats/datastore/data/')\n",
    "\n",
    "assert data_dir.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ealstm_less_vars_2004_1607_1334', 'lstm_less_vars_1307_1717', 'ealstm_less_vars_2004_1707_1424', 'lstm_less_vars_2004_1507_1028']\n",
      "['config.yml', 'events.out.tfevents.1594906656.GPU_MachineLearning.22441.0', 'model_epoch001.pt', 'model_epoch002.pt', 'model_epoch003.pt', 'model_epoch004.pt', 'model_epoch005.pt', 'model_epoch006.pt', 'model_epoch007.pt', 'model_epoch008.pt', 'model_epoch009.pt', 'model_epoch010.pt', 'model_epoch011.pt', 'valid_ds.nc', 'results_ealstm_less_vars_2004_1607_1334_E002.csv', 'results_ealstm_less_vars_2004_1607_1334_E006.csv', 'model_epoch012.pt', 'results_ealstm_less_vars_2004_1607_1334_E007.csv', 'results_ealstm_less_vars_2004_1607_1334_E001.csv', 'results_ealstm_less_vars_2004_1607_1334_E008.csv', 'results_ealstm_less_vars_2004_1607_1334_E009.csv', 'results_ealstm_less_vars_2004_1607_1334_E010.csv', 'model_epoch013.pt', 'results_ealstm_less_vars_2004_1607_1334_E005.csv', 'results_ealstm_less_vars_2004_1607_1334_E004.csv', 'results_ealstm_less_vars_2004_1607_1334_E003.csv', 'results_ealstm_less_vars_2004_1607_1334_E011.csv', 'all_ealstm_less_vars_2004_1607_1334_results.csv', 'model_epoch014.pt', 'train_data', 'test']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('/cats/datastore/data/runs/lstm_less_vars_2004_1507_1028')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print([d.name for d in (data_dir / \"runs/\").iterdir()])\n",
    "print([d.name for d in (data_dir / \"runs/ealstm_less_vars_2004_1607_1334\").glob(\"*\")])\n",
    "\n",
    "(data_dir / \"runs/ealstm_less_vars_2004_1607_1334\")\n",
    "(data_dir / \"runs/lstm_less_vars_2004_1507_1028\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = (data_dir / \"runs/ealstm_less_vars_2004_1607_1334/model_epoch014.pt\") \n",
    "config_path = (data_dir / \"runs/ealstm_less_vars_2004_1607_1334/config.yml\") \n",
    "yaml = YAML(typ=\"safe\")\n",
    "cfg = yaml.load(config_path)\n",
    "model_dict = torch.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (data_dir / \"CAMELS_GB_DATASET\").exists()\n",
    "assert (data_dir / \"runs/lstm_less_vars_2004_1507_1028/train_data/train_data_scaler.p\").exists()\n",
    "assert (data_dir / \"runs/lstm_less_vars_2004_1507_1028/train_data/train_data.h5\").exists()\n",
    "\n",
    "cfg[\"data_dir\"] = data_dir / \"CAMELS_GB_DATASET\"\n",
    "cfg[\"scaler_file\"] = data_dir / \"runs/lstm_less_vars_2004_1507_1028/train_data/train_data_scaler.p\"\n",
    "cfg[\"h5_file\"] = data_dir / \"runs/lstm_less_vars_2004_1507_1028/train_data/train_data.h5\"\n",
    "\n",
    "# input_size_dyn = len(cfg[\"dynamic_inputs\"])\n",
    "# input_size_stat = len(cfg[\"static_inputs\"] + cfg[\"camels_attributes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '/home/tommy/tommy_multiple_forcing')\n",
    "\n",
    "from codebase.modelzoo.ealstm import EALSTM\n",
    "from codebase.modelzoo.cudalstm import CudaLSTM\n",
    "from codebase.data.camelstxt import CamelsGBCSV\n",
    "from codebase.data.utils import load_basin_file\n",
    "from codebase.data.camelsh5 import CamelsGBH5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size_dyn = len(cfg[\"dynamic_inputs\"])\n",
    "input_size_stat = len(cfg[\"static_inputs\"] + cfg[\"camels_attributes\"])\n",
    "\n",
    "# Initialize model\n",
    "model = EALSTM(cfg)\n",
    "model.load_state_dict(torch.load(model_path, map_location=\"cpu\"))\n",
    "\n",
    "# # extract weight and bias of input gate\n",
    "# weight = model.lstm.weight_sh\n",
    "# bias = model.lstm.bias_s\n",
    "\n",
    "#Â load in the attributes\n",
    "h5 = CamelsGBH5(cfg)\n",
    "attributes = h5._load_attributes()\n",
    "# means = attributes.mean()\n",
    "# stds = attributes.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<codebase.data.camelsh5.CamelsGBH5 at 0x7fc62144d9d0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'open'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-4dad5ec9e86e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbasins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_basin_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train_basin_file\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbasin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbasins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m ds_test = CamelsGBCSV(camels_root=cfg[\"data_dir\"],\n\u001b[1;32m      4\u001b[0m                         \u001b[0mbasin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbasin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                         \u001b[0mdates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"test_start_date\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"test_end_date\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tommy_multiple_forcing/codebase/data/utils.py\u001b[0m in \u001b[0;36mload_basin_file\u001b[0;34m(basin_file)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_basin_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbasin_file\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mPosixPath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mbasin_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m         \u001b[0mbasins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0mbasins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbasin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbasin\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbasins\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'open'"
     ]
    }
   ],
   "source": [
    "basins = load_basin_file(cfg[\"train_basin_file\"])\n",
    "basin = basins[0]\n",
    "ds_test = CamelsGBCSV(camels_root=cfg[\"data_dir\"],\n",
    "                        basin=basin,\n",
    "                        dates=[cfg[\"test_start_date\"], cfg[\"test_end_date\"]],\n",
    "                        is_train=False,\n",
    "                        with_attributes=True,\n",
    "                        attribute_means=means,\n",
    "                        attribute_stds=stds,\n",
    "                        db_path=str(BASE_RUN_DIR / \"attributes.db\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for basin in tqdm(basins):\n",
    "    ds_test = CamelsTXT(camels_root=CAMELS_DIR,\n",
    "                        basin=basin,\n",
    "                        dates=[VAL_START, VAL_END],\n",
    "                        is_train=False,\n",
    "                        with_attributes=True,\n",
    "                        attribute_means=means,\n",
    "                        attribute_stds=stds,\n",
    "                        db_path=str(BASE_RUN_DIR / \"attributes.db\"))\n",
    "    input_gate = torch.sigmoid(torch.addmm(bias, ds_test.attributes, weight))\n",
    "    lstm_embedding[basin] = input_gate.detach().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
